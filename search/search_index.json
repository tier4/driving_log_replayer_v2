{"config":{"lang":["en","ja"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"driving_log_replayer_v2 Documentation","text":"<p>Language selection is available by pressing the \"\u6587 A\" icon at the top of the page.</p>"},{"location":"#about-driving_log_replayer_v2","title":"About driving_log_replayer_v2","text":"<p>driving_log_replayer_v2 is a ROS 2 package that evaluates the performance of Autoware.Universe based on previously recorded input data. It allows for defining and checking whether the assumptions of the system operation have been met.</p>"},{"location":"analyzer/","title":"driving_log_replayer_v2_analyzer","text":"<p>Package to analyze the result files of tests performed by driving_log_replayer_v2.</p>"},{"location":"analyzer/#directory-structure","title":"Directory Structure","text":"<p>The directory structure is as follows.</p> <pre><code>driving_log_replayer_v2_analyzer\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 __main__.py    # Entry point for CLI\n\u251c\u2500\u2500 analysis       # CLI analysis command\n\u251c\u2500\u2500 config         # Configuration file and module to read configuration\n\u251c\u2500\u2500 data           # Module to read data from jsonl\n\u2514\u2500\u2500 plot           # Module to plot data\n</code></pre> <p>Although this package is ROS-independent, it is also imported into ROS nodes as a library, so it is also installed as a ROS package.</p> <p>The roles of the modules are shown in Fig.</p> <p>architecture</p>"},{"location":"analyzer/#caution","title":"Caution","text":"<p>Currently only analysis of result.jsonl of obstacle_segmentation is possible. If necessary, add analysis modules for each use case. Add use_case_name.py files to analysis, config, and data.</p>"},{"location":"analyzer/#how-to-install","title":"How to install","text":"<ul> <li>Installed with driving_log_replayer_v2_cli</li> <li>Installed with driving_log_replayer_v2 as a ros package</li> </ul>"},{"location":"analyzer/#usage","title":"Usage","text":"<pre><code>dlr-analyzer analysis ${use-case-name} ${result.jsonl_path} [-c ${config_path}]\n</code></pre>"},{"location":"overview/command/","title":"Command","text":"<p>The driving_log_replayer_v2 can be started by specifying the scenario path.</p> <pre><code>ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=${scenario_path} [output_dir:=${output_dir} dataset_dir:=${dataset_dir}]\n</code></pre>"},{"location":"overview/command/#run-driving_log_replayer_v2-with-wasim","title":"Run driving_log_replayer_v2 with wasim","text":"<p>If you have access rights to Autoware Evaluator provided by TIER IV, you can also use wasim.</p> <p>Please see the wasim documentation site for an example of tool usage.</p> <p>Since wasim downloads and executes scenarios from Autoware Evaluator, it can only execute scenarios that are already registered in the cloud environment.</p>"},{"location":"overview/command/#run-driving_log_replayer_v2-with-driving-log-replayer-v2-cli","title":"Run driving_log_replayer_v2 with driving-log-replayer-v2-cli","text":"<p>Using CLI, multiple scenarios can be executed consecutively with a single command input.</p> <p>For example, suppose that multiple scenarios are placed in subdirectories (SCENARIO_DIR1, SCENARIO_DIR2...) under SCENARIO_ROOT as shown below.</p> <pre><code>SCENARIO_ROOT\n\u251c\u2500\u2500 SCENARIO_DIR1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 out # output directyory\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 SCENARIO_DIR1_DATASET0 # t4_dataset\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 annotation\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 input_bag\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 map\n\u2502\u00a0\u00a0 \u2502  \u2514\u2500\u2500 status.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 SCENARIO_DIR1_DATASET1 # t4_dataset\n\u2502\u00a0\u00a0 \u2502  \u2514\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2502  ...\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 scenario.yaml  # scenario fixed name\n\u2502\n\u251c\u2500\u2500 SCENARIO_DIR2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 out # output directyory\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 SCNERIO_DIR2_DATASET0 # t4_dataset\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 annotation\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 input_bag\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 map\n\u2502\u00a0\u00a0 \u2502  \u2514\u2500\u2500 status.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 scenario.yaml  # scenario fixed name\n...\n</code></pre> <p>To run multiple scenarios in the above SCENARIO_ROOT with the ros2 launch command, you need to hit the command multiple times as follows.</p> <pre><code>source ${AUTOWARE_ROOT}/install/setup.bash\nros2 launch driving_log_replayer_v2 driving_log_replayer_v2 scenario_path:=${SCENARIO_ROOT}/SCENARIO_DIR1/scenario.yaml dataset_index:=0 # If you have multiple datasets\nros2 launch driving_log_replayer_v2 driving_log_replayer_v2 scenario_path:=${SCENARIO_ROOT}/SCENARIO_DIR1/scenario.yaml dataset_index:=1 # If you have multiple datasets\nros2 launch driving_log_replayer_v2 driving_log_replayer_v2 scenario_path:=${SCENARIO_ROOT}/SCENARIO_DIR2/scenario.yaml\n...\n</code></pre> <p>If you use cli, you only need the following command</p> <pre><code>source ${AUTOWARE_ROOT}/install/setup.bash\ndlr2 simulation run ${SCENARIO_ROOT}\n</code></pre>"},{"location":"overview/command/#cli-installation","title":"cli installation","text":"<p>You can install cli with the following command.</p> <pre><code># install\npipx install git+https://github.com/tier4/driving_log_replayer_v2.git\n\n# upgrade\npipx upgrade driving-log-replayer-v2\n\n# uninstall\npipx uninstall driving-log-replayer-v2\n</code></pre>"},{"location":"overview/command/#cli-limitation","title":"cli limitation","text":"<p>The following limitations apply because of the automatic search for scenario files in CLI.</p> <ul> <li>The scenario file must be named scenario.yaml</li> <li>scenario.yaml must exist in a subdirectory under SCENARIO_ROOT (no sub-sub-directories allowed)</li> </ul>"},{"location":"overview/command/#cli-output","title":"cli output","text":"<p>Using CLI not only shortens the command input, but also increases the number of files output.</p> <p>The following is an example of the output destination when using CLI. The simulation run command and the console log are output as files. This is used to run multiple tests in a row and debug only the tests that show errors later.</p> <pre><code>OUTPUT_LATEST\n\u251c\u2500\u2500 0 # result of Datasets[0]\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 result.jsonl\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 result_archive_path\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 result_bag\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 metadata.yaml\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 result_bag_0.db3\n\u251c\u2500\u2500 1 # result of Datasets[1]\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 result.jsonl\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 result_archive_path\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 result_bag\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 metadata.yaml\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 result_bag_0.db3\n\u251c\u2500\u2500 console.log # Logs displayed in the console as a file\n\u2514\u2500\u2500 run.bash # simulation run command\n</code></pre>"},{"location":"overview/command/#cli-command","title":"cli command","text":"<p>The <code>dlr2</code> command has subcommands. The arguments required for each command can be displayed by specifying the <code>--help</code> option.</p> <pre><code># dlr2 top level help\ndlr2 --help\n\n# show version\ndlr2 --version\n\n# show subcommand help\ndlr2 subcommand --help\n\n# show subsubcommand help\ndlr2 subcommand subsubcommand --help\n</code></pre>"},{"location":"overview/command/#dlr2-simulation","title":"dlr2 simulation","text":"<p>Subcommands for simulation</p> <pre><code># Execute scenario under scenario_root in succession\ndlr2 simulation run ${scenario_root}\n\n# Add launch's argument with the -l option. Multiple -l's can be described.\n# The argument displayed by executing the following command can be specified\n# ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py -s\n# ros2 launch autoware_launch logging_simulator.launch.xml -s\n\n# Example: disable rviz with 0.5x playback speed for bag\ndl2 simulation run -l play_rate:=0.5 -l rviz:=false\n\n# Display a summary of result files under output_directory\ndlr2 simulation show-result ${output_directory}\n</code></pre>"},{"location":"overview/","title":"Overview","text":"<p>driving_log_replayer_v2 is a package that runs <code>logging_simulator.launch.xml</code> or <code>planning_simulator.launch.xml</code> on Autoware by supplying previously recorded input data using log(rosbag2) API. The package gathers information and evaluates topics output produced by Autoware. This software is used to verify the performance of each Autoware component and for software regression testing.</p>"},{"location":"overview/#related-documents","title":"Related Documents","text":"<ol> <li>AutowareDocumentation</li> <li>WebAutoDocumentation</li> </ol>"},{"location":"overview/#related-repositories","title":"Related repositories","text":"<ol> <li>ros2bag_extensions</li> <li>perception_eval</li> <li>perception_dataset</li> </ol>"},{"location":"overview/#architecture","title":"Architecture","text":"<p>driving_log_replayer_v2 package contains an evaluation node that extends Autoware's standard functionality. The architecture graph is shown below.</p> <p></p>"},{"location":"overview/#package-structure","title":"Package structure","text":"<p>The evaluation node works in the following manner:</p> <ul> <li>reads a scenario describing the conditions of positive evaluation</li> <li>launches autoware</li> <li>outputs the evaluation result in a JSON file format</li> </ul> <p>The details of the node's operation are shown in the figure below.</p> <p></p>"},{"location":"overview/#example-usage-flow","title":"Example usage flow","text":"<ol> <li>Acquire rosbags for evaluation using a real-world vehicle.</li> <li>Filter the acquired rosbags to contain only sufficient input topics in required period of time<ul> <li>For this purpose please use ros2bag_extensions package (developed by TIER IV). To properly filter the input rosbag:</li> <li>See docs/use_case/ documentations for which topics to leave in the filter.</li> </ul> </li> <li>Create an evaluation scenario<ol> <li>Example scenarios could be found in the repository's sample folder</li> <li>Refer to the format definition section of this document for description contents.</li> </ol> </li> <li>Create a dataset<ol> <li>localization, eagleye, yabloc, ar_tag_based_localizer, and performance_diag are optional if you will not use Evaluator.</li> <li>Create up to T4 non-annotated format data with reference to perception_dataset tools_overview.</li> <li>If you create T4 non-annotated format data, it is possible to check the contents of the data set on Vehicle Data Search.</li> </ol> </li> <li>If the node should test obstacle_segmentation, perception, perception_2d, or traffic_light stacks, please annotate with an annotation tool that supports conversion to t4_dataset.<ol> <li>Deepen.AI is available.</li> <li>By adding conversion functionality to perception_dataset, it becomes possible to use other annotation tools as well.</li> </ol> </li> <li>Perform the evaluation.</li> </ol>"},{"location":"quick_start/installation/","title":"Installation","text":"<p>This document contains step-by-step instruction on how to build AWF Autoware Core/Universe with <code>driving_log_replayer_v2</code>.</p>"},{"location":"quick_start/installation/#requirements","title":"Requirements","text":"<ul> <li>CPU amd64</li> <li>Ubuntu 22.04</li> <li>ROS humble</li> <li>Python 3.10</li> <li>NVIDIA GPU (required if running perception)</li> <li>zstd<ul> <li>sudo apt install zstd</li> </ul> </li> </ul>"},{"location":"quick_start/installation/#how-to-build","title":"How to build","text":"<ol> <li> <p>Navigate to the Autoware workspace:</p> <pre><code>cd autoware\n</code></pre> </li> <li> <p>Add dependency packages:</p> <pre><code>nano simulator.repos\n# add repositories below.\n</code></pre> <pre><code>  simulator/perception_eval:\n    type: git\n    url: https://github.com/tier4/autoware_perception_evaluation.git\n    version: main\n  simulator/driving_log_replayer_v2:\n    type: git\n    url: https://github.com/tier4/driving_log_replayer_v2.git\n    version: main\n  simulator/vendor/ros2_numpy:\n    type: git\n    url: https://github.com/Box-Robotics/ros2_numpy.git\n    version: humble\n  simulator/vendor/ros2bag_extensions:\n    type: git\n    url: https://github.com/tier4/ros2bag_extensions.git\n    version: main\n  simulator/tool/autoware_tools:\n    type: git\n    url: https://github.com/autowarefoundation/autoware_tools.git\n    version: main\n</code></pre> </li> <li> <p>Import Simulator dependencies:</p> <pre><code>vcs import src &lt; simulator.repos\n</code></pre> </li> <li> <p>(Optional) Basically, the main branch of driving_log_replayer_v2 is intended to be used with the latest autoware, so import nightly.repos as needed.</p> <pre><code>vcs import src &lt; autoware-nightly.repos\nvcs import src &lt; tools-nightly.repos\n</code></pre> </li> <li> <p>Update rosdep:</p> <pre><code>rosdep update\n</code></pre> </li> <li> <p>Install dependent ROS packages:</p> <pre><code>rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO\n</code></pre> </li> <li> <p>Build the workspace:</p> <pre><code>colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE=Release\n</code></pre> </li> </ol>"},{"location":"quick_start/run/","title":"Run driving_log_replayer_v2 evaluation","text":"<pre><code>cd ${AUTOWARE_WORKSPACE}\nsource install/setup.bash\nros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=${scenario_file}\n# example\n# ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=$HOME/driving_log_replayer_v2/yabloc.yaml\n</code></pre>"},{"location":"quick_start/setup/","title":"Setup","text":"<p>Note</p> <p>Running the driving_log_replayer_v2 requires some additional steps on top of building and installing Autoware, so make sure that driving_log_replayer_v2 installation has been completed first before proceeding.</p> <p>Sample map: Copyright 2020 TIER IV, Inc.</p> <p>Sample Dataset: Copyright 2022 TIER IV, Inc.</p>"},{"location":"quick_start/setup/#set-up-resources","title":"Set up resources","text":"<ol> <li> <p>Dataset and Map Setup (annotationless_perception, localization, obstacle_segmentation, perception)</p> <pre><code>mkdir -p ~/driving_log_replayer_v2\ngdown -O ~/driving_log_replayer_v2/sample_dataset_v2.tar.zst 'https://docs.google.com/uc?export=download&amp;id=1iCoykBBETI_rGfKEFYYb7LFydF-RJVkC'\ntar -I zstd -xvf ~/driving_log_replayer_v2/sample_dataset_v2.tar.zst -C ~/driving_log_replayer_v2/\ngdown -O ~/driving_log_replayer_v2/sample-map-planning.zip 'https://docs.google.com/uc?export=download&amp;id=1499_nsbUbIeturZaDj7jhUownh5fvXHd'\nunzip -d ~/driving_log_replayer_v2/ ~/driving_log_replayer_v2/sample-map-planning.zip\nmv ~/driving_log_replayer_v2/sample-map-planning ~/driving_log_replayer_v2/sample_dataset/map\n</code></pre> <p>You can also download manually.</p> <p>dataset</p> <p>sample-map-planning</p> </li> <li> <p>Dataset and Map Setup(yabloc, eagleye, ar_tag_based_localizer)</p> <pre><code>gdown -O ~/driving_log_replayer_v2/sample_bag.tar.zst 'https://docs.google.com/uc?export=download&amp;id=17ppdMKi4IC8J_2-_9nyYv-LAfW0M1re5'\ntar -I zstd -xvf ~/driving_log_replayer_v2/sample_bag.tar.zst -C ~/driving_log_replayer_v2/\nmv ~/driving_log_replayer_v2/sample_bag/*  ~/driving_log_replayer_v2/\nrmdir ~/driving_log_replayer_v2/sample_bag\ncp -r ~/driving_log_replayer_v2/ar_tag_based_localizer/map ~/driving_log_replayer_v2/eagleye/\ncp -r ~/driving_log_replayer_v2/ar_tag_based_localizer/map ~/driving_log_replayer_v2/yabloc/\n</code></pre> <p>You can also download manually.</p> <p>bag</p> </li> <li> <p>Copy the sample scenario to the dataset directory</p> <pre><code># Specify the directory where autoware is installed. Change according to your environment.\nAUTOWARE_PATH=$HOME/ros_ws/awf\n# SAMPLE_ROOT=${AUTOWARE_PATH}/src/simulator/driving_log_replayer_v2/sample\nSAMPLE_ROOT=${AUTOWARE_PATH}/src/simulator/driving_log_replayer_v2/sample\ncp ${SAMPLE_ROOT}/annotationless_perception/scenario.yaml ~/driving_log_replayer_v2/annotationless_perception.yaml\ncp ${SAMPLE_ROOT}/ar_tag_based_localizer/scenario.yaml ~/driving_log_replayer_v2/ar_tag_based_localizer.yaml\ncp ${SAMPLE_ROOT}/eagleye/scenario.yaml ~/driving_log_replayer_v2/eagleye.yaml\ncp ${SAMPLE_ROOT}/localization/scenario.yaml ~/driving_log_replayer_v2/localization.yaml\ncp ${SAMPLE_ROOT}/obstacle_segmentation/scenario.yaml ~/driving_log_replayer_v2/obstacle_segmentation.yaml\ncp ${SAMPLE_ROOT}/perception/scenario.yaml ~/driving_log_replayer_v2/perception.yaml\ncp ${SAMPLE_ROOT}/yabloc/scenario.yaml ~/driving_log_replayer_v2/yabloc.yaml\n</code></pre> </li> <li> <p>Transform machine learning trained models</p> <pre><code>source ~/autoware/install/setup.bash\nros2 launch autoware_launch logging_simulator.launch.xml map_path:=$HOME/autoware_map/sample-map-planning vehicle_model:=sample_vehicle sensor_model:=sample_sensor_kit\n# Wait until the following file is created in ~/autoware/install/lidar_centerpoint/share/lidar_centerpoint/data\n# - pts_backbone_neck_head_centerpoint_tiny.engine\n# - pts_voxel_encoder_centerpoint_tiny.engine\n# When the file is output, press Ctrl+C to stop launch.\n</code></pre> </li> </ol>"},{"location":"result_format/","title":"driving_log_replayer_v2 Result File Format","text":"<p>It is in JSONL format, with each line containing a string in JSON format.</p>"},{"location":"result_format/#format","title":"Format","text":"<p>Each line is output in the following format. The actual output is a single line of text, but it is formatted for ease of reading.</p> <pre><code>{\n  \"Result\": {\n    \"Success\": \"true or false\",\n    \"Summary\": \"summary of result\"\n  },\n  \"Stamp\": {\n    \"System\": \"system time\",\n    \"ROS\": \"simulation time\"\n  },\n  \"Frame\": {\n    \"Ego\": { \"TransformStamped\": \"transform_stamped from map to base_link\" },\n    \"Different configurations for each use case\": \"...\"\n  }\n}\n</code></pre> <p>Each evaluation output consists of the following attributes:</p> <ul> <li>Result: Result of the evaluation of the executed scenario</li> <li>Stamp: The time of the evaluation</li> <li>Frame: Evaluation results for one received frame (topic) and attached information such as values used for judgment.</li> </ul> <p>For more information on Frame, see the evaluation results file format for each use case.</p>"},{"location":"result_format/#analyze-the-result-files","title":"Analyze the result files","text":"<p>With vscode's JSONL Converter, you can easily convert jsonl &lt;-&gt; json with the push of a button</p> <p>https://marketplace.visualstudio.com/items?itemName=F-loat.jsonl-converter</p> <p>If you use python, you can read jsonl by setting lines=True in pandas.read_json.</p>"},{"location":"scenario_format/","title":"driving_log_replayer_v2 Scenario Format Definition","text":"<p>This section describes the scenario format used in driving_log_replayer_v2.</p>"},{"location":"scenario_format/#notes-on-the-format","title":"Notes on the format","text":"<ul> <li>Keys are defined in CamelCase until Scenario Format Version 3.0</li> <li>Due to scenario validation using pydantic, snake_case is recommended for newly added keys from Scenario Format Version 3.1</li> <li>Unless otherwise specified, the coordinate system is <code>map</code> coordinate system.</li> <li>Unless otherwise specified, the following unit system is used.</li> </ul> <pre><code>Distance: m\nVelocity: m/s\nacceleration: m/s^2\nTime: s\n</code></pre>"},{"location":"scenario_format/#samples","title":"Samples","text":"<p>Sample scenarios are stored in the sample folder.</p>"},{"location":"scenario_format/#format","title":"Format","text":"<p>The basic structure is as follows. Details of each key are described below.</p>"},{"location":"scenario_format/#driving_log_replayer_v2-scenario-format-version-3xx","title":"driving_log_replayer_v2 Scenario Format version 3.x.x","text":"<pre><code>ScenarioFormatVersion: 3.x.x\nScenarioName: String\nScenarioDescription: String\nSensorModel: String\nVehicleModel: String\npublish_profile: String\nEvaluation:\n  UseCaseName: String\n  UseCaseFormatVersion: String\n  Conditions: Dictionary # refer use case\n  Datasets:\n    - DatasetName:\n        VehicleId: String\ninclude_use_case:\n  UseCaseName: String\n  UseCaseFormatVersion: String\n  Conditions: Dictionary\n</code></pre>"},{"location":"scenario_format/#scenarioformatversion","title":"ScenarioFormatVersion","text":"<p>Describe the version information of the scenario format. Use the semantic version.</p> <p>Current Version is 3.1.0</p> <p>Minor versions are updated each time the format is updated.</p>"},{"location":"scenario_format/#scenarioname","title":"ScenarioName","text":"<p>Describes the name of the scenario, used as the display name of the scenario on the Autoware Evaluator.</p>"},{"location":"scenario_format/#scenariodescription","title":"ScenarioDescription","text":"<p>Describes a scenario, used as a scenario description on the Autoware Evaluator.</p>"},{"location":"scenario_format/#sensormodel","title":"SensorModel","text":"<p>Specify <code>sensor_model</code> as argument in <code>autoware_launch/launch/logging_simulator.launch.xml</code></p>"},{"location":"scenario_format/#vehiclemodel","title":"VehicleModel","text":"<p>Specify <code>vehicle_model</code> as an argument in <code>autoware_launch/launch/logging_simulator.launch.xml</code></p>"},{"location":"scenario_format/#publish_profile","title":"publish_profile","text":"<p>(Optional) Specify the name of the topics profile to control which topics are published during simulation. The profile file should be located at <code>config/publish/{profile_name}.yaml</code>, such as <code>planning_control</code>. If not specified, all available topics will be published.</p>"},{"location":"scenario_format/#evaluation","title":"Evaluation","text":"<p>Define the evaluation conditions for the simulation.</p>"},{"location":"scenario_format/#usecasename","title":"UseCaseName","text":"<p>Specify an evaluation program.</p> <p>The evaluation is executed by calling the evaluator node with the name specified here.</p>"},{"location":"scenario_format/#usecaseformatversion","title":"UseCaseFormatVersion","text":"<p>Describe the version information of the use case format. The semantic version shall be used. Until the major version becomes 1, the minor version is updated every time the format is updated. The initial version is 0.1.0.</p>"},{"location":"scenario_format/#conditions","title":"Conditions","text":"<p>Specify conditions that can be set for each use case.</p> <p>Refer to each use case for the conditions that can be specified.</p>"},{"location":"scenario_format/#datasets","title":"Datasets","text":"<p>Multiple datasets can be described, but they can be used only when the same evaluation conditions are used for multiple datasets. If multiple datasets are described, the index of the dataset to be used must be passed as the launch argument. The index starts with the number 0. If there is only one dataset, dataset_index:=0 may be used.</p> <pre><code># If the number of datasets described in the scenario is 1. dataset_index:=0 can be omitted.\nros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=${scenario_path} [dataset_index:=0]\n\n# If the number of datasets described in the scenario is more than one\nros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=${scenario_path} dataset_index:=${index_number}\n</code></pre>"},{"location":"scenario_format/#datasetname","title":"DatasetName","text":"<p>dataset name of t4_dataset</p>"},{"location":"scenario_format/#vehicleid","title":"VehicleId","text":"<p>Specify <code>vehicle_id</code> as an argument in <code>autoware_launch/launch/logging_simulator.launch.xml</code></p> <p>If you don't know <code>vehicle_id</code>, set <code>default</code>.</p>"},{"location":"scenario_format/#include_use_case","title":"include_use_case","text":"<p>Use this when you want to perform evaluation with a different use case simultaneously with the use case specified in Evaluation. Note that the nodes for the use cases specified here will not be automatically started.</p> <p>Each use case's evaluator node needs to add processing to evaluate with the conditions specified in include_use_case. Since the evaluator processes the last line of result.jsonl to determine success or failure, it is necessary to merge the results of result.jsonl from Evaluation and result.jsonl output from include_use_case in post_process.</p> <p>Currently, the functionality to evaluate diagnostics in planning_control has been implemented.</p>"},{"location":"trouble_shooting/","title":"Troubleshooting","text":"<p>Check if simulation does not work as expected</p>"},{"location":"trouble_shooting/#autoware-does-not-start","title":"Autoware does not start","text":""},{"location":"trouble_shooting/#cause-1","title":"Cause 1","text":"<p>The sensor_model, vehicle_model, and vehicle_id specified in the scenario are not included in the Autoware workspace used.</p>"},{"location":"trouble_shooting/#example-1","title":"Example 1","text":"<pre><code>\u276f ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=$HOME/driving_log_replayer_v2/sample.yaml\n[INFO] [launch]: All log files can be found below /home/hyt/.ros/log/2024-06-07-12-37-19-365597-dpc2405001-1360746\n[INFO] [launch]: Default logging verbosity is set to INFO\n1717731451.040883 [77]       ros2: determined eno1 (udp/10.0.55.137) as highest quality interface, selected for automatic interface.\n[ERROR] [launch]: Caught exception in launch (see debug for traceback): executed command failed. Command: xacro /home/hyt/ros_ws/pilot-auto/install/tier4_vehicle_launch/share/tier4_vehicle_launch/urdf/vehicle.xacro vehicle_model:=sample_vehicle sensor_model:=sample_sensor_kit config_dir:=/home/hyt/ros_ws/pilot-auto/install/individual_params/share/individual_params/config/default/sample_sensor_kit\nCaptured stderr output: error: package not found: \"package 'sample_sensor_kit_description' not found, searching: ...\n...\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area-1","title":"Correction method, Check area 1","text":"<p>Check whether sensor_model, vehicle_model, and vehicle_id specified in the scenario exist in the autoware_path specified in the profile.</p>"},{"location":"trouble_shooting/#autoware-exits-immediately-after-startup","title":"Autoware exits immediately after startup","text":""},{"location":"trouble_shooting/#cause","title":"Cause","text":"<p>Incorrect scenario format</p>"},{"location":"trouble_shooting/#example","title":"Example","text":"<pre><code>[localization_evaluator_node.py-55] [ERROR] [1717734608.157798307] [driving_log_replayer_v2.localization_evaluator]: An error occurred while loading the scenario. 1 validation error for LocalizationScenario\n[localization_evaluator_node.py-55] Evaluation.UseCaseFormatVersion\n[localization_evaluator_node.py-55]   Input should be '1.2.0' or '1.3.0' [type=literal_error, input_value='1.0.0', input_type=str]\n[localization_evaluator_node.py-55]     For further information visit https://errors.pydantic.dev/2.7/v/literal_error\n\nscenario: direct\n--------------------------------------------------\nTestResult: Failed\nScenarioFormatError\n--------------------------------------------------\n</code></pre> <pre><code>{\"Condition\":{}}\n{\"Result\":{\"Success\":false,\"Summary\":\"NoData\"},\"Stamp\":{\"System\":1717734608.157981},\"Frame\":{}}\n{\"Result\":{\"Success\":false,\"Summary\":\"ScenarioFormatError\"},\"Stamp\":{\"System\":0},\"Frame\":{\"ErrorMsg\":\"1 validation error for LocalizationScenario\\nEvaluation.UseCaseFormatVersion\\n  Input should be '1.2.0' or '1.3.0' [type=literal_error, input_value='1.0.0', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.7/v/literal_error\"}}\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area","title":"Correction method, Check area","text":"<p>The result.jsonl file shows what the problem is, so fix it as instructed. In the example, UseCaseFormatVersion should be 1.2.0 or 1.3.0, but it is 1.0.0, so it cannot be used. Since the old format is used, you should fix it by referring to the scenario in the sample directory of the repository.</p>"},{"location":"trouble_shooting/#the-evaluation-result-is-nodata","title":"The evaluation result is NoData","text":""},{"location":"trouble_shooting/#cause-1_1","title":"Cause 1","text":"<p>Autoware is not outputting the topic to be evaluated.</p>"},{"location":"trouble_shooting/#example-1-1","title":"Example 1-1","text":"<p>The node that outputs the topic to be evaluated is not invoked from launch. The true/false value in the launch file is incorrectly set.</p>"},{"location":"trouble_shooting/#correction-method-check-area-1-1","title":"Correction method, Check area 1-1","text":"<p>Find the topic to be evaluated in the document and check if the publisher exists by doing topic info. If the Publisher count: 0, it is highly likely that the system has not been started in the first place.</p> <pre><code>\u276f ros2 topic info /perception/traffic_light_recognition/traffic_signals -v\nType: autoware_auto_perception_msgs/msg/TrafficSignalArray\n\nPublisher count: 1 &lt;- Make sure it's not 0.\n\nNode name: crosswalk_traffic_light_estimator\nNode namespace: /perception/traffic_light_recognition\nTopic type: autoware_auto_perception_msgs/msg/TrafficSignalArray\nEndpoint type: PUBLISHER\nGID: 01.10.d8.43.57.21.7c.2d.98.25.db.df.00.00.46.03.00.00.00.00.00.00.00.00\nQoS profile:\n  Reliability: RELIABLE\n  History (Depth): KEEP_LAST (1)\n  Durability: VOLATILE\n  Lifespan: Infinite\n  Deadline: Infinite\n  Liveliness: AUTOMATIC\n  Liveliness lease duration: Infinite\n</code></pre>"},{"location":"trouble_shooting/#example-1-2","title":"Example 1-2","text":"<p>The node is running at launch, but dies immediately after startup.</p>"},{"location":"trouble_shooting/#correction-method-check-area-1-2","title":"Correction method, Check area 1-2","text":"<p>Search the terminal you started or console.log with ERROR.</p> <p>The following is a log of a case in which no point cloud was produced at all. Searching by ERROR shows that pointcloud_preprocessor is dead. Check if component_container, which outputs topics, is not throwing an error.</p> <pre><code>[ERROR] [component_container_mt-18]: process has died [pid 95, exit code -6, cmd '/opt/ros/galactic/lib/rclcpp_components/component_container_mt --ros-args -r __node:=pointcloud_preprocessor_container -r __ns:=/sensing/lidar/pointcloud_preprocessor --params-file /tmp/launch_params_rh_9gxcs'].\n</code></pre>"},{"location":"trouble_shooting/#example-1-3","title":"Example 1-3","text":"<p>Inconsistency between cuda, cuDNN, and TensorRT resulting in no perception recognition results. This may occur when nvidia driver is updated by apt upgrade.</p> <pre><code>hyt@dpc1909014-2204:~/ros_ws/awf$ ros2 launch lidar_centerpoint lidar_centerpoint.launch.xml model_name:=centerpoint_tiny model_path:=/home/hyt/autoware_data/lidar_centerpoint model_param_path:=$(ros2 pkg prefix lidar_centerpoint --share)/config/centerpoint_tiny.param.yaml build_only:=true\n[INFO] [launch]: All log files can be found below /home/hyt/.ros/log/2024-01-22-14-36-04-069409-dpc1909014-2204-3835027\n[INFO] [launch]: Default logging verbosity is set to INFO\n[INFO] [lidar_centerpoint_node-1]: process started with pid [3835028]\n[lidar_centerpoint_node-1] 1705901764.307868 [77] lidar_cent: determined enp4s0 (udp/10.0.53.59) as highest quality interface, selected for automatic interface.\n[lidar_centerpoint_node-1] terminate called after throwing an instance of 'thrust::system::system_error'\n[lidar_centerpoint_node-1]   what():  This program was not compiled for SM 75\n[lidar_centerpoint_node-1] : cudaErrorInvalidDevice: invalid device ordinal\n[ERROR] [lidar_centerpoint_node-1]: process has died [pid 3835028, exit code -6, cmd '/home/hyt/ros_ws/awf/install/lidar_centerpoint/lib/lidar_centerpoint/lidar_centerpoint_node --ros-args -r __node:=lidar_centerpoint --params-file /tmp/launch_params_60_o26mq --params-file /tmp/launch_params_79jodq9o --params-file /tmp/launch_params_spwl7uq2 --params-file /tmp/launch_params_ur_yt_y2 --params-file /tmp/launch_params_iqs0hf9o --params-file /tmp/launch_params_t6bo4aow --params-file /tmp/launch_params_ufdn98_7 --params-file /tmp/launch_params_7m7aj130 --params-file /tmp/launch_params_yr4emr64 --params-file /tmp/launch_params_u4_e0ngh --params-file /home/hyt/ros_ws/awf/install/lidar_centerpoint/share/lidar_centerpoint/config/centerpoint_tiny.param.yaml --params-file /home/hyt/ros_ws/awf/install/lidar_centerpoint/share/lidar_centerpoint/config/detection_class_remapper.param.yaml -r ~/input/pointcloud:=/sensing/lidar/pointcloud -r ~/output/objects:=objects'].\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area-1-3","title":"Correction method, Check area 1-3","text":"<p>Check to see if <code>cudaErrorInvalidDevice: invalid device ordinal</code> is not showing. If so, reinstall nvidia-driver, cuda, cuDNN, and TensorRT.</p> <pre><code>sudo apt-mark unhold cuda-*\nsudo apt-mark unhold nvidia-*\nsudo apt-mark unhold libcudnn*\nsudo apt-mark unhold libnv*\n\nsudo apt purge cuda-*\nsudo apt purge nvidia-*\nsudo apt purge libcudnn*\nsudo apt purge libnv*\n\n# install nvidia driver and run Autoware's setup-dev-env.sh\n</code></pre>"},{"location":"trouble_shooting/#cause-2","title":"Cause 2","text":"<p>Autoware is outputting the topic to be evaluated, but the node cannot subscribe.</p>"},{"location":"trouble_shooting/#example-2-1","title":"Example 2-1","text":"<p>Not obtained due to QoS mismatch</p> <pre><code>[component_container_mt-13] [WARN 1633081042.510824100] [localization.util.random_downsample_filter]: New subscription discovered on topic '/localization/util/downsample/pointcloud', requesting incompatible QoS. No messages will be sent to it. Last incompatible policy: RELIABILITY_QOS_POLICY\n[component_container_mt-19] [WARN 1633081042.593132498] [sensing.lidar.occupancy_grid_map_outlier_filter]: New subscription discovered on topic '/sensing/lidar/no_ground/pointcloud', requesting incompatible QoS. No messages will be sent to it. Last incompatible policy: RELIABILITY_QOS_POLICY\n[component_container_mt-19] [WARN 1633081042.597116410] [sensing.lidar.concatenate_data]: New subscription discovered on topic '/sensing/lidar/concatenated/pointcloud', requesting incompatible QoS. No messages will be sent to it. Last incompatible policy: RELIABILITY_QOS_POLICY\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area-2-1","title":"Correction method, Check area 2-1","text":"<p>Search for QoS in the terminal or console.log.</p> <p>Check that the version of Autoware and the version of driving_log_replayer_v2 are compatible. If you are experiencing this problem using Autoware Foundation main and driving_log_replayer_v2 main, please report it in a github issue.</p>"},{"location":"trouble_shooting/#example-2-2","title":"Example 2-2","text":"<p>Not retrieved due to message type mismatch. This occurs because the type output by Autoware is different from the type expected by driving_log_replayer_v2.</p> <p>In June 2024, autoware_auto_msg was changed to autoware_msg. As a result, if the version of autoware and the version of driving_log_replayer_v2 do not correspond, this message will appear.</p> <pre><code>[ros2-67] [ERROR] [1717610261.542314281] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610261.721551659] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610261.903905941] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610262.084860123] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610262.263855979] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610262.442275790] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area-2-2","title":"Correction method, Check area 2-2","text":"<p>If there are major functionality changes, the required Autoware features (PR numbers, etc.) are listed in driving_log_replayer_v2's ReleaseNotes.md. Check if the required functions are included in the Autoware you are using.</p> <p>If you are using Autoware Foundation's main and driving_log_replayer_v2's main and are experiencing this issue, please report it in an issue on github.</p>"},{"location":"trouble_shooting/#unusually-low-number-of-evaluations","title":"Unusually low number of evaluations","text":""},{"location":"trouble_shooting/#cause-1_2","title":"Cause 1","text":"<p>Due to insufficient PC performance, Autoware is not able to publish the topic at the required period (10 Hz for point clouds).</p>"},{"location":"trouble_shooting/#example-1_1","title":"Example 1","text":"<pre><code>\u276f ros2 topic hz /perception/obstacle_segmentation/pointcloud\n1718083964.779455 [77]       ros2: determined eno1 (udp/10.0.55.137) as highest quality interface, selected for automatic interface.\naverage rate: 5.619\n min: 0.109s max: 0.207s std dev: 0.03246s window: 7\naverage rate: 5.333\n min: 0.109s max: 0.214s std dev: 0.02783s window: 12\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area1","title":"Correction method, Check area1","text":"<p>Check with ros2 topic hz to see if the target topic is being output at the expected period. Note that if play_rate is 0.5, 10*0.5=5, which is normal.</p> <p>If not, lower the play_rate argument</p> <pre><code>ros2 launch driving_log_replayer_v2 driving_log_replayer_v2 scenario_path:=$HOME/driving_log_replayer_v2/sample.yaml play_rate:=0.2\n</code></pre>"},{"location":"trouble_shooting/#cause-2_1","title":"Cause 2","text":"<p>The topic does not appear at the beginning of the simulation, but appears at the end of the simulation. If the ml model has not been converted to an engine in advance, the engine conversion starts when the simulation is executed, and the topic appears after the engine conversion is finished.</p>"},{"location":"trouble_shooting/#example2","title":"Example2","text":"<pre><code>[component_container_mt-52] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +894, GPU +174, now: CPU 1009, GPU 852 (MiB)\n[component_container_mt-52] [I] [TRT] ----------------------------------------------------------------\n[component_container_mt-52] [I] [TRT] Input filename:   /home/autoware/autoware_data/traffic_light_classifier/traffic_light_classifier_mobilenetv2_batch_6.onnx\n[component_container_mt-52] [I] [TRT] ONNX IR version:  0.0.8\n[component_container_mt-52] [I] [TRT] Opset version:    11\n[component_container_mt-52] [I] [TRT] Producer name:    pytorch\n[component_container_mt-52] [I] [TRT] Producer version: 1.13.1\n[component_container_mt-52] [I] [TRT] Domain:\n[component_container_mt-52] [I] [TRT] Model version:    0\n[component_container_mt-52] [I] [TRT] Doc string:\n[component_container_mt-52] [I] [TRT] ----------------------------------------------------------------\n[component_container_mt-52] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 116, GPU 678 (MiB)\n\n[component_container_mt-52] [I] [TRT] Applying optimizations and building TRT CUDA engine. Please wait for a few minutes...\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area-2","title":"Correction method, Check area 2","text":"<p>Check if the terminal or console.log outputs a log like the one shown in the example. If so, convert the engine file from onnx in advance before evaluation by driving_log_replayer_v2.</p> <p>Start logging_simulator.launch.xml with \u201cpermission:=true\u201d and leave it for a while. Or, launch a launch that builds only models.</p> <pre><code># Start logging_simulator.launch.xml and leave it for a while.\nros2 launch autoware_launch logging_simulator.launch.xml map_path:=$HOME/autoware_map/sample-map-planning vehicle_model:=sample_vehicle sensor_model:=sample_sensor_kit\n\n# launch lidar_centerpoint with build_only option\nros2 launch lidar_centerpoint lidar_centerpoint.launch.xml model_name:=centerpoint_tiny model_path:=$HOME/autoware_data/lidar_centerpoint model_param_path:=$(ros2 pkg prefix lidar_centerpoint --share)/config/centerpoint_tiny.param.yaml build_only:=true\n</code></pre>"},{"location":"trouble_shooting/#not-terminating-or-terminating-in-the-middle-of-the-process","title":"Not terminating or terminating in the middle of the process","text":""},{"location":"trouble_shooting/#cause_1","title":"Cause","text":"<p>An exception occurs due to unintended input data, etc., and the node stops. or terminate.</p>"},{"location":"trouble_shooting/#example_1","title":"Example","text":"<p>The contents of the object in PERCEPTION were not as expected and an exception was output.</p> <pre><code>[perception_evaluator_node.py-115] [ERROR] [1711460672.978143229] [driving_log_replayer_v2.perception_evaluator]: Unexpected footprint length: len(perception_object.shape.footprint.points)=2\n[perception_evaluator_node.py-115] Exception in thread Thread-2 (run_func):\n[perception_evaluator_node.py-115] Traceback (most recent call last):\n[perception_evaluator_node.py-115]   File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n[perception_evaluator_node.py-115]     self.run()\n[perception_evaluator_node.py-115]   File \"/usr/lib/python3.10/threading.py\", line 953, in run\n[perception_evaluator_node.py-115]     self._target(*self._args, **self._kwargs)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/lib/python3.10/site-packages/tf2_ros/transform_listener.py\", line 95, in run_func\n[perception_evaluator_node.py-115]     self.executor.spin()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 294, in spin\n[perception_evaluator_node.py-115]     self.spin_once()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 739, in spin_once\n[perception_evaluator_node.py-115]     self._spin_once_impl(timeout_sec)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 728, in _spin_once_impl\n[perception_evaluator_node.py-115]     handler, entity, node = self.wait_for_ready_callbacks(timeout_sec=timeout_sec)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 711, in wait_for_ready_callbacks\n[perception_evaluator_node.py-115]     return next(self._cb_iter)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 612, in _wait_for_ready_callbacks\n[perception_evaluator_node.py-115]     raise ExternalShutdownException()\n[perception_evaluator_node.py-115] rclpy.executors.ExternalShutdownException\n[ros2-117] [INFO] [1711460673.168213400] [rosbag2_recorder]: Subscribed to topic '/driving_log_replayer_v2/marker/results'\n[ros2-117] [INFO] [1711460673.174638594] [rosbag2_recorder]: Subscribed to topic '/driving_log_replayer_v2/marker/ground_truth'\n[simple_object_merger_node-69] [INFO] [1711460673.191825620] [sensing.radar.simple_object_merger]: waiting for object msg...\n[perception_evaluator_node.py-115] Traceback (most recent call last):\n[perception_evaluator_node.py-115]   File \"/home/autoware/autoware.proj/install/driving_log_replayer_v2/lib/driving_log_replayer_v2/perception_evaluator_node.py\", line 336, in &lt;module&gt;\n[perception_evaluator_node.py-115]     main()\n[perception_evaluator_node.py-115]   File \"/home/autoware/autoware.proj/install/driving_log_replayer_v2/local/lib/python3.10/dist-packages/driving_log_replayer_v2/evaluator.py\", line 448, in wrapper\n[perception_evaluator_node.py-115]     rclpy.shutdown()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/__init__.py\", line 126, in shutdown\n[perception_evaluator_node.py-115]     _shutdown(context=context)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/utilities.py\", line 58, in shutdown\n[perception_evaluator_node.py-115]     return context.shutdown()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/context.py\", line 100, in shutdown\n[perception_evaluator_node.py-115]     raise RuntimeError('Context must be initialized before it can be shutdown')\n[perception_evaluator_node.py-115] RuntimeError: Context must be initialized before it can be shutdown\n[perception_evaluator_node.py-115] The following exception was never retrieved: Expected BOUNDING_BOX, but got polygon, which should have footprint.\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area_1","title":"Correction method, Check area","text":"<p>Search the terminal you started or console.log for the string of <code>evaluator</code> to see if an exception is output as shown in the example.</p>"},{"location":"use_case/all_components/","title":"Evaluate All Components","text":"<p>Run all components of Autoware to test whether the topic is output correctly and whether the output rate is stable.</p>"},{"location":"use_case/all_components/#execution-method","title":"Execution method","text":"<p>No evaluation is performed, only recording the BAG file for post-analysis.</p> <p>Launching the file executes the following steps:</p> <ol> <li>Execute launch of <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data output from input rosbag and the each component outputs topics.</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the bag record is terminated.</li> </ol>"},{"location":"use_case/all_components/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<ul> <li>sensing: true</li> <li>perception: true</li> <li>planning: true</li> <li>control: true</li> <li>localization: true</li> <li>pose_source: ndt</li> <li>twist_source: gyro_odom</li> </ul>"},{"location":"use_case/all_components/#simulation","title":"simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/all_components/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /localization/kinematic_state nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>The vehicle topics can be included instead of CAN.</p> Topic name Data type /localization/kinematic_state nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_auto_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_auto_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_auto_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_auto_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_auto_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/all_components/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/all_components/#evaluation","title":"evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/all_components/#scenario-format","title":"Scenario Format","text":"<p>See sample</p>"},{"location":"use_case/all_components/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>The contents of the result file are always the same.</p> <p>See sample</p>"},{"location":"use_case/annotationless_perception/","title":"Evaluate Annotationless Perception","text":"<p>Evaluate Autoware's recognition features (perception) without annotations using the perception_online_evaluator.</p> <p>Requires Autoware with the following PR features. https://github.com/autowarefoundation/autoware.universe/pull/6556</p>"},{"location":"use_case/annotationless_perception/#evaluation-method","title":"Evaluation method","text":"<p>Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>annotationless_perception_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data output from input rosbag and the perception module performs recognition.</li> <li>The perception_online_evaluator publishes diagnostic topic to <code>/perception/perception_online_evaluator/metrics</code></li> <li>The evaluation node subscribes to the topic and evaluates data. The result is dumped into a file.</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/annotationless_perception/#evaluation-results","title":"Evaluation results","text":"<p>The output topic of perception_online_evaluator is in the form of the following sample. topic sample</p> <p>For each subscription, the following judgment results are output for each recognition class.</p> <p>If all classes are normal, the test is successful.</p>"},{"location":"use_case/annotationless_perception/#normal","title":"Normal","text":"<p>The following two values specified in the scenario or launch argument are used to judge</p> <ul> <li>Threshold</li> <li>PassRange(Coefficient to correct threshold)</li> </ul> <p>Success or failure is determined for each status.name in <code>/perception/perception_online_evaluator/metrics</code> according to the following rules. Items for which no threshold is set (min, max, mean) are always judged as normal. Only those items for which a threshold is specified are subject to evaluation.</p>"},{"location":"use_case/annotationless_perception/#min","title":"min","text":"<p>If <code>threshold * lower_limit</code> &lt;= <code>minimum value of min</code> &lt;= <code>threshold * upper_limit</code>, it is assumed to be normal.</p>"},{"location":"use_case/annotationless_perception/#max","title":"max","text":"<p>If <code>threshold * lower_limit</code> &lt;= <code>maximum value of max</code> &lt;= <code>threshold * upper_limit</code>, it is assumed to be normal.</p> <p>Lower limit recommended to be 0.0</p>"},{"location":"use_case/annotationless_perception/#mean","title":"mean","text":"<p>If <code>threshold * lower_limit</code> &lt;= <code>average value of mean</code> &lt;= <code>threshold * upper_limit</code>, it is assumed to be normal.</p>"},{"location":"use_case/annotationless_perception/#metric_value","title":"metric_value","text":"<p>If <code>threshold * lower_limit</code> &lt;= <code>value of metric_value</code> &lt;= <code>threshold * upper_limit</code>, it is assumed to be normal. metric_value is determined by the current topic value only and does not update the values of min, max, and mean metrics.</p> <p>An illustration is shown below.</p> <p></p>"},{"location":"use_case/annotationless_perception/#error","title":"Error","text":"<p>When the normal condition is not met</p>"},{"location":"use_case/annotationless_perception/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /perception/perception_online_evaluator/metrics diagnostic_msgs/msg/DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"use_case/annotationless_perception/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> <li>use_perception_online_evaluator: true</li> </ul>"},{"location":"use_case/annotationless_perception/#simulation","title":"simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/annotationless_perception/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /localization/kinematic_state nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>The vehicle topics can be included instead of CAN.</p> Topic name Data type /localization/kinematic_state nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_auto_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_auto_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_auto_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_auto_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_auto_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/annotationless_perception/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/annotationless_perception/#evaluation","title":"evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/annotationless_perception/#scenario-format","title":"Scenario Format","text":"<p>See sample</p>"},{"location":"use_case/annotationless_perception/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample</p> <p>The format of each frame and the metrics format are shown below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <pre><code>{\n  \"Frame\": {\n    \"Ego\": {},\n    \"OBJECT_CLASSIFICATION\": {\n      // Recognized class\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" }, // The results for Total and Frame are the same. The same values are output to make the data structure the same as other evaluations.\n      \"Info\": {\n        \"name_min_max_mean\": { \"min\": \"min value\", \"max\": \"max value\", \"mean\": \"average value\" },\n        \"name_metric_value\": { \"metric_value\": \"value\"},\n        ...\n      },\n      \"Metrics\": {\n        \"name_min_max_mean\": {\n          \"min\": \"Minimum value of min\",\n          \"max\": \"Maximum value of max\",\n          \"mean\": \"Average value of mean\"\n        },\n        ...\n      }\n    }\n  }\n}\n</code></pre> <p>See the figure below for the meaning of items</p> <p></p> <p></p>"},{"location":"use_case/ar_tag_based_localizer/","title":"Evaluate ArTagBasedLocalizer estimation","text":"<p>Evaluate whether Autoware's ArTagBasedLocalizer, a camera based pcd-less localization, is working stably.</p>"},{"location":"use_case/ar_tag_based_localizer/#evaluation-method","title":"Evaluation method","text":"<p>Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>ar_tag_based_localizer_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data input from prepared rosbag and performs localization estimation</li> <li>Evaluation node subscribes to Autoware's output topics, determines whether the outputs meet the criteria, and outputs the results</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/ar_tag_based_localizer/#availability-of-artagbasedlocalizer","title":"Availability of ArTagBasedLocalizer","text":"<p>We use the output from <code>ar_tag_based_localizer</code> via <code>/diagnostics</code> to evaluate whether ArTagBasedLocalizer is available.</p> <ul> <li><code>/diagnostics</code></li> </ul>"},{"location":"use_case/ar_tag_based_localizer/#evaluation-result","title":"Evaluation Result","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/ar_tag_based_localizer/#artagbasedlocalizer-availability-normal","title":"ArTagBasedLocalizer Availability Normal","text":"<p>Information related to the monitored topic is extracted from <code>/diagnostics</code> which Component State Monitor outputs. If the most recent information of \"Number of Detected AR Tags\" is greater than or equal to 0, it is considered as pass.</p>"},{"location":"use_case/ar_tag_based_localizer/#artagbasedlocalizer-availability-error","title":"ArTagBasedLocalizer Availability Error","text":"<p>The ArTagBasedLocalizer availability evaluation output is marked as <code>Error</code> when conditions for <code>ArTagBasedLocalizer Availability Normal</code> are not met.</p>"},{"location":"use_case/ar_tag_based_localizer/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs/msg/DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"use_case/ar_tag_based_localizer/#service-name-and-data-type-used-by-the-evaluation-node","title":"Service name and data type used by the evaluation node","text":"Service name Data type /localization/initialize autoware_internal_localization_msgs/srv/InitializeLocalization"},{"location":"use_case/ar_tag_based_localizer/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> <li>pose_source: artag</li> <li>twist_source: gyro_odom</li> </ul>"},{"location":"use_case/ar_tag_based_localizer/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/ar_tag_based_localizer/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>The following example shows the topic list available in evaluation input rosbag.</p> Topic name Data type /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/ar_tag_based_localizer/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must NOT be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/ar_tag_based_localizer/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/ar_tag_based_localizer/#scenario-format","title":"Scenario Format","text":"<p>See sample.</p>"},{"location":"use_case/ar_tag_based_localizer/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>Examples of each evaluation are described below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Availability Result example:</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre>"},{"location":"use_case/diagnostics/","title":"Evaluate Diagnostics","text":"<p>Evaluates whether diagnostics are at a specified level at a specified time.</p> <p>A similar evaluation is performance_diag, which is specialized for LiDAR. diagnostics_evaluator_node has only a simple function to evaluate level, but it supports arbitrary status.name.</p>"},{"location":"use_case/diagnostics/#evaluation-method","title":"Evaluation Method","text":"<p>Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>diagnostics_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data output from input rosbag and publishes <code>/diagnostics</code>.</li> <li>The evaluation node subscribes to the topic and evaluates data. The result is dumped into a file.</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/diagnostics/#evaluation-result","title":"Evaluation Result","text":"<p>If msg.status[0].hardware_id of the received msg matches the hardware_id specified in the scenario and msg.header.stamp meets the time specified in the scenario, it is evaluated. If the conditions for evaluation are not met, no log is output.</p>"},{"location":"use_case/diagnostics/#normal","title":"Normal","text":"<p>There exists a status in msg.status that satisfies the name and level specified in the scenario.</p>"},{"location":"use_case/diagnostics/#error","title":"Error","text":"<p>When the normal condition is not met</p>"},{"location":"use_case/diagnostics/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs::msg::DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"use_case/diagnostics/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<p>No (launch with default argument)</p> <p>To use /sensing/lidar/concatenated/pointcloud in the bag, add sensing:=false to the launch argument. If you want to use perception and planning from the bag as well, add \u201cperception:=false planning:=false\u201d to the \u201claunch\u201d argument.</p> <pre><code>ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=${daignostics_scenario_path} sensing:=false perception:=false planning:=false\n</code></pre>"},{"location":"use_case/diagnostics/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/diagnostics/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>Which topic is needed depends on what you want to do.</p>"},{"location":"use_case/diagnostics/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type -------- ----------------------- /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/diagnostics/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/diagnostics/#scenario-format","title":"Scenario Format","text":"<p>See sample.</p>"},{"location":"use_case/diagnostics/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>The result format is shown below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Success is determined when all evaluation conditions are met.</p> <pre><code>{\n  \"Frame\": {\n    \"Condition_IDNEX\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"TotalPassed\": \"Total number of topics that passed the evaluation criteria\",\n        \"Level\": \"Level of acquired status\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"use_case/eagleye/","title":"Evaluate Eagleye estimation","text":"<p>Evaluate whether Eagleye, a GNSS-IMU based map-less localization, is working stably.</p>"},{"location":"use_case/eagleye/#evaluation-method","title":"Evaluation method","text":"<p>Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>eagleye_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data input from prepared rosbag and performs localization estimation</li> <li>Evaluation node subscribes to Autoware's output topics, determines whether the outputs meet the criteria, and outputs the results</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/eagleye/#availability-of-eagleye","title":"Availability of Eagleye","text":"<p>We use the output from <code>eagleye_monitor</code> via <code>/diagnostics</code> to evaluate whether Eagleye is available.</p> <ul> <li><code>/diagnostics</code></li> </ul>"},{"location":"use_case/eagleye/#evaluation-result","title":"Evaluation Result","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/eagleye/#eagleye-availability-normal","title":"Eagleye Availability Normal","text":"<p>Information related to the monitored topic is extracted from <code>/diagnostics</code> which Component State Monitor outputs. If the most recent information is \"OK\", it is considered as pass.</p>"},{"location":"use_case/eagleye/#eagleye-availability-error","title":"Eagleye Availability Error","text":"<p>The Eagleye availability evaluation output is marked as <code>Error</code> when conditions for <code>Eagleye Availability Normal</code> are not met.</p>"},{"location":"use_case/eagleye/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs/msg/DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"use_case/eagleye/#service-name-and-data-type-used-by-the-evaluation-node","title":"Service name and data type used by the evaluation node","text":"Service name Data type /localization/initialize autoware_internal_localization_msgs/srv/InitializeLocalization"},{"location":"use_case/eagleye/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> <li>pose_source: eagleye</li> <li>twist_source: eagleye</li> </ul>"},{"location":"use_case/eagleye/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/eagleye/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>The following example shows the topic list available in evaluation input rosbag.</p> Topic name Data type /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/eagleye/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must NOT be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/eagleye/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/eagleye/#scenario-format","title":"Scenario Format","text":"<p>See sample.</p>"},{"location":"use_case/eagleye/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>Examples of each evaluation are described below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Availability Result example:</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre>"},{"location":"use_case/ground_segmentation/","title":"Evaluate Ground Segmentation","text":"<p>Evaluate the performance of the Ground Segmentation sub-component in Autoware, which is responsible for segmenting and removing ground points from the input point cloud.</p>"},{"location":"use_case/ground_segmentation/#ground-truth-data","title":"Ground Truth data","text":"<p>The Ground Truth data required for evaluation can be provided using the following method.</p>"},{"location":"use_case/ground_segmentation/#annotated_pcd","title":"annotated_pcd","text":"<p>This method uses the t4_dataset, which contains 3D semantic-segmentation annotations. (format)</p> <ol> <li>Use a nearest neighbor search to match the ground-removed point cloud with the point cloud in the t4_dataset that corresponds to <code>/sensing/lidar/concatenated/pointcloud</code> (stored as <code>dataset/data/LIDAR_CONCAT/*.pcd.bin</code>).</li> <li>Check each matched point to determine whether it belongs to ground or obstacle.</li> </ol>"},{"location":"use_case/ground_segmentation/#evaluation-method","title":"Evaluation method","text":"<p>Launching the file executes the following steps:</p> <ol> <li>Launch the commands <code>ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py</code> with necessary arguments.</li> <li>Autoware receives sensor data input from previously prepared rosbag and performs ground point cloud removal within the perception module.</li> <li>Record the output topics in the bag file</li> <li>After rosbag playback if finished, parse the recorded rosbag one message at a time and evaluate the target topic.</li> </ol>"},{"location":"use_case/ground_segmentation/#points-to-note-during-evaluation","title":"Points to note during evaluation","text":"<ul> <li>annotated_pcd mode   Since the evaluation process takes time, the playback rate of the rosbag needs to be reduced.   Example:   <code>ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=${scenario_file} play_rate:=0.1</code></li> </ul>"},{"location":"use_case/ground_segmentation/#evaluation-result","title":"Evaluation result","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/ground_segmentation/#normal","title":"Normal","text":"<p>If the Accuracy obtained through the evaluation meets or exceeds the Evaluation.Conditions.accuracy_min specified in the scenario, it is assumed to be normal.</p>"},{"location":"use_case/ground_segmentation/#error","title":"Error","text":"<p>When the normal condition is not met</p>"},{"location":"use_case/ground_segmentation/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> topic name Data type /sensing/lidar/concatenated/pointcloud \u3000\u3000 sensor_msgs/msg/PointCloud2 /perception/obstacle_segmentation/pointcloud sensor_msgs/msg/PointCloud2 <p>NOTE: the<code>/perception/obstacle_segmentation/pointcloud</code>topic can be modified by changing the <code>evaluation_target_topic</code> launch argument.</p> <p>Published topics:</p> topic name Data type - -"},{"location":"use_case/ground_segmentation/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> <li>sensing: false</li> <li>perception_mode: lidar</li> </ul>"},{"location":"use_case/ground_segmentation/#simulation","title":"simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/ground_segmentation/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"topic name Data type /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /tf tf2_msgs/msg/TFMessage"},{"location":"use_case/ground_segmentation/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/ground_segmentation/#evaluation","title":"evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/ground_segmentation/#scenario-format","title":"Scenario Format","text":"<p>See sample</p>"},{"location":"use_case/ground_segmentation/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample</p> <p>In ground segmentation, the evaluation results for Accuracy, Precision, Recall, Specificity, and F1-score are output for each frame.</p> <p>The format of each frame and the metrics format are shown below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <pre><code>{\n  \"GroundSegmentation\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n    \"Info\": {\n      \"TP\": \"The number of ground points recognized as ground\",\n      \"FP\": \"The number of obstacle points recognized as ground\",\n      \"TN\": \"The number of obstacle points recognized as obstacle\",\n      \"FN\": \"The number of ground points recognized as obstacle\",\n      \"Accuracy\": \"Accuracy value\",\n      \"Precision\": \"Precision value\",\n      \"Recall\": \"Recall value\",\n      \"Specificity\": \"Specificity value\",\n      \"F1-score\": \"F1-score value\"\n    }\n  }\n}\n</code></pre>"},{"location":"use_case/","title":"Evaluation Use Cases","text":"<p>This section describes how driving_log_replayer_v2 can be used for evaluation.</p>"},{"location":"use_case/#list-of-driving_log_replayer_v2-use-cases","title":"List of driving_log_replayer_v2 use cases","text":"<ul> <li>Localization</li> <li>YabLoc</li> <li>Eagleye</li> <li>AR-Tag Based Localizer</li> <li>Obstacle Segmentation</li> <li>Perception</li> <li>Performance Diag</li> <li>Annotationless Perception</li> <li>Traffic Light</li> <li>Perception 2D</li> <li>Planning Control</li> <li>Perception Reproducer</li> <li>Diagnostics</li> <li>GroundSegmentation</li> <li>AllComponents</li> </ul>"},{"location":"use_case/localization/","title":"Evaluate NDT estimation","text":"<p>Use case <code>localization</code> will evaluate the performance of NDT localization in Autoware. Driving Log Replayer runs the <code>logging_simulator</code> of Autoware to replay the scenario, and evaluation will run during and after the simulation. This pages explains how the simulation and the evaluation works for this use case.</p>"},{"location":"use_case/localization/#simulation-details","title":"Simulation Details","text":"<p>This section explains the details and requirements to run the simulation.</p>"},{"location":"use_case/localization/#scenario-format","title":"Scenario Format","text":"<p>See the sample scenario file.</p>"},{"location":"use_case/localization/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> <li>pose_source: ndt</li> <li>twist_source: gyro_odom</li> </ul>"},{"location":"use_case/localization/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>The input rosbag requires topics to function the localization component of Autoware.</p> <p>If you use CAN data from the ECU, you will need the following topics in your rosbag.</p> Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan <p>Or, you can use vehicle topics instead of CAN data.</p> Topic name Data type /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/localization/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it outputs twice so it should not be included in the bag.</p>"},{"location":"use_case/localization/#localization_evaluator_node","title":"localization_evaluator_node","text":"<p>Driving Log Replayer also launches a <code>localization_evaluator_node</code> with the <code>logging_simulator</code> to collect data for the evaluation.</p> <p>The <code>localization_evaluator_node</code> subscribes the following topics.</p> Topic name Data type /diagnostics diagnostic_msgs::msg::DiagnosticArray /localization/pose_estimator/transform_probability autoware_internal_debug_msgs::msg::Float32Stamped /localization/pose_estimator/nearest_voxel_transformation_likelihood autoware_internal_debug_msgs::msg::Float32Stamped /localization/pose_estimator/initial_to_result_relative_pose geometry_msgs::msg::PoseStamped /localization/pose_estimator/exe_time_ms autoware_internal_debug_msgs::msg::Float32Stamped /localization/pose_estimator/iteration_num autoware_internal_debug_msgs::msg::Int32Stamped /tf tf2_msgs/msg/TFMessage /localization/util/downsample/pointcloud sensor_msgs::msg::PointCloud2 /localization/pose_estimator/points_aligned sensor_msgs::msg::PointCloud2 <p>The <code>localization_evaluator_node</code> publishes the following topics.</p> Topic name Data type /driving_log_replayer_v2/localization/lateral_distance example_interfaces/msg/Float64 <p>The <code>localization_evaluator_node</code> calls the following services.</p> Service name Data type /localization/initialize autoware_internal_localization_msgs/srv/InitializeLocalization"},{"location":"use_case/localization/#evaluation-details","title":"Evaluation details","text":"<p>This use case can evaluate the following contents.</p> <ul> <li>NDT Availability</li> <li>NDT Convergence</li> <li>NDT Reliability</li> <li>Difference from the reference trajectory (position, twist and acceleration)</li> <li>Error rate of diagnostics</li> <li>Rise/fall timing of the diagnostics</li> </ul> <p>When you launch Driving Log Replayer, the evaluation will start with the procedure below.</p> <ol> <li>Launch the <code>localization_evaluator_node</code>, <code>logging_simulator.launch</code> and <code>ros2 bag play</code> command</li> <li>Autoware performs localization by the sensor data from the rosbag</li> <li>The <code>localization_evaluator_node</code> evaluates the NDT Availability, Convergence and Reliability meanwhile and record the results into a file.</li> <li>After the logging simulation is done, <code>autoware_localization_evaluation_scripts</code> will start and evaluate the difference from the reference trajectory, error rate of diagnostics and the rise/fall timing of the diagnostics.</li> <li>Summarize all results and then the program finishes automatically.</li> </ol> <p>If all the evaluation items turn to be Success, the entire evaluation is judged as Success.</p> <p>The following sections explain the details of each evaluation item.</p>"},{"location":"use_case/localization/#ndt-availability","title":"NDT Availability","text":"<p>This evaluation basically starts for any kind of scenario, but it doesn't only if you defined a <code>availability</code> condition in the <code>Conditions</code> of the scenario and set its <code>enable</code> parameter as <code>false</code>.</p> <p>Driving Log Replayer will evaluate the NDT Availability through <code>logging_simulator</code> by detecting these two cases.</p> <ul> <li>The <code>pointcloud_preprocessor</code> is failing due to such like runtime error. (Then the <code>ndt_scan_matcher</code> cannot subscribe LiDAR scan points.)</li> <li>The <code>ndt_scan_matcher</code> itself is failing due to such like runtime error.</li> </ul> <p>This can be done by monitoring the following topic using an Autoware package Component State Monitor.</p> <ul> <li>/localization/pose_estimator/exe_time_ms</li> </ul> <p>We use <code>/localization/pose_estimator/exe_time_ms</code> since this topic is being published constantly. For example, <code>/localization/pose_estimator/pose</code> will not be published when the NVTL or TP is lower than the score threshold and does not suit this purpose.</p> <p>This evaluation is judged as Success if <code>/localization/pose_estimator/exe_time_ms</code> is alive until the end of the <code>logging_simulator</code>, Fail if not.</p>"},{"location":"use_case/localization/#ndt-convergence","title":"NDT Convergence","text":"<p>This evaluation starts if a <code>Convergence</code> condition is defined in the <code>Conditions</code> of the scenario.</p> <pre><code>Evaluation:\n  Conditions:\n    Convergence:\n      AllowableDistance: 0.2 # Lateral distance to be considered convergence\n      AllowableExeTimeMs: 100.0 # If the NDT computation time is less than or equal to this value, it is considered successful.\n      AllowableIterationNum: 30 # If the number of NDT calculations is less than or equal to this value, it is considered a success.\n      PassRate: 95.0 # How much (%) of the evaluation attempts are considered successful.\n</code></pre> <p>This evaluation monitors these three topics through the <code>logging_simulator</code>.</p> Topic name Success condition /localization/pose_estimator/initial_to_result_relative_pose value of lateral factor &lt;= AllowableDistance /localization/pose_estimator/exe_time_ms value &lt;= AllowableExeTimeMs /localization/pose_estimator/iteration_num value &lt;= AllowableIterationNum <p>If all three conditions have been passed, the NDT will be marked as converged for that time frame. If the rate of convergence is equal or larger than the <code>PassRate</code>, this evaluation is judged as Success.</p>"},{"location":"use_case/localization/#ndt-reliability","title":"NDT Reliability","text":"<p>This evaluation starts if a <code>Reliability</code> condition is defined in the <code>Conditions</code> of the scenario.</p> <pre><code>Evaluation:\n  Conditions:\n    Reliability:\n      Method: NVTL # NVTL or TP which method to use for evaluation\n      AllowableLikelihood: 2.3 # If above this value, the localization reliability value is considered normal.\n      NGCount: 10 # If the reliability value is lower than the threshold value for more than this number in the sequence. the evaluation is considered to have failed.\n</code></pre> <p>This evaluation monitors the topic selected in the scenario during the <code>logging_simulator</code>.</p> Method Topic Name Success Condition TP /localization/pose_estimator/transform_probability value &gt;= AllowableLikelihood NVTL /localization/pose_estimator/nearest_voxel_transformation_likelihood value &gt;= AllowableLikelihood <p>If the value of the topic is equal or larger than the <code>AllowableLikelihood</code>, the NDT is assumed to be reliable. If the TP or NVTL is below <code>AllowableLikelihood</code> for a consecutive <code>NGCount</code> times in the simulation, the evaluation is judged as Fail, if not Success.</p>"},{"location":"use_case/localization/#difference-from-the-reference-trajectory","title":"Difference from the reference trajectory","text":"<p>This evaluation basically starts for any kind of scenario.</p> <p>After <code>logging_simulator</code> is done, the position, twist, and acceleration difference from the reference trajectory will be evaluated. See the actual implementation of <code>autoware_localization_evaluation_scripts</code> for details of such like the definition of the difference.</p> <p>The difference of the following factors will be evaluated</p> <ul> <li>Position</li> <li>Orientation</li> <li>Linear Velocity</li> <li>Angular Velocity</li> <li>Linear Acceleration</li> </ul> <p>You can choose which factor to evaluate or not by defining a <code>OverallCriteriaMask</code> in the scenario file and set true or false to <code>mean_relative_*</code>. If <code>OverallCriteriaMask</code> is not set in the scenario, the evaluator will set all factors to true by default. When all if the factors have small difference the evaluation is judged as Success, and Fail if not.</p> <pre><code>Evaluation:\n  Conditions:\n    OverallCriteriaMask: # Toggle the mask below to perform or not to perform evaluation of the according criteria. The evaluator will automatically set all to `true` if this block is not defined.\n      mean_relative_position: true\n      mean_relative_angle: true\n      mean_relative_linear_velocity: true\n      mean_relative_angular_velocity: true\n      mean_relative_acceleration: true\n      diagnostics_not_ok_rate: true\n</code></pre>"},{"location":"use_case/localization/#error-rate-of-diagnostics","title":"Error rate of diagnostics","text":"<p>This evaluation basically starts for any kind of scenario.</p> <p>After the <code>logging_simulator</code> is done <code>autoware_localization_evaluation_scripts</code> evaluates whether localization related diagnostics (listed below) are not publishing errors with a high rate.</p> <ul> <li>ndt_scan_matcher: scan_matching_status</li> <li>localization: ekf_localizer</li> <li>localization_error_monitor: ellipse_error_status</li> <li>localization: pose_instability_detector</li> </ul> <p>See the actual implementation of <code>autoware_localization_evaluation_scripts</code> for details.</p> <p>If the error rate is small enough for all diagnostics, the evaluation is judged as Success, and Fail if not.</p> <p>You can disable the evaluation of this item by making the <code>diagnostics_not_ok_rate</code> in the <code>OverallCriteriaMask</code> false. If <code>OverallCriteriaMask</code> is not set in the scenario, the evaluator will set it to true by default.</p> <pre><code>Evaluation:\n  Conditions:\n    OverallCriteriaMask: # Toggle the mask below to perform or not to perform evaluation of the according criteria. The evaluator will automatically set all to `true` if this block is not defined.\n      mean_relative_position: true\n      mean_relative_angle: true\n      mean_relative_linear_velocity: true\n      mean_relative_angular_velocity: true\n      mean_relative_acceleration: true\n      diagnostics_not_ok_rate: true\n</code></pre>"},{"location":"use_case/localization/#risefall-timing-of-the-diagnostics","title":"Rise/fall timing of the diagnostics","text":"<p>This evaluation starts if a <code>DiagnosticsFlagCheck</code> condition is defined in the <code>Conditions</code> of the scenario.</p> <pre><code>Evaluation:\n  Conditions:\n    DiagnosticsFlagCheck:\n      pose_is_passed_delay_gate: # name of the diagnostics to check\n        flag: rise # which flag to detect (`rise` or `fall`)\n        at_sec: 113 # The `sec` part of the expected time to rise/fall\n        at_nanosec: 750000000 # The `nanosec` part of the expected time to rise/fall\n      pose_no_update_count:\n        flag: rise\n        at_sec: 117\n        at_nanosec: 900000000\n</code></pre> <p>After the <code>logging_simulator</code> is done <code>autoware_localization_evaluation_scripts</code> evaluates whether localization related diagnostics rise or fall at an expected timing. See the actual implementation of <code>autoware_localization_evaluation_scripts</code> for details.</p> <p>If all the specified diagnostics have risen/fallen within +/- 0.2 seconds of the expected time (defined by <code>at_sec</code> and <code>at_nanosec</code>), the evaluation is judged as Success, and Fail if not. Also if the flag has risen/fallen much earlier than expected, the evaluation is judged as Fail.</p>"},{"location":"use_case/localization/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See the sample file.</p> <p>For NDT Availability, Convergence and Reliability you can have the following result frames</p> <p>Availability Result</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre> <p>Convergence Result</p> <pre><code>{\n  \"Convergence\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n    \"Info\": {\n      \"LateralDistance\": \"initial_to_result_relative_pose.pose.position.y\",\n      \"HorizontalDistance\": \"initial_to_result_relative_pose.pose.position\u306e\u6c34\u5e73\u8ddd\u96e2\u3002\u53c2\u8003\u5024\",\n      \"ExeTimeMs\": \"ndt\u306e\u8a08\u7b97\u306b\u304b\u304b\u3063\u305f\u6642\u9593\",\n      \"IterationNum\": \"ndt\u306e\u518d\u8a08\u7b97\u56de\u6570\"\n    }\n  }\n}\n</code></pre> <p>Reliability Result</p> <pre><code>{\n  \"Reliability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n    \"Info\": {\n      \"Value\": {\n        \"stamp\": {\n          \"sec\": \"stamp\u306e\u79d2\",\n          \"nanosec\": \"stamp\u306enano\u79d2\"\n        },\n        \"data\": \"NVTL or TP\u306e\u5024\"\n      },\n      \"Reference\": {\n        \"stamp\": {\n          \"sec\": \"stamp\u306e\u79d2\",\n          \"nanosec\": \"stamp\u306enano\u79d2\"\n        },\n        \"data\": \"\u8a55\u4fa1\u306b\u4f7f\u7528\u3057\u306a\u304b\u3063\u305f\u5c24\u5ea6\u3002\u53c2\u8003\u5024\u3002Value\u304cNVTL\u306a\u3089TP\u304c\u5165\u308b\"\n      }\n    }\n  }\n}\n</code></pre> <p>For the difference from the reference trajectory, Error rate of diagnostics, and Rise/fall timing of the diagnostics, all results will be summarized in the bottom the result.json file.</p> <pre><code>{\n  \"Result\": {\n    \"Success\": false,\n    \"Summary\": \"Failed: Convergence (Fail): 570 / 632 -&gt; 90.19%, Reliability (Fail): NVTL Sequential NG Count: 10 (Total Test: 632, Average: 2.46835, StdDev: 0.16043), NDT Availability (Success): NDT available, mean_position_norm=0.166 [m]|mean_angle_norm=0.032 [deg]|mean_linear_velocity_norm=0.003 [m/s]|mean_angular_velocity_norm=0.001 [rad/s]|localization__ekf_localizer 13.447 [%] is too large.|localization__pose_instability_detector 0.000 [%]|localization_error_monitor__ellipse_error_status 13.447 [%] is too large.|ndt_scan_matcher__scan_matching_status 57.177 [%] is too large.|Diagnostics flag 'pose_is_passed_delay_gate' OK.|Diagnostics flag 'pose_no_update_count' OK.\"\n  }\n}\n</code></pre>"},{"location":"use_case/obstacle_segmentation/","title":"Evaluate point cloud generation","text":"<p>Evaluate if the Autoware point cloud generation process (if there is a connection between sensing and perception nodes) runs, and if data is being published to the <code>/perception/obstacle_segmentation/pointcloud</code> topic as intended.</p> <p>The following evaluations are performed simultaneously to check if point cloud published by perception nodes is valid.</p> <ul> <li>Check whether vehicles, pedestrians and other traffic participants, annotated in advance, are detected (detection step).</li> <li>Check whether extra point clouds appear in the overlapping area between the lane and the polygons around the vehicle defined in the scenario (non_detection step).</li> </ul> <p>It is also possible not to evaluate if null is specified as the evaluation condition. In other words, evaluation can be performed in the following three modes.</p> <ol> <li>evaluate detection and non_detection at the same time</li> <li>evaluate only detection (NonDetection: null)</li> <li>Evaluate only non_detection (Detection: null)</li> </ol> <p>The recommended annotation tool is Deepen, but any tool that supports conversion to <code>t4_dataset</code> format can be used. Multiple annotation tools can be used as long as a conversion tool can be created.</p>"},{"location":"use_case/obstacle_segmentation/#evaluation-method","title":"Evaluation method","text":"<p>Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>obstacle_segmentation_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data output from input rosbag and outputs <code>/perception/obstacle_segmentation/pointcloud</code> topic.</li> <li>The evaluation node subscribes <code>/perception/obstacle_segmentation/pointcloud</code> topic and calculates the polygon of the non-detection area at the time specified in the header.</li> <li>The evaluation node passes the point cloud and the polygon of the non-detected area to perception_eval for evaluation. The result is dumped into a file.</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/obstacle_segmentation/#how-to-calculate-polygon-for-non-detectable-area","title":"How to calculate polygon for non-detectable area","text":"<p>The non-detect area is calculated as the area where the polygon given in the scenario overlaps with the road_lanelet. It is calculated according to the following steps:</p> <ol> <li>get the transform of map_to_base_link at the time of the header.stamp in pointcloud, and transform the polygon to the map coordinate system.</li> <li>get the road_lanelet in the range of search_range (see the figure below) from the point where the vehicle is.</li> <li>take the intersection of the road_lanelet and polygon obtained in step 2.</li> <li>return the array of polygons obtained in step 3 to the base_link coordinate system (to match the coordinate system to filter the pointcloud).</li> </ol> <p></p> <p>In step 2, by narrowing down to the lanelets in the range where polygons can exist, the intersection process with lanelets that are obvious to return empty polygons in step 3 is omitted.</p>"},{"location":"use_case/obstacle_segmentation/#evaluation-result","title":"Evaluation Result","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/obstacle_segmentation/#detection-normal","title":"Detection Normal","text":"<p>If all of the following conditions are met, the evaluation is reported as normal:</p> <ol> <li>A bounding box with the UUID specified in the scenario must contain a point cloud (topic <code>/perception/obstacle_segmentation/pointcloud</code>) with at least a number of points equal to the specified number.<ul> <li>If multiple UUIDs are specified, the condition must be satisfied for all the specified bounding boxes.</li> </ul> </li> <li>The output rate of the point cloud cannot be in error state (this data is provided by Autoware's diagnostic function). The default frequency value is 1.0Hz.</li> </ol>"},{"location":"use_case/obstacle_segmentation/#detection-warning","title":"Detection Warning","text":"<p>The state is achieved when the visibility of the bounding box with the UUID specified in the scenario is none (bounding box is occluded) and cannot be evaluated.</p>"},{"location":"use_case/obstacle_segmentation/#detection-error","title":"Detection Error","text":"<p>The detection state is <code>Error</code> when neither conditions for <code>Normal</code> nor <code>Warning</code> state cannot be met.</p>"},{"location":"use_case/obstacle_segmentation/#non-detection-normal","title":"Non-Detection Normal","text":"<p>The state is <code>Normal</code> when no point is contained in the non-detection area, which is calculated by the node in step 3 of the evaluation method.</p>"},{"location":"use_case/obstacle_segmentation/#non-detection-error","title":"Non-Detection Error","text":"<p>The state is <code>Error</code> when any point was found in the non-detection area.</p>"},{"location":"use_case/obstacle_segmentation/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /perception/obstacle_segmentation/pointcloud sensor_msgs/msg/PointCloud2 /diagnostics diagnostic_msgs/msg/DiagnosticArray /tf tf2_msgs/msg/TFMessage /planning/scenario_planning/status/stop_reasons tier4_planning_msgs/msg/StopReasonArray /planning/trajectory autoware_planning_msgs/msg/Trajectory <p>Published topics:</p> Topic name Data type /driving_log_replayer_v2/marker/detection visualization_msgs/msg/MarkerArray /driving_log_replayer_v2/marker/non_detection visualization_msgs/msg/MarkerArray /driving_log_replayer_v2/pcd/detection sensor_msgs/msg/PointCloud2 /driving_log_replayer_v2/pcd/non_detection sensor_msgs/msg/PointCloud2 /planning/mission_planning/goal geometry_msgs/msg/PoseStamped"},{"location":"use_case/obstacle_segmentation/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<ul> <li>localization: false</li> <li>control: false</li> <li>scenario_simulation: true</li> </ul>"},{"location":"use_case/obstacle_segmentation/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/obstacle_segmentation/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>Must contain the required topics in <code>t4_dataset</code> format.</p> <p>The vehicle's ECU CAN and sensors data topics are required for the evaluation to be run correctly. The following example shows the topic list available in evaluation input rosbag when multiple LiDARs.</p> Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /localization/kinematic_state Type: nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>The vehicle topics can be included instead of CAN.</p> Topic name Data type /localization/kinematic_state Type: nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/obstacle_segmentation/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/obstacle_segmentation/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/obstacle_segmentation/#scenario-format","title":"Scenario Format","text":"<p>See sample.</p>"},{"location":"use_case/obstacle_segmentation/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>In <code>obstacle_segmentation</code> evaluation scenario, two types of checks, detection (Detection) and non-detection (NonDetection), are evaluated. Although they are evaluated simultaneously, in one callback function, they are counted separately. The <code>Result</code> is <code>true</code> if both detection and non-detection evaluation steps have passed. Otherwise the <code>Result</code> is <code>false</code>.</p> <p>An example of evaluation is described below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <pre><code>{\n  \"Frame\": {\n    \"FrameName\": \"Frame number of t4_dataset used for evaluation\",\n    \"FrameSkip\": \"Number of times that an object was requested to be evaluated but the evaluation was skipped because there was no ground truth in the dataset within 75msec\",\n    \"StopReasons\": \"Reasons for stopping output by the Planning module. Reference value\",\n    \"TopicRate\": \"Result of diag indicating whether the output rate of the point cloud is normal or not.\",\n    \"Detection\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, Warn or Invalid\" },\n      \"Info\": {\n        \"DetectionSuccess or DetectionFail or DetectionWarn\": {\n          \"Annotation\": {\n            \"Scale\": {\n              \"x\": \"Length of bounding box in x-direction\",\n              \"y\": \"Length of bounding box in y-direction\",\n              \"z\": \"Length of bounding box in z-direction\"\n            },\n            \"Position\": {\n              \"position\": {\n                \"x\": \"Bounding box position x\",\n                \"y\": \"Bounding box position y\",\n                \"z\": \"Bounding box position z\"\n              },\n              \"orientation\": {\n                \"x\": \"Bounding box direction x\",\n                \"y\": \"Bounding box direction y\",\n                \"z\": \"Bounding box direction z\",\n                \"w\": \"Bounding box direction w\"\n              }\n            },\n            \"UUID\": \"UUID of the bounding box\",\n            \"StampFloat\": \"Bounding box unix_time[us] made into a float.\"\n          },\n          \"PointCloud\": {\n            \"NumPoints\": \"Number of point clouds contained within the bounding box.\",\n            \"Nearest\": \"[x,y,z] coordinates of the closest point in the bounding box from the base_link\",\n            \"Stamp\": {\n              \"sec\": \"Sec of header.stamp of the point cloud\",\n              \"nanosec\": \"NanoSec of header.stamp of the point cloud\"\n            }\n          }\n        }\n      }\n    },\n    \"NonDetection\": {\n      \"Result\": \"Success, Fail, or Invalid\",\n      \"Info\": {\n        \"PointCloud\": {\n          \"NumPoints\": \"Number of point clouds out in non-detected areas.\",\n          \"Distance\": {\n            \"0-1\": \"Number of point clouds out in non-detected areas between 0-1 m from base_link\",\n            \"x-x+1\": \"Distribution of point clouds appearing in non-detected areas by distance\",\n            \"99-100\": \"Number of point clouds out in non-detected areas between 99-100 m from base_link\"\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"use_case/perception/","title":"Evaluate perception","text":"<p>The performance of Autoware's recognition function (perception) is evaluated by calculating mAP (mean Average Precision) and other indices from the recognition results.</p> <p>The perception topic is saved when Autoware is executed. The evaluation is then performed during post-processing.</p> <p>The topic for pass/fail is based on the evaluation_task described in scenario.yaml. The topic to be analyzed can be specified from terminal arguments. If not specified, the default value is used.</p> <p>In addition, you can use planning_factor on planning_control. Please see this documents.</p>"},{"location":"use_case/perception/#preparation","title":"Preparation","text":"<p>In perception evaluation, machine learning pre-trained models are used. If the model is not prepared in advance, Autoware will not output recognition results. If no evaluation results are produced, check to see if this has been done correctly.</p>"},{"location":"use_case/perception/#downloading-model-files","title":"Downloading Model Files","text":"<p>Models are downloaded during Autoware setup. The method of downloading models depends on the version of Autoware you are using, so check which method is used. The following patterns exist.</p>"},{"location":"use_case/perception/#download-with-ansible","title":"Download with ansible","text":"<p>When you run the ansible setup script, you will see <code>Download artifacts? [y/N]</code>, type <code>y</code> and press enter (Autoware foundation's main branch use this method) https://github.com/autowarefoundation/autoware/blob/main/ansible/roles/artifacts/tasks/main.yaml</p>"},{"location":"use_case/perception/#automatically-downloaded-when-the-package-is-built","title":"Automatically downloaded when the package is built","text":"<p>If you are using a slightly older Autoware.universe, this is the one to use, until the commit hash of <code>13b96ad3c636389b32fea3a47dfb7cfb7813cadc</code>. lidar_centerpoint/CMakeList.txt</p>"},{"location":"use_case/perception/#conversion-of-model-files","title":"Conversion of model files","text":"<p>The downloaded onnx file is not to be used as-is, but to be converted to a TensorRT engine file for use. A conversion command is available, so source the autoware workspace and execute the command.</p> <p>Let's assume that autoware is installed in <code>$HOME/autoware</code>.</p> <pre><code>source $HOME/autoware/install/setup.bash\nros2 launch lidar_centerpoint lidar_centerpoint.launch.xml build_only:=true\n</code></pre> <p>When the conversion command finishes, the engine file is output. The output destination changes according to the model download method, so check that the output is in the appropriate directory.</p>"},{"location":"use_case/perception/#download-with-ansible_1","title":"Download with ansible","text":"<p>An example of the use of autowarefoundation's autoware.universe is shown below.</p> <p>The following file is output.</p> <pre><code>$HOME/autoware_data/lidar_centerpoint/pts_backbone_neck_head_centerpoint_tiny.engine\n$HOME/autoware_data/lidar_centerpoint/pts_voxel_encoder_centerpoint_tiny.engine\n</code></pre>"},{"location":"use_case/perception/#automatic-download-at-package-build-time","title":"Automatic download at package build time","text":"<p>The following file is output.</p> <pre><code>$HOME/autoware/install/lidar_centerpoint/share/lidar_centerpoint/data/pts_backbone_neck_head_centerpoint_tiny.engine\n$HOME/autoware/install/lidar_centerpoint/share/lidar_centerpoint/data/pts_voxel_encoder_centerpoint_tiny.engine\n</code></pre>"},{"location":"use_case/perception/#evaluation-method","title":"Evaluation method","text":"<p>First, complete the setup procedure described in Setup Instructions.</p> <p>Once the setup is finished, user can start the perception evaluation using the sample rosbag provided at <code>~/driving_log_replayer_v2/sample_dataset</code>. with the command:</p> <pre><code>ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py \\\n    scenario_path:=$HOME/driving_log_replayer_v2/perception.yaml \\\n    sensing:=false\n</code></pre> <p>or</p> <pre><code>ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py \\\n    scenario_path:=$HOME/driving_log_replayer_v2/perception.yaml \\\n    remap_arg:=\"/sensing/lidar/top/velodyne_packets,/sensing/lidar/left/velodyne_packets,/sensing/lidar/right/velodyne_packets\"\n</code></pre> <p>[!NOTE] sample rosbag includes packets to produce pointcloud and /sensing/lidar/concatenated/pointcloud. So it is necessary to either remap or not activate <code>sensing</code> to avoid topic duplication.</p> <p>This command will perform the following steps:</p> <ol> <li>launch the commands <code>logging_simulator.launch</code> and <code>ros2 bag play</code></li> <li>Autoware receives the sensor data output from the rosbag and the perception module recognizes it</li> <li>Record the output topics in the bag file</li> <li>After rosbag playback is finished, parse the saved rosbag one message at a time and evaluate the target topic.</li> </ol>"},{"location":"use_case/perception/#evaluation-results","title":"Evaluation results","text":"<p>The results are calculated for each subscription to judge pass/fail. The format and available states are described below.</p>"},{"location":"use_case/perception/#perception-normal","title":"Perception Normal","text":"<p>Satisfy Criteria in the Criterion tag of the scenario.</p> <p>The scenario.yaml of the sample is as follows,</p> <pre><code>Criterion:\n  - PassRate: 95.0 # How much (%) of the evaluation attempts are considered successful.\n    CriteriaMethod: num_gt_tp # refer https://github.com/tier4/driving_log_replayer_v2/blob/develop/driving_log_replayer_v2/driving_log_replayer_v2/criteria/perception.py#L136-L152\n    CriteriaLevel: hard # Level of criteria (perfect/hard/normal/easy, or custom value 0.0-100.0)\n    Filter:\n      Distance: 0.0-50.0 # [m] null [Do not filter by distance] or lower_limit-(upper_limit) [Upper limit can be omitted. If omitted value is 1.7976931348623157e+308]\n  - PassRate: 95.0 # How much (%) of the evaluation attempts are considered successful.\n    CriteriaMethod: num_gt_tp # refer https://github.com/tier4/driving_log_replayer_v2/blob/develop/driving_log_replayer_v2/driving_log_replayer_v2/criteria/perception.py#L136-L152\n    CriteriaLevel: easy # Level of criteria (perfect/hard/normal/easy, or custom value 0.0-100.0)\n    Filter:\n      Distance: 50.0- # [m] null [Do not filter by distance] or lower_limit-(upper_limit) [Upper limit can be omitted. If omitted value is 1.7976931348623157e+308]\n</code></pre> <ul> <li>For each subscription of topic to judge pass/fail, the number of objects in tp is hard (75.0%) or more for objects at a distance of 0.0-50.0[m]. Frame of Result becomes Success.</li> <li>For one subscription of topic to judge pass/fail, the number of objects in tp is easy (25.0%) or more for objects at a distance of 50.0-1.7976931348623157e+308[m]. Frame of Result becomes Success.</li> <li>If the condition <code>PassRate &gt;= Normal / Total Received * 100</code> is satisfied, the Total of Result becomes Success.</li> </ul>"},{"location":"use_case/perception/#perception-error","title":"Perception Error","text":"<p>The perception evaluation output is marked as <code>Error</code> when condition for <code>Normal</code> is not met.</p>"},{"location":"use_case/perception/#skipping-evaluation","title":"Skipping evaluation","text":"<p>Only add 1 to FrameSkip in the following cases. FrameSkip is a counter for the number of times evaluation is skipped.</p> <ul> <li>No Ground Truth exists within 75msec before or after the received object's header time.</li> <li>If the number of footprint.points of the received object is 1 or 2 (this condition will be removed when \"perception_eval\" is updated)</li> </ul>"},{"location":"use_case/perception/#skipping-evaluationnogtnoobject","title":"Skipping evaluation(NoGTNoObject)","text":"<ul> <li>When the Ground Truth and the recognition objects are filtered by the filter condition and not evaluated (when the content of the evaluation result PassFail object is empty).</li> </ul>"},{"location":"use_case/perception/#topic-name-and-data-type-used-by-evaluation-script","title":"Topic name and data type used by evaluation script","text":"<p>The topic to determine pass/fail is based on the evaluation_task defined in scenario.yaml.</p> evaluation_task Data type detection autoware_perception_msgs/msg/DetectedObjects tracking autoware_perception_msgs/msg/TrackedObjects prediction TBD fp_validation autoware_perception_msgs/msg/DetectedObjects <p>The topic to be analyzed, independent of pass/fail, can be defined with the terminal argument USE_CASE_ARGS.</p> Arguments Data type evaluation_detection_topic_regex autoware_perception_msgs/msg/DetectedObjects evaluation_tracking_topic_regex autoware_perception_msgs/msg/TrackedObjects evaluation_prediction_topic_regex TBD evaluation_fp_validation_topic_regex autoware_perception_msgs/msg/DetectedObjects <p>The results obtained through the evaluation are also written in rosbag.</p> Topic name Data type /driving_log_replayer_v2/marker/ground_truth visualization_msgs/msg/MarkerArray /driving_log_replayer_v2/marker/results visualization_msgs/msg/MarkerArray"},{"location":"use_case/perception/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> </ul> <p>NOTE: The <code>tf</code> in the bag is used to align the localization during annotation and simulation. Therefore, localization is invalid.</p>"},{"location":"use_case/perception/#dependent-libraries","title":"Dependent libraries","text":"<p>The perception evaluation step bases on the perception_eval library.</p>"},{"location":"use_case/perception/#division-of-roles-of-driving_log_replayer_v2-with-dependent-libraries","title":"Division of roles of driving_log_replayer_v2 with dependent libraries","text":"<p><code>driving_log_replayer_v2</code> package is in charge of the part of the relationship with ROS and the part that determines pass/fail. The actual perception evaluation is conducted in perception_eval library. The perception_eval is a ROS-independent library, it cannot receive ROS objects. Also, ROS timestamps use nanoseconds while the <code>t4_dataset</code> format is based on microseconds (because it uses <code>nuScenes</code>), so the values must be properly converted before using the library's functions.</p> <p><code>driving_log_replayer_v2</code> subscribes the topic output from the perception module of Autoware, converts it to the data format defined in perception_eval, and passes it on. It is also responsible for publishing and visualizing the evaluation results from perception_eval on proper ROS topic.</p> <p>perception_eval is in charge of the part that compares the detection results passed from <code>driving_log_replayer_v2</code> with ground truth data, calculates the index, and outputs the evaluations.</p>"},{"location":"use_case/perception/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/perception/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>Must contain the required topics in <code>t4_dataset</code> format.</p> <p>The vehicle's ECU CAN and sensors data topics are required for the evaluation to be run correctly.</p> <p>If more than one CAMERA is attached, all camera_info and image_rect_color_compressed should be included. In addition, /sensing/lidar/concatenated/pointcloud is remapped to avoid duplication depending on true or false of sensing.</p> Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>The vehicle topics can be included instead of CAN.</p> Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/perception/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/perception/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/perception/#scenario-format","title":"Scenario Format","text":"<p>There are two types of evaluation: use case evaluation and database evaluation. Use case evaluation is performed on a single dataset, while database evaluation uses multiple datasets and takes the average of the results for each dataset.</p> <p>In the database evaluation, the <code>vehicle_id</code> should be able to be set for each data set, since the calibration values may change. Also, it is necessary to set whether or not to activate the sensing module.</p> <p>See sample.</p>"},{"location":"use_case/perception/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>The evaluation results by perception_eval under the conditions specified in the scenario are output for each frame. Only the final line has a different format from the other lines since the final metrics are calculated after all data has been flushed.</p> <p>The format of each frame and the metrics format are shown below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Format of each frame:</p> <pre><code>{\n  \"Frame\": {\n    \"FrameName\": \"Frame number of t4_dataset used for evaluation\",\n    \"FrameSkip\": \"The total number of times the evaluation was skipped, which occurs when the evaluation of an object is requested but there is no Ground Truth in the dataset within 75msec, or when the number of footprint.points is 1 or 2.\",\n    \"criteria0\": {\n      // result of criteria 0, If the Ground Truth and recognition objects exist\n      \"PassFail\": {\n        \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n        \"Info\": {\n          \"TP\": \"Number of filtered objects determined to be TP\",\n          \"FP\": \"Number of filtered objects determined to be FP\",\n          \"FN\": \"Number of filtered objects determined to be FN\"\n        },\n        \"Objects\": {\n          // Evaluated objects information. See the [json schema](../../driving_log_replayer_v2/config/perception/object_output_schema.json) for details.\n        }\n      }\n    },\n    \"criteria1\": {\n      // result of criteria 1. If the Ground Truth and the recognition objects do not exist\n      \"NoGTNoObj\": \"Number of times that the Ground Truth and the recognition objects were filtered and could not be evaluated.\"\n    }\n  }\n}\n</code></pre> <p>Information Data Format:</p> <pre><code>{\n  \"Frame\": {\n    \"Info\": \"Information Message\",\n    \"FrameSkip\": \"Total number of times the evaluation was skipped. This occurs when you request the evaluation of an object but there is no ground truth value within 75msec in the dataset or footprint.points is 1 or 2.\"\n  }\n}\n</code></pre> <p>Warning Data Format:</p> <pre><code>{\n  \"Frame\": {\n    \"Warning\": \"Warning Message\",\n    \"FrameSkip\": \"The total number of times the evaluation was skipped, which occurs when the evaluation of an object is requested but there is no Ground Truth in the dataset within 75msec, or when the number of footprint.points is 1 or 2.\"\n  }\n}\n</code></pre> <p>Objects Data Format:</p> <p>See json schema</p> <p>Metrics Data Format:</p> <p>When the <code>evaluation_task</code> is detection or tracking</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"Score\": {\n        \"TP\": {\n          \"ALL\": \"TP rate for all labels\",\n          \"label0\": \"TP rate of label0\",\n          \"label1\": \"TP rate of label1\"\n        },\n        \"FP\": {\n          \"ALL\": \"FP rate for all labels\",\n          \"label0\": \"FP rate of label0\",\n          \"label1\": \"FP rate of label1\"\n        },\n        \"FN\": {\n          \"ALL\": \"FN rate for all labels\",\n          \"label0\": \"FN rate of label0\",\n          \"label1\": \"FN rate of label1\"\n        },\n        \"TN\": {\n          \"ALL\": \"TN rate for all labels\",\n          \"label0\": \"TN rate of label0\",\n          \"label1\": \"TN rate of label1\"\n        },\n        \"AP(Center Distance)\": {\n          \"ALL\": \"AP(Center Distance) rate for all labels\",\n          \"label0\": \"AP(Center Distance) rate of label0\",\n          \"label1\": \"AP(Center Distance) rate of label1\"\n        },\n        \"APH(Center Distance)\": {\n          \"ALL\": \"APH(Center Distance) rate for all labels\",\n          \"label0\": \"APH(Center Distance) rate of label0\",\n          \"label1\": \"APH(Center Distance) rate of label1\"\n        },\n        \"AP(IoU 2D)\": {\n          \"ALL\": \"AP(IoU 2D) rate for all labels\",\n          \"label0\": \"AP(IoU 2D) rate of label0\",\n          \"label1\": \"AP(IoU 2D) rate of label1\"\n        },\n        \"APH(IoU 2D)\": {\n          \"ALL\": \"APH(IoU 2D) rate for all labels\",\n          \"label0\": \"APH(IoU 2D) rate of label0\",\n          \"label1\": \"APH(IoU 2D) rate of label1\"\n        },\n        \"AP(IoU 3D)\": {\n          \"ALL\": \"AP(IoU 3D) rate for all labels\",\n          \"label0\": \"AP(IoU 3D) rate of label0\",\n          \"label1\": \"AP(IoU 3D) rate of label1\"\n        },\n        \"APH(IoU 3D)\": {\n          \"ALL\": \"APH(IoU 3D) rate for all labels\",\n          \"label0\": \"APH(IoU 3D) rate of label0\",\n          \"label1\": \"APH(IoU 3D) rate of label1\"\n        },\n        \"AP(Plane Distance)\": {\n          \"ALL\": \"AP(Plane Distance) rate for all labels\",\n          \"label0\": \"AP(Plane Distance) rate of label0\",\n          \"label1\": \"AP(Plane Distance) rate of label1\"\n        },\n        \"APH(Plane Distance)\": {\n          \"ALL\": \"APH(Plane Distance) rate for all labels\",\n          \"label0\": \"APH(Plane Distance) rate of label0\",\n          \"label1\": \"APH(Plane Distance) rate of label1\"\n        }\n      },\n      \"MOTA\": {\"https://github.com/tier4/autoware_perception_evaluation/blob/develop/docs/en/perception/metrics.md#tracking\"},\n      \"MOTA\": {\"https://github.com/tier4/autoware_perception_evaluation/blob/develop/docs/en/perception/metrics.md#tracking\"},\n      \"IDswitch\": {\"https://github.com/tier4/autoware_perception_evaluation/blob/develop/docs/en/perception/metrics.md#id-switch\"},\n      \"Error\": {\n        \"ALL\": {\n          \"average\": {\n            \"x\": \"x position\",\n            \"y\": \"y position\",\n            \"yaw\": \"yaw\",\n            \"length\": \"length\",\n            \"width\": \"width\",\n            \"vx\": \"x velocity\",\n            \"vy\": \"y velocity\",\n            \"nn_plane\": \"Nearest neighbor plane distance\"\n          },\n          \"rms\": {\n            \"x\": \"x position\",\n            \"y\": \"y position\",\n            \"yaw\": \"yaw\",\n            \"length\": \"length\",\n            \"width\": \"width\",\n            \"vx\": \"x velocity\",\n            \"vy\": \"y velocity\",\n            \"nn_plane\": \"Nearest neighbor plane distance\"\n          },\n          \"std\": {\n            \"x\": \"x position\",\n            \"y\": \"y position\",\n            \"yaw\": \"yaw\",\n            \"length\": \"length\",\n            \"width\": \"width\",\n            \"vx\": \"x velocity\",\n            \"vy\": \"y velocity\",\n            \"nn_plane\": \"Nearest neighbor plane distance\"\n          },\n          \"max\": {\n            \"x\": \"x position\",\n            \"y\": \"y position\",\n            \"yaw\": \"yaw\",\n            \"length\": \"length\",\n            \"width\": \"width\",\n            \"vx\": \"x velocity\",\n            \"vy\": \"y velocity\",\n            \"nn_plane\": \"Nearest neighbor plane distance\"\n          },\n          \"min\": {\n            \"x\": \"x position\",\n            \"y\": \"y position\",\n            \"yaw\": \"yaw\",\n            \"length\": \"length\",\n            \"width\": \"width\",\n            \"vx\": \"x velocity\",\n            \"vy\": \"y velocity\",\n            \"nn_plane\": \"Nearest neighbor plane distance\"\n          }\n        },\n        \"label0\": \"Error metrics for the label0\"\n      }\n    }\n  }\n}\n</code></pre> <p>When the <code>evaluation_task</code> is fp_validation</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"GroundTruthStatus\": {\n        \"UUID\": {\n          \"rate\": {\n            \"TP\": \"TP rate of the displyed UUID\",\n            \"FP\": \"FP rate of the displyed UUID\",\n            \"TN\": \"TN rate of the displyed UUID\",\n            \"FN\": \"FN rate of the displyed UUID\"\n          },\n          \"frame_nums\": {\n            \"total\": \"List of frame numbers, which GT is evaluated\",\n            \"TP\": \"List of frame numbers, which GT is evaluated as TP\",\n            \"FP\": \"List of frame numbers, which GT is evaluated as FP\",\n            \"TN\": \"List of frame numbers, which GT is evaluated as TN\",\n            \"FN\": \"List of frame numbers, which GT is evaluated as FN\"\n          }\n        }\n      },\n      \"Scene\": {\n        \"TP\": \"TP rate of the scene\",\n        \"FP\": \"FP rate of the scene\",\n        \"TN\": \"TN rate of the scene\",\n        \"FN\": \"FN rate of the scene\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"use_case/perception/#pickle-file","title":"pickle file","text":"<p>In database evaluation, it is necessary to replay multiple rosbags, but due to the ROS specification, it is impossible to use multiple bags in a single launch. Since one rosbag, i.e., one <code>t4_dataset</code>, requires one launch, it is necessary to execute as many launches as the number of datasets contained in the database evaluation.</p> <p>Since database evaluation cannot be done in a single launch, perception outputs a file <code>scene_result.pkl</code> in addition to <code>result.jsonl</code> file. A pickle file is a python object saved as a file, PerceptionEvaluationManager.frame_results of perception_eval. The dataset evaluation can be performed by reading all the objects recorded in the pickle file and outputting the index of the dataset's average.</p>"},{"location":"use_case/perception/#result-file-of-database-evaluation","title":"Result file of database evaluation","text":"<p>In the case of a database evaluation with multiple datasets in the scenario, a file named <code>database_result.json</code> is output to the results directory.</p> <p>The format is the same as the Metrics Data Format.</p>"},{"location":"use_case/perception_2d/","title":"Evaluate perception(Camera)","text":"<p>The performance of Autoware's recognition function (perception) is evaluated by calculating mAP (mean Average Precision) and other indices from the recognition results.</p> <p>Run the perception module and pass the output perception topic to the evaluation library for evaluation.</p>"},{"location":"use_case/perception_2d/#preparation","title":"Preparation","text":"<p>In perception evaluation, machine-learning pre-trained models are used. If the model is not prepared in advance, Autoware will not output recognition results. If no evaluation results are produced, check to see if this has been done correctly.</p>"},{"location":"use_case/perception_2d/#downloading-model-files","title":"Downloading Model Files","text":"<p>Models are downloaded during Autoware setup. The method of downloading models depends on the version of Autoware you are using, so check which method is used. The following patterns exist.</p>"},{"location":"use_case/perception_2d/#download-with-ansible","title":"Download with ansible","text":"<p>When you run the ansible setup script, you will see <code>Download artifacts? [y/N]</code>, type <code>y</code> and press enter (Autoware foundation's main branch use this method) https://github.com/autowarefoundation/autoware/blob/main/ansible/roles/artifacts/tasks/main.yaml</p>"},{"location":"use_case/perception_2d/#automatically-downloaded-when-the-package-is-built","title":"Automatically downloaded when the package is built","text":"<p>If you are using a slightly older Autoware.universe, this is the one to use, until the commit hash of <code>13b96ad3c636389b32fea3a47dfb7cfb7813cadc</code>. tensorrt_yolox/CMakeList.txt</p>"},{"location":"use_case/perception_2d/#conversion-of-model-files","title":"Conversion of model files","text":"<p>The downloaded onnx file is not to be used as-is, but to be converted to a TensorRT engine file for use. A conversion command is available, so source the autoware workspace and execute the command.</p> <p>Let's assume that autoware is installed in <code>$HOME/autoware</code>.</p> <pre><code>source $HOME/autoware/install/setup.bash\nros2 launch tensorrt_yolox yolox.launch.xml use_decompress:=false build_only:=true\n</code></pre> <p>When the conversion command finishes, the engine file is output. The output destination changes according to the model download method, so check that the output is in the appropriate directory.</p>"},{"location":"use_case/perception_2d/#download-with-ansible_1","title":"Download with ansible","text":"<p>The following file is output.</p> <pre><code>$HOME/autoware_data/tensorrt_yolox/yolox-sPlus-T4-960x960-pseudo-finetune.EntropyV2-int8-batch1.engine\n</code></pre>"},{"location":"use_case/perception_2d/#automatic-download-at-package-build-time","title":"Automatic download at package build time","text":"<p>The following file is output.</p> <pre><code>$HOME/autoware/install/tensorrt_yolox/share/tensorrt_yolox/data/yolox-sPlus-T4-960x960-pseudo-finetune.EntropyV2-int8-batch1.engine\n</code></pre>"},{"location":"use_case/perception_2d/#for-evaluation-on-a-single-pc-modify-the-launch-file","title":"(For evaluation on a single PC) modify the launch file","text":"<p>To evaluate on a single PC, it is necessary to modify launch to output the recognition results of the camera. Change launch as follows.</p> <pre><code>\u276f vcs diff src/\n.................................\ndiff --git a/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml b/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml\nindex 9ca8ea3df..a35e8d00f 100644\n--- a/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml\n+++ b/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml\n@@ -30,6 +30,14 @@\n   &lt;arg name=\"remove_unknown\" default=\"true\"/&gt;\n   &lt;arg name=\"trust_distance\" default=\"30.0\"/&gt;\n\n+  &lt;group&gt;\n+    &lt;include file=\"$(find-pkg-share tensorrt_yolox)/launch/yolox.launch.xml\" /&gt;\n+  &lt;/group&gt;\n+\n+  &lt;group&gt;\n+    &lt;include file=\"$(find-pkg-share bytetrack)/launch/bytetrack.launch.xml\" /&gt;\n+  &lt;/group&gt;\n+\n   &lt;!-- Jetson AGX --&gt;\n   &lt;!-- &lt;include file=\"$(find-pkg-share tensorrt_yolo)/launch/yolo.launch.xml\"&gt;\n     &lt;arg name=\"image_raw0\" value=\"$(var image_raw0)\"/&gt;\ndiff --git a/launch/tier4_perception_launch/launch/perception.launch.xml b/launch/tier4_perception_launch/launch/perception.launch.xml\nindex 0a2ef57f6..9a9b06379 100644\n--- a/launch/tier4_perception_launch/launch/perception.launch.xml\n+++ b/launch/tier4_perception_launch/launch/perception.launch.xml\n@@ -33,7 +33,7 @@\n   &lt;arg name=\"camera_info6\" default=\"/sensing/camera/camera6/camera_info\"/&gt;\n   &lt;arg name=\"image_raw7\" default=\"/sensing/camera/camera7/image_rect_color\"/&gt;\n   &lt;arg name=\"camera_info7\" default=\"/sensing/camera/camera7/camera_info\"/&gt;\n-  &lt;arg name=\"image_number\" default=\"6\" description=\"choose image raw number(0-7)\"/&gt;\n+  &lt;arg name=\"image_number\" default=\"1\" description=\"choose image raw number(0-7)\"/&gt;\n   &lt;arg name=\"use_vector_map\" default=\"true\" description=\"use vector map in prediction\"/&gt;\n   &lt;arg name=\"use_pointcloud_map\" default=\"true\" description=\"use pointcloud map in detection\"/&gt;\n   &lt;arg name=\"use_object_filter\" default=\"true\" description=\"use object filter\"/&gt;\ndiff --git a/perception/tensorrt_yolox/launch/yolox.launch.xml b/perception/tensorrt_yolox/launch/yolox.launch.xml\nindex b697b1f50..b9cb53102 100644\n--- a/perception/tensorrt_yolox/launch/yolox.launch.xml\n+++ b/perception/tensorrt_yolox/launch/yolox.launch.xml\n@@ -1,7 +1,7 @@\n &lt;?xml version=\"1.0\"?&gt;\n &lt;launch&gt;\n   &lt;arg name=\"input/image\" default=\"/sensing/camera/camera0/image_rect_color\"/&gt;\n-  &lt;arg name=\"output/objects\" default=\"/perception/object_recognition/detection/rois0\"/&gt;\n+  &lt;arg name=\"output/objects_yolox\" default=\"/perception/object_recognition/detection/rois0\"/&gt;\n   &lt;arg name=\"model_name\" default=\"yolox-tiny\"/&gt;\n   &lt;arg name=\"model_path\" default=\"$(find-pkg-share tensorrt_yolox)/data\"/&gt;\n   &lt;arg name=\"score_threshold\" default=\"0.35\"/&gt;\n@@ -16,7 +16,7 @@\n\n   &lt;node pkg=\"tensorrt_yolox\" exec=\"tensorrt_yolox_node_exe\" name=\"tensorrt_yolox\" output=\"screen\"&gt;\n     &lt;remap from=\"~/in/image\" to=\"$(var input/image)\"/&gt;\n-    &lt;remap from=\"~/out/objects\" to=\"$(var output/objects)\"/&gt;\n+    &lt;remap from=\"~/out/objects\" to=\"$(var output/objects_yolox)\"/&gt;\n     &lt;param name=\"score_threshold\" value=\"$(var score_threshold)\"/&gt;\n     &lt;param name=\"nms_threshold\" value=\"$(var nms_threshold)\"/&gt;\n     &lt;param name=\"model_path\" value=\"$(var model_path)/$(var model_name).onnx\"/&gt;\n</code></pre>"},{"location":"use_case/perception_2d/#evaluation-method","title":"Evaluation method","text":"<p>Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>perception_2d_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data output from input rosbag and outputs camera, and the perception module performs recognition.</li> <li>The evaluation node subscribes to <code>/perception/object_recognition/detection{/detected}/rois{camera_no}</code> and evaluates data. The result is dumped into a file.</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/perception_2d/#evaluation-results","title":"Evaluation results","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/perception_2d/#perception-normal","title":"Perception Normal","text":"<p>When the following conditions are satisfied by executing the evaluation function of perception_eval</p> <ol> <li>frame_result.pass_fail_result contains at least one object (<code>tp_object_results ! = [] and fp_object_results ! = [] and fn_objects ! = []</code>)</li> <li>no object fail (<code>frame_result.pass_fail_result.get_fail_object_num() == 0</code>)</li> </ol>"},{"location":"use_case/perception_2d/#perception-error","title":"Perception Error","text":"<p>The perception evaluation output is marked as <code>Error</code> when condition for <code>Normal</code> is not met.</p>"},{"location":"use_case/perception_2d/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /perception/object_recognition/detection/rois{camera_no} tier4_perception_msgs/msg/DetectedObjectsWithFeature /perception/object_recognition/detection/tracked/rois{camera_no} tier4_perception_msgs/msg/DetectedObjectsWithFeature <p>Published topics:</p> Topic name Data type - -"},{"location":"use_case/perception_2d/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> <li>perception_mode: camera_lidar_fusion</li> </ul> <p>NOTE: The <code>tf</code> in the bag is used to align the localization during annotation and simulation. Therefore, localization is invalid.</p>"},{"location":"use_case/perception_2d/#dependent-libraries","title":"Dependent libraries","text":"<p>The perception evaluation step bases on the perception_eval library.</p>"},{"location":"use_case/perception_2d/#division-of-roles-of-driving_log_replayer_v2-with-dependent-libraries","title":"Division of roles of driving_log_replayer_v2 with dependent libraries","text":"<p><code>driving_log_replayer_v2</code> package is in charge of the connection with ROS. The actual perception evaluation is conducted in perception_eval library. The perception_eval is a ROS-independent library, it cannot receive ROS objects. Also, ROS timestamps use nanoseconds while the <code>t4_dataset</code> format is based on milliseconds (because it uses <code>nuScenes</code>), so the values must be properly converted before using the library's functions.</p> <p><code>driving_log_replayer_v2</code> subscribes the topic output from the perception module of Autoware, converts it to the data format defined in perception_eval, and passes it on. It is also responsible for publishing and visualizing the evaluation results from perception_eval on proper ROS topic.</p> <p>perception_eval is in charge of the part that compares the detection results passed from <code>driving_log_replayer_v2</code> with ground truth data, calculates the index, and outputs the results.</p>"},{"location":"use_case/perception_2d/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/perception_2d/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>Must contain the required topics in <code>t4_dataset</code> format.</p> <p>The vehicle's ECU CAN and sensors data topics are required for the evaluation to be run correctly. The following example shows the topic list available in evaluation input rosbag when multiple LiDARs and Cameras are used in a real-world vehicle configuration.</p> <p>/sensing/lidar/concatenated/pointcloud is used when sensing:=false is added to the launch argument.</p> <p>If there is more than one CAMERA, include all on-board camera_info and image_rect_color_compressed.</p> Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>The vehicle topics can be included instead of CAN.</p> Topic name Data type /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/perception_2d/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/perception_2d/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/perception_2d/#scenario-format","title":"Scenario Format","text":"<p>There are two types of evaluation: use case evaluation and database evaluation. Use case evaluation is performed on a single dataset, while database evaluation uses multiple datasets and takes the average of the results for each dataset.</p> <p>In the database evaluation, the <code>vehicle_id</code> should be able to be set for each data set, since the calibration values may change. Also, it is necessary to set whether or not to activate the sensing module.</p> <p>See sample.</p>"},{"location":"use_case/perception_2d/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>The evaluation results by perception_eval under the conditions specified in the scenario are output for each frame. Only the final line has a different format from the other lines since the final metrics are calculated after all data has been flushed.</p> <p>The format of each frame and the metrics format are shown below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Format of each frame:</p> <pre><code>{\n  \"Frame\": {\n    \"CameraType\": \"Evaluated camera\",\n    \"FrameName\": \"Frame number of t4_dataset used for evaluation\",\n    \"FrameSkip\": \"Number of times that an object was requested to be evaluated but the evaluation was skipped because there was no ground truth in the dataset within 75msec\",\n    \"PassFail\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"TP\": \"Number of TPs\",\n        \"FP\": \"Number of FPs\",\n        \"FN\": \"Number of FNs\"\n      }\n    }\n  }\n}\n</code></pre> <p>Metrics Data Format:</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"Score\": {\n        \"TP\": {\n          \"ALL\": \"TP rate for all labels\",\n          \"label0\": \"TP rate of label0\",\n          \"label1\": \"TP rate of label1\"\n        },\n        \"FP\": {\n          \"ALL\": \"FP rate for all labels\",\n          \"label0\": \"FP rate of label0\",\n          \"label1\": \"FP rate of label1\"\n        },\n        \"FN\": {\n          \"ALL\": \"FN rate for all labels\",\n          \"label0\": \"FN rate of label0\",\n          \"label1\": \"FN rate of label1\"\n        },\n        \"TN\": {\n          \"ALL\": \"TN rate for all labels\",\n          \"label0\": \"TN rate of label0\",\n          \"label1\": \"TN rate of label1\"\n        },\n        \"AP(Center Distance)\": {\n          \"ALL\": \"AP(Center Distance) rate for all labels\",\n          \"label0\": \"AP(Center Distance) rate of label0\",\n          \"label1\": \"AP(Center Distance) rate of label1\"\n        },\n        \"APH(Center Distance)\": {\n          \"ALL\": \"APH(Center Distance) rate for all labels\",\n          \"label0\": \"APH(Center Distance) rate of label0\",\n          \"label1\": \"APH(Center Distance) rate of label1\"\n        },\n        \"AP(IoU 2D)\": {\n          \"ALL\": \"AP(IoU 2D) rate for all labels\",\n          \"label0\": \"AP(IoU 2D) rate of label0\",\n          \"label1\": \"AP(IoU 2D) rate of label1\"\n        },\n        \"APH(IoU 2D)\": {\n          \"ALL\": \"APH(IoU 2D) rate for all labels\",\n          \"label0\": \"APH(IoU 2D) rate of label0\",\n          \"label1\": \"APH(IoU 2D) rate of label1\"\n        }\n      },\n      \"ConfusionMatrix\": {\n        \"label0(GroundTruth)\": {\n          \"label0(Prediction)\": \"value\",\n          \"label1(Prediction)\": \"value\"\n        },\n        \"label1(GroundTruth)\": {\n          \"label0(Prediction)\": \"value\",\n          \"label1(Prediction)\": \"value\"\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"use_case/perception_2d/#pickle-file","title":"pickle file","text":"<p>In database evaluation, it is necessary to replay multiple rosbags, but due to the ROS specification, it is impossible to use multiple bags in a single launch. Since one rosbag, i.e., one <code>t4_dataset</code>, requires one launch, it is necessary to execute as many launches as the number of datasets contained in the database evaluation.</p> <p>Since database evaluation cannot be done in a single launch, perception outputs a file <code>scene_result.pkl</code> in addition to <code>result.jsonl</code> file. A pickle file is a python object saved as a file, PerceptionEvaluationManager.frame_results of perception_eval. The dataset evaluation can be performed by reading all the objects recorded in the pickle file and outputting the index of the dataset's average.</p>"},{"location":"use_case/perception_2d/#result-file-of-database-evaluation","title":"Result file of database evaluation","text":"<p>In the case of a database evaluation with multiple datasets in the scenario, a file named <code>database_result.json</code> is output to the results directory.</p> <p>The format is the same as the Metrics Data Format.</p>"},{"location":"use_case/perception_reproducer/","title":"Evaluate Perception Reproducer","text":"<p>Evaluate if the vehicle can complete the specified route under closed-loop conditions with perception data reproduced from rosbag. The perception_reproducer node reproduces perception objects from rosbag based on the current ego position, enabling closed-loop testing.</p>"},{"location":"use_case/perception_reproducer/#evaluation-method","title":"Evaluation Method","text":"<p>Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>perception_reproducer_evaluator_node</code>), <code>planning_simulator.launch</code> file and <code>perception_reproducer</code> node</li> <li>The <code>perception_reproducer</code> node reads perception objects from rosbag based on the current ego position and publishes them</li> <li>The vehicle starts driving when Autoware enters DRIVING state (ENGAGE)</li> <li>The evaluation node subscribes to the topics and evaluates if each criterion is met. The result is dumped into a file.</li> <li>When all pass conditions are met or any fail condition is triggered, the launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/perception_reproducer/#evaluation-result","title":"Evaluation Result","text":""},{"location":"use_case/perception_reproducer/#pass-conditions","title":"Pass Conditions","text":"<p>When all condition groups in <code>pass_conditions</code> meet ONCE, the test passes and terminates.</p>"},{"location":"use_case/perception_reproducer/#ego_kinematic_trigger","title":"ego_kinematic_trigger","text":"<p>Evaluate if the ego vehicle reaches the specified area.</p> <ul> <li>If there is an area condition in the scenario, the x,y position of ego is within the range from the x,y coordinates specified in the scenario.</li> <li>If there is a velocity condition in the scenario, the ego's velocity is within the range specified in the scenario.</li> <li>If there is an acceleration condition in the scenario, the ego's acceleration is within the range specified in the scenario.</li> </ul>"},{"location":"use_case/perception_reproducer/#time_wait_trigger","title":"time_wait_trigger","text":"<p>Evaluate if the specified wait time has elapsed.</p> <ul> <li>The condition is met when the elapsed time from activation reaches <code>wait_seconds</code>.</li> </ul>"},{"location":"use_case/perception_reproducer/#condition_group","title":"condition_group","text":"<p>Nested condition groups are supported. The group can be configured with <code>start_at</code> and <code>end_at</code> to control when it becomes active.</p>"},{"location":"use_case/perception_reproducer/#fail-conditions","title":"Fail Conditions","text":"<p>When any condition group in <code>fail_conditions</code> does NOT meet ONCE, the test fails and terminates after <code>terminated_after_fail_s</code> seconds.</p>"},{"location":"use_case/perception_reproducer/#metric","title":"metric","text":"<p>Evaluate metrics. Same as the planning_control use case.</p>"},{"location":"use_case/perception_reproducer/#diagnostic","title":"diagnostic","text":"<p>Evaluate diagnostics status. Same as the diagnostics use case.</p>"},{"location":"use_case/perception_reproducer/#planning_factor","title":"planning_factor","text":"<p>Evaluate planning factors. Same as the planning_control use case.</p>"},{"location":"use_case/perception_reproducer/#ego_kinematic","title":"ego_kinematic","text":"<p>Evaluate ego kinematic conditions (position, velocity, acceleration) continuously during the active period.</p> <ul> <li>If there is an area condition in the scenario, the x,y position of ego is within/outside the range from the x,y coordinates specified in the scenario.</li> <li>If there is a velocity condition in the scenario, the ego's velocity is within the range specified in the scenario.</li> <li>If there is an acceleration condition in the scenario, the ego's acceleration is within the range specified in the scenario.</li> </ul>"},{"location":"use_case/perception_reproducer/#condition_group_1","title":"condition_group","text":"<p>Nested condition groups are supported. The group can be configured with <code>start_at</code> and <code>end_at</code> to control when it becomes active.</p>"},{"location":"use_case/perception_reproducer/#output-file-for-evaluation-results","title":"Output File for Evaluation Results","text":"<p>In perception_reproducer, result.jsonl is created in the following three files. result.jsonl is always output, but pass_result.jsonl and fail_result.jsonl are only output when specified in the scenario.</p>"},{"location":"use_case/perception_reproducer/#resultjsonl","title":"result.jsonl","text":"<p>Output to output_dir/result.jsonl. Contains summarized results of pass and fail evaluations.</p> <p>When running with Evaluator, the success/failure is determined by referencing the last line of this file. Therefore, the final success/failure information that merges the results of pass_result.jsonl and fail_result.jsonl is written in post_process.</p>"},{"location":"use_case/perception_reproducer/#pass_resultjsonl","title":"pass_result.jsonl","text":"<p>Output to output_dir/result_archive/pass_result.jsonl. Contains pass condition evaluation results.</p>"},{"location":"use_case/perception_reproducer/#fail_resultjsonl","title":"fail_result.jsonl","text":"<p>Output to output_dir/result_archive/fail_result.jsonl. Contains fail condition evaluation results.</p>"},{"location":"use_case/perception_reproducer/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /localization/kinematic_state nav_msgs/msg/Odometry /localization/acceleration geometry_msgs/msg/AccelWithCovarianceStamped /control/control_evaluator/metrics tier4_metric_msg/msg/MetricArray /planning/planning_evaluator/metrics tier4_metric_msg/msg/MetricArray /system/processing_time/metrics tier4_metric_msg/msg/MetricArray /planning/planning_factors/** autoware_internal_planning_msgs/msg/PlanningFactorArray /diagnostics diagnostic_msgs/msg/DiagnosticArray /autoware/state autoware_system_msgs/msg/AutowareState <p>Published topics:</p> Topic name Data type /driving_log_replayer/perception_reproducer/results std_msgs/msg/String /driving_log_replayer/perception_reproducer/pass_results std_msgs/msg/String /driving_log_replayer/perception_reproducer/fail_results std_msgs/msg/String"},{"location":"use_case/perception_reproducer/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/perception_reproducer/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"<p>See perception_reproducer.</p>"},{"location":"use_case/perception_reproducer/#planning-simulator","title":"Planning Simulator","text":"<p>This use case uses <code>planning_simulator.launch</code> instead of <code>logging_simulator.launch</code> to enable closed-loop testing where the vehicle can actually drive.</p>"},{"location":"use_case/perception_reproducer/#perception-reproducer-node","title":"Perception Reproducer Node","text":"<p>The <code>perception_reproducer</code> node from <code>planning_debug_tools</code> package reproduces perception objects from rosbag based on the current ego position. For more details, see perception_reproducer.</p> <p>Configuration options:</p> <ul> <li><code>noise</code>: Apply perception noise to the objects</li> <li><code>reproduce_cool_down</code>: Cool down time for republishing (default: 80.0)</li> <li><code>tracked_object</code>: Publish tracked object</li> <li><code>search_radius</code>: Search radius for searching rosbag's ego odom messages (default: 1.5)</li> <li><code>pub_route</code>: Publish route created from rosbag (use when GoalPose is not specified)</li> </ul>"},{"location":"use_case/perception_reproducer/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/perception_reproducer/#scenario-format","title":"Scenario Format","text":"<p>See sample.</p>"},{"location":"use_case/perception_reproducer/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p>"},{"location":"use_case/performance_diag/","title":"Evaluate LiDAR diagnostics","text":"<p>Evaluate whether Autoware's diagnostics functionality behaves as expected.</p> <p>The following subjects of evaluation are currently supported:</p> <ul> <li>visibility: function to determine if visibility is impaired by fog, rain, etc.</li> <li>blockage: function to determine if leaves or other objects are attached to LiDAR and obstructing the measurement.</li> </ul>"},{"location":"use_case/performance_diag/#evaluation-method","title":"Evaluation Method","text":"<p>Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>performance_diag_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command.</li> <li>Autoware receives sensor data output from the input rosbag and outputs the<code>/diagnostics</code> topic.</li> <li>The evaluation node subscribes to <code>/diagnostics</code> topic, and evaluates data. The result is dumped into a file.</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/performance_diag/#visibility-evaluation","title":"visibility evaluation","text":"<p>The evaluation process confirms that more than a specified rate of ERRORs for limited visibility are generated for rosbag input data obtained under rainy conditions (naturally or artificially generated). Also, using data obtained during sunny weather, it is confirmed that ERRORs are never generated.</p> <p>The <code>status.name</code> in <code>/diagnostics</code> corresponding to <code>polar_voxel_outlier_filter: /sensing/lidar/.*: visibility_validation</code> is used for judgment.</p>"},{"location":"use_case/performance_diag/#blockage-evaluation","title":"blockage evaluation","text":"<p>For blockage evaluation, acquire data with LiDAR intentionally covered with a material that will not pass the laser beam (for example box). The evaluation confirms that ERROR for blockage is output more than a certain rate for the considered situation. The node will also confirm that no ERROR is generated for not covered LiDAR.</p> <p>The <code>status.name</code> in <code>/diagnostics</code> corresponding to <code>blockage_return_diag: /sensing/lidar/.*: blockage_validation</code> is used for judgment.</p>"},{"location":"use_case/performance_diag/#evaluation-result","title":"Evaluation Result","text":"<p>For each LiDAR diagnostic subscription, the evaluation judgment will be published on the topics described below:</p> <p>Each output of the evaluation can be considered a success or a failure depending on what you want to evaluate. You can change this by describing the type in the scenario.</p> <ul> <li>If the scenario type is TP (true positive), it succeeds if the <code>Diag</code> state is ERROR.</li> <li>If the scenario type is FP (false positive), it succeeds if the <code>Diag</code> state is not ERROR.</li> <li>If the scenario type is null, the test is omitted.</li> </ul>"},{"location":"use_case/performance_diag/#tp-normal","title":"TP Normal","text":"<p>If the scenario type is TP and the level in the diagnostic information is ERROR</p>"},{"location":"use_case/performance_diag/#tp-error","title":"TP Error","text":"<p>If the scenario type is TP and the level in the diagnostic information is not ERROR.</p>"},{"location":"use_case/performance_diag/#fp-normal","title":"FP Normal","text":"<p>If the scenario type is FP and the level in the diagnostic information is not ERROR.</p>"},{"location":"use_case/performance_diag/#fp-error","title":"FP Error","text":"<p>If the scenario type is FP and the level in the diagnostic information is ERROR.</p>"},{"location":"use_case/performance_diag/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /perception/obstacle_segmentation/pointcloud sensor_msgs/msg/PointCloud2 /diagnostics diagnostic_msgs/msg/DiagnosticArray /tf tf2_msgs/msg/TFMessage <p>Published topics:</p> Topic name Data type /driving_log_replayer_v2/visibility/value example_interfaces/msg/Float64 /driving_log_replayer_v2/visibility/level example_interfaces/msg/Byte /driving_log_replayer_v2/blockage/{lidar_name}/ground/ratio example_interfaces/msg/Float64 /driving_log_replayer_v2/blockage/{lidar_name}/sky/ratio example_interfaces/msg/Float64 /driving_log_replayer_v2/blockage/{lidar_name}/level example_interfaces/msg/Byte <p>{lidar_name} contains the name of the mounted lidar.</p>"},{"location":"use_case/performance_diag/#service-name-and-data-type-used-by-the-evaluation-node","title":"Service name and data type used by the evaluation node","text":"Service name Data type /localization/initialize autoware_internal_localization_msgs/srv/InitializeLocalization"},{"location":"use_case/performance_diag/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> </ul>"},{"location":"use_case/performance_diag/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/performance_diag/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>The vehicle's ECU CAN and sensors data topics are required for the evaluation to be run correctly. The following example shows the topic list available in evaluation input rosbag when multiple LiDARs are used in a real-world vehicle configuration.</p> Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>The vehicle topics can be included instead of CAN.</p> Topic name Data type /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport <p>NOTE: If localization is false (false by default), /tf is required.</p>"},{"location":"use_case/performance_diag/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/performance_diag/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/performance_diag/#scenario-format","title":"Scenario Format","text":"<p>See sample.</p>"},{"location":"use_case/performance_diag/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>In <code>performance_diag</code> evaluation scenario visibility and blockage are evaluated. The <code>Result</code> is <code>true</code> if both visibility and blockage evaluation steps have passed. Otherwise, the <code>Result</code> is <code>false</code>.</p> <p>The result format is shown below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Visibility Result example:</p> <pre><code>{\n  \"Visibility\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Invalid\" },\n    \"Info\": {\n      \"Level\": \"diag\u306e\u30ec\u30d9\u30eb\",\n      \"Visibility\": \"visibility\u306e\u5024\"\n    }\n  }\n}\n</code></pre> <p>Blockage Result example:</p> <pre><code>{\n  \"Blockage\": {\n    \"name of LiDAR1\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"Level\": \"Level of diag\",\n        \"GroundBlockageRatio\": \"Ground blockage ratio\",\n        \"GroundBlockageCount\": \"Ground blockage count. Reference\",\n        \"SkyBlockageRatio\": \"Sky blockage ratio\",\n        \"SkyBlockageCount\": \"Sky blockage count. Reference\"\n      }\n    },\n    \"name of LiDAR2\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"Level\": \"Level of diag\",\n        \"GroundBlockageRatio\": \"Ground blockage ratio\",\n        \"GroundBlockageCount\": \"Ground blockage count. Reference\",\n        \"SkyBlockageRatio\": \"Sky blockage ratio\",\n        \"SkyBlockageCount\": \"Sky blockage count. Reference\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"use_case/planning_control/","title":"Evaluate Planning Control","text":"<p>Evaluate if Metrics and PlanningFactors are output under specified conditions. If diagnostics is specified in include_use_case, diagnostics evaluation is also possible.</p>"},{"location":"use_case/planning_control/#evaluation-method","title":"Evaluation Method","text":"<p>Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>planning_control_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data output from bag and publishes metrics type and PlanningFactor type messages</li> <li>The evaluation node subscribes to the topics and evaluates if each criterion is met. The result is dumped into a file.</li> <li>When the playback of the rosbag is finished, the launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/planning_control/#evaluation-result","title":"Evaluation Result","text":""},{"location":"use_case/planning_control/#metric","title":"Metric","text":"<p>Use topics that utilize Metric.msg. Primarily intended for <code>/control/control_evaluator/metrics</code>, <code>/planning/planning_evaluator/metrics</code>, and <code>/system/processing_time/metrics</code>. The <code>name</code> within the topic being evaluated is specified by <code>metric_name</code>. The following conditions can be evaluated:</p> <ul> <li>Whether the specified metric is within the range specified in the scenario</li> <li>Whether the specified metric matches the value specified in the scenario</li> </ul>"},{"location":"use_case/planning_control/#metric-normaljudgement-positive","title":"Metric Normal(judgement: positive)","text":"<p>When <code>value_type=number</code>, it is normal if the specified metric in the metric topic falls within the <code>value_range</code>. When <code>value_type=string</code>, it is normal if the specified metric in the metric topic matches the <code>value_target</code>.</p>"},{"location":"use_case/planning_control/#metric-normaljudgement-negative","title":"Metric Normal(judgement: negative)","text":"<p>When <code>value_type=number</code>, it is normal if the specified metric in the metric topic falls outside the <code>value_range</code>. When <code>value_type=string</code>, it is normal if the specified metric in the metric topic does not match the <code>value_target</code>.</p>"},{"location":"use_case/planning_control/#metric-error","title":"Metric Error","text":"<p>When the Metric Normal condition is not met</p>"},{"location":"use_case/planning_control/#planningfactor","title":"PlanningFactor","text":""},{"location":"use_case/planning_control/#planningfactor-normaljudgement-positive","title":"PlanningFactor Normal(judgement: positive)","text":"<p>Normal if <code>/planning/planning_factors/**</code> meets all of the following conditions:</p> <ul> <li>If there is an area condition in the scenario, the x,y position of control_points[0].pose is within the range from the x,y coordinates specified in the scenario.</li> <li>If there is a behavior condition in the scenario, the planning_factor's behavior matches the behavior specified in the scenario.</li> <li>If there is a distance condition in the scenario, the planning_factor's distance (distance from Ego to control_point) is within the range specified in the scenario.</li> <li>If there is a velocity condition in the scenario, the planning_factor's velocity (velocity at the control_point) is within the range specified in the scenario.</li> <li>If there is a time_to_wall condition in the scenario, the planning_factor's time_to_wall (time to reach the control_point at current velocity) is within the range specified in the scenario.</li> <li>If there is an acceleration_to_wall condition in the scenario, the planning_factor's acceleration_to_wall (acceleration needed to reach the control_point at current velocity) is within the range specified in the scenario.</li> </ul>"},{"location":"use_case/planning_control/#planningfactor-normaljudgement-negative","title":"PlanningFactor Normal(judgement: negative)","text":"<p>Normal if <code>/planning/planning_factors/**</code> does not meet any of the following conditions:</p> <ul> <li>If there is an area condition in the scenario, the x,y position of control_points[0].pose is within the range from the x,y coordinates specified in the scenario.</li> <li>If there is a behavior condition in the scenario, the planning_factor's behavior matches the behavior specified in the scenario.</li> <li>If there is a distance condition in the scenario, the planning_factor's distance (distance from Ego to control_point) is within the range specified in the scenario.</li> <li>If there is a velocity condition in the scenario, the planning_factor's velocity (velocity at the control_point) is within the range specified in the scenario.</li> <li>If there is a time_to_wall condition in the scenario, the planning_factor's time_to_wall (time to reach the control_point at current velocity) is within the range specified in the scenario.</li> <li>If there is an acceleration_to_wall condition in the scenario, the planning_factor's acceleration_to_wall (acceleration needed to reach the control_point at current velocity) is within the range specified in the scenario.</li> </ul>"},{"location":"use_case/planning_control/#planningfactor-error","title":"PlanningFactor Error","text":"<p>When the PlanningFactor Normal condition is not met</p>"},{"location":"use_case/planning_control/#output-file-for-evaluation-results","title":"Output File for Evaluation Results","text":"<p>In planning_control, result.jsonl is created in the following three files. result.jsonl is always output, but planning_factor_result.jsonl, metric_result.jsonl and diag_result.jsonl are only output when specified in the scenario.</p>"},{"location":"use_case/planning_control/#resultjsonl","title":"result.jsonl","text":"<p>Output to output_dir/result.jsonl. Contains summarized results of planning_factor, metric and diag evaluations.</p> <p>When running with Evaluator, the success/failure is determined by referencing the last line of this file. Therefore, the final success/failure information that merges the results of planning_factor_result.jsonl, metric_result.jsonl and diag_result.jsonl is written in post_process.</p>"},{"location":"use_case/planning_control/#planning_factor_resultjsonl","title":"planning_factor_result.jsonl","text":"<p>Output to output_dir/result_archive/planning_factor_result.jsonl. Contains planning_factor evaluation results.</p>"},{"location":"use_case/planning_control/#metric_resultjsonl","title":"metric_result.jsonl","text":"<p>Output to output_dir/result_archive/metric_result.jsonl. Contains the evaluation results for metrics.</p>"},{"location":"use_case/planning_control/#diag_resultjsonl","title":"diag_result.jsonl","text":"<p>Output to output_dir/result_archive/diag_result.jsonl. Contains diagnostics evaluation results.</p>"},{"location":"use_case/planning_control/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /control/control_evaluator/metrics tier4_metric_msg/msg/MetricArray /planning/planning_evaluator/metrics tier4_metric_msg/msg/MetricArray /system/processing_time/metrics tier4_metric_msg/msg/MetricArray /planning/planning_factors/** autoware_internal_planning_msgs/msg/PlanningFactorArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"use_case/planning_control/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/planning_control/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/planning_control/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/planning_control/#scenario-format","title":"Scenario Format","text":"<p>See sample.</p>"},{"location":"use_case/planning_control/#evaluation-result-format","title":"Evaluation Result Format","text":""},{"location":"use_case/planning_control/#metric_1","title":"metric","text":"<p>See sample.</p>"},{"location":"use_case/planning_control/#planning_factor","title":"planning_factor","text":"<p>See sample.</p>"},{"location":"use_case/planning_control/#diagnostics","title":"diagnostics","text":"<p>Same as the diagnostics use case</p>"},{"location":"use_case/time_step_based_trajectory/","title":"Evaluate Time Step Based Trajectory","text":"<p>Evaluates the self-vehicle trajectories output by Autoware. Currently, no evaluation against specific criteria is performed (TBD). Analysis is conducted solely via <code>autoware_planning_data_analyzer</code> in <code>autoware_tools</code> during post-processing.</p>"},{"location":"use_case/time_step_based_trajectory/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<ul> <li>perception: false</li> <li>control: false</li> <li>localization: false</li> </ul>"},{"location":"use_case/time_step_based_trajectory/#simulation","title":"Simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/time_step_based_trajectory/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/time_step_based_trajectory/#evaluation","title":"evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/time_step_based_trajectory/#scenario-format","title":"Scenario Format","text":"<p>See sample</p>"},{"location":"use_case/time_step_based_trajectory/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>The contents of the result file are always the same.</p> <p>See sample</p>"},{"location":"use_case/traffic_light/","title":"Evaluate perception(traffic light)","text":"<p>The performance of Autoware's recognition function (perception) is evaluated by calculating mAP (mean Average Precision) and other indices from the recognition results.</p> <p>Run the perception module and pass the output perception topic to the evaluation library for evaluation.</p> <p>Currently, only the evaluation of <code>classification2d</code> is supported.</p>"},{"location":"use_case/traffic_light/#preparation","title":"Preparation","text":"<p>In perception evaluation, machine-learning pre-trained models are used. If the model is not prepared in advance, Autoware will not output recognition results. If no evaluation results are produced, check to see if this has been done correctly.</p>"},{"location":"use_case/traffic_light/#downloading-model-files","title":"Downloading Model Files","text":"<p>Models are downloaded during Autoware setup. The method of downloading models depends on the version of Autoware you are using, so check which method is used. The following patterns exist.</p>"},{"location":"use_case/traffic_light/#download-with-ansible","title":"Download with ansible","text":"<p>When you run the ansible setup script, you will see <code>Download artifacts? [y/N]</code>, type <code>y</code> and press enter (Autoware foundation's main branch use this method) https://github.com/autowarefoundation/autoware/blob/main/ansible/roles/artifacts/tasks/main.yaml</p>"},{"location":"use_case/traffic_light/#automatically-downloaded-when-the-package-is-built","title":"Automatically downloaded when the package is built","text":"<p>If you are using a slightly older Autoware.universe, this is the one to use, until the commit hash of <code>13b96ad3c636389b32fea3a47dfb7cfb7813cadc</code>. traffic_light_classifier/CMakeList.txt</p>"},{"location":"use_case/traffic_light/#conversion-of-model-files","title":"Conversion of model files","text":"<p>The downloaded onnx file is not to be used as-is, but to be converted to a TensorRT engine file for use. A conversion command is available, so source the autoware workspace and execute the command.</p> <p>Let's assume that autoware is installed in <code>$HOME/autoware</code>.</p> <pre><code>source $HOME/autoware/install/setup.bash\nros2 launch traffic_light_classifier traffic_light_classifier.launch.xml use_gpu:=true  build_only:=true\nros2 launch traffic_light_fine_detector traffic_light_fine_detector.launch.xml build_only:=true\n</code></pre> <p>When the conversion command finishes, the engine file is output. The output destination changes according to the model download method, so check that the output is in the appropriate directory.</p>"},{"location":"use_case/traffic_light/#download-with-ansible_1","title":"Download with ansible","text":"<p>The following file is output.</p> <pre><code>$HOME/autoware_data/traffic_light_classifier/traffic_light_classifier_mobilenetv2_batch_6.fp16-batch6.engine\n$HOME/autoware_data/traffic_light_fine_detector/tlr_yolox_s_batch_6.fp16-batch6.engine\n</code></pre>"},{"location":"use_case/traffic_light/#automatic-download-at-package-build-time","title":"Automatic download at package build time","text":"<p>The following file is output.</p> <pre><code>$HOME/autoware/install/traffic_light_classifier/share/traffic_light_classifier/data/traffic_light_classifier_mobilenetv2_batch_6.fp16-batch6.engine\n$HOME/autoware/install/traffic_light_fine_detector/share/traffic_light_fine_detector/data/tlr_yolox_s_batch_6.fp16-batch6.engine\n</code></pre>"},{"location":"use_case/traffic_light/#for-evaluation-on-a-single-pc-rewrite-parameters-in-the-launch-file","title":"(For evaluation on a single PC) rewrite parameters in the launch file","text":"<p>set the value of <code>traffic_light_recognition/fusion_only</code> <code>true</code> in the file <code>autoware.universe/launch/tier4_perception_launch/launch/perception.launch.xml</code> https://github.com/autowarefoundation/autoware.universe/blob/main/launch/tier4_perception_launch/launch/perception.launch.xml#L79</p> <p>In the main branch of Autoware Foundation's Autoware, it is set to <code>false</code>, but in the case of Autoware used in actual vehicles, it may be set to <code>true</code>. Because <code>true</code> is a setting that recognition results are sent from another computer, when evaluating with a single PC, it should be set back to <code>false</code> before execution.</p>"},{"location":"use_case/traffic_light/#evaluation-method","title":"Evaluation method","text":"<p>Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>traffic_light_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data output from input rosbag and outputs camera, and the perception module performs recognition.</li> <li>The evaluation node subscribes to <code>/perception/traffic_light_recognition/traffic_signals</code> and evaluates data. The result is dumped into a file.</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/traffic_light/#evaluation-results","title":"Evaluation results","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/traffic_light/#perception-normal","title":"Perception Normal","text":"<p>When the following conditions are satisfied by executing the evaluation function of perception_eval</p> <ol> <li>frame_result.pass_fail_result contains at least one object (<code>tp_object_results ! = [] and fp_object_results ! = [] and fn_objects ! = []</code>)</li> <li>no object fail (<code>frame_result.pass_fail_result.get_fail_object_num() == 0</code>)</li> </ol>"},{"location":"use_case/traffic_light/#perception-error","title":"Perception Error","text":"<p>The perception evaluation output is marked as <code>Error</code> when condition for <code>Normal</code> is not met.</p>"},{"location":"use_case/traffic_light/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /perception/traffic_light_recognition/traffic_signals tier4_perception_msgs/msg/TrafficSignalArray <p>Published topics:</p> Topic name Data type - -"},{"location":"use_case/traffic_light/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> </ul> <p>NOTE: The <code>tf</code> in the bag is used to align the localization during annotation and simulation. Therefore, localization is invalid.</p>"},{"location":"use_case/traffic_light/#dependent-libraries","title":"Dependent libraries","text":"<p>The perception evaluation step bases on the perception_eval library.</p>"},{"location":"use_case/traffic_light/#division-of-roles-of-driving_log_replayer_v2-with-dependent-libraries","title":"Division of roles of driving_log_replayer_v2 with dependent libraries","text":"<p><code>driving_log_replayer_v2</code> package is in charge of the connection with ROS. The actual perception evaluation is conducted in perception_eval library. The perception_eval is a ROS-independent library, it cannot receive ROS objects. Also, ROS timestamps use nanoseconds while the <code>t4_dataset</code> format is based on milliseconds (because it uses <code>nuScenes</code>), so the values must be properly converted before using the library's functions.</p> <p><code>driving_log_replayer_v2</code> subscribes the topic output from the perception module of Autoware, converts it to the data format defined in perception_eval, and passes it on. It is also responsible for publishing and visualizing the evaluation results from perception_eval on proper ROS topic.</p> <p>perception_eval is in charge of the part that compares the detection results passed from <code>driving_log_replayer_v2</code> with ground truth data, calculates the index, and outputs the results.</p>"},{"location":"use_case/traffic_light/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/traffic_light/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>Must contain the required topics in <code>t4_dataset</code> format.</p> <p>The vehicle's ECU CAN and sensors data topics are required for the evaluation to be run correctly. The following example shows the topic list available in evaluation input rosbag when multiple LiDARs and Cameras are used in a real-world vehicle configuration.</p> <p>/sensing/lidar/concatenated/pointcloud is used when sensing:=false is added to the launch argument.</p> <p>If there is more than one CAMERA, include all on-board camera_info and image_rect_color_compressed.</p> Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>The vehicle topics can be included instead of CAN.</p> Topic name Data type /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/traffic_light/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/traffic_light/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/traffic_light/#scenario-format","title":"Scenario Format","text":"<p>There are two types of evaluation: use case evaluation and database evaluation. Use case evaluation is performed on a single dataset, while database evaluation uses multiple datasets and takes the average of the results for each dataset.</p> <p>In the database evaluation, the <code>vehicle_id</code> should be able to be set for each data set, since the calibration values may change. Also, it is necessary to set whether or not to activate the sensing module.</p> <p>See sample.</p>"},{"location":"use_case/traffic_light/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>The evaluation results by perception_eval under the conditions specified in the scenario are output for each frame. Only the final line has a different format from the other lines since the final metrics are calculated after all data has been flushed.</p> <p>The format of each frame and the metrics format are shown below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Format of each frame:</p> <pre><code>{\n  \"Frame\": {\n    \"FrameName\": \"Frame number of t4_dataset used for evaluation\",\n    \"FrameSkip\": \"Number of times that an object was requested to be evaluated but the evaluation was skipped because there was no ground truth in the dataset within 75msec\",\n    \"PassFail\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"TP\": \"Number of TPs\",\n        \"FP\": \"Number of FPs\",\n        \"FN\": \"Number of FNs\"\n      }\n    }\n  }\n}\n</code></pre> <p>Metrics Data Format:</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"Score\": {\n        \"TP\": {\n          \"ALL\": \"TP rate for all labels\",\n          \"label0\": \"TP rate of label0\",\n          \"label1\": \"TP rate of label1\"\n        },\n        \"FP\": {\n          \"ALL\": \"FP rate for all labels\",\n          \"label0\": \"FP rate of label0\",\n          \"label1\": \"FP rate of label1\"\n        },\n        \"FN\": {\n          \"ALL\": \"FN rate for all labels\",\n          \"label0\": \"FN rate of label0\",\n          \"label1\": \"FN rate of label1\"\n        },\n        \"TN\": {\n          \"ALL\": \"TN rate for all labels\",\n          \"label0\": \"TN rate of label0\",\n          \"label1\": \"TN rate of label1\"\n        },\n        \"Accuracy\": {\n          \"ALL\": \"Accuracy for all labels\",\n          \"label0\": \"Accuracy of label0\",\n          \"label1\": \"Accuracy of label1\"\n        },\n        \"Precision\": {\n          \"ALL\": \"Precision for all labels\",\n          \"label0\": \"Precision of label0\",\n          \"label1\": \"Precision of label1\"\n        },\n        \"Recall\": {\n          \"ALL\": \"Recall for all labels\",\n          \"label0\": \"Recall of label0\",\n          \"label1\": \"Recall of label1\"\n        },\n        \"F1score\": {\n          \"ALL\": \"F1score for all labels\",\n          \"label0\": \"F1score of label0\",\n          \"label1\": \"F1score of label1\"\n        }\n      },\n      \"ConfusionMatrix\": {\n        \"label0(GroundTruth)\": {\n          \"label0(Prediction)\": \"value\",\n          \"label1(Prediction)\": \"value\"\n        },\n        \"label1(GroundTruth)\": {\n          \"label0(Prediction)\": \"value\",\n          \"label1(Prediction)\": \"value\"\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"use_case/traffic_light/#pickle-file","title":"pickle file","text":"<p>In database evaluation, it is necessary to replay multiple rosbags, but due to the ROS specification, it is impossible to use multiple bags in a single launch. Since one rosbag, i.e., one <code>t4_dataset</code>, requires one launch, it is necessary to execute as many launches as the number of datasets contained in the database evaluation.</p> <p>Since database evaluation cannot be done in a single launch, perception outputs a file <code>scene_result.pkl</code> in addition to <code>result.jsonl</code> file. A pickle file is a python object saved as a file, PerceptionEvaluationManager.frame_results of perception_eval. The dataset evaluation can be performed by reading all the objects recorded in the pickle file and outputting the index of the dataset's average.</p>"},{"location":"use_case/traffic_light/#result-file-of-database-evaluation","title":"Result file of database evaluation","text":"<p>In the case of a database evaluation with multiple datasets in the scenario, a file named <code>database_result.json</code> is output to the results directory.</p> <p>The format is the same as the Metrics Data Format.</p>"},{"location":"use_case/yabloc/","title":"Evaluate YabLoc estimation","text":"<p>Evaluate whether Autoware's YabLoc, a camera based pcd-less localization, is working stably.</p>"},{"location":"use_case/yabloc/#evaluation-method","title":"Evaluation method","text":"<p>Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>yabloc_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data input from prepared rosbag and performs localization estimation</li> <li>Evaluation node subscribes to Autoware's output topics, determines whether the outputs meet the criteria, and outputs the results</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/yabloc/#availability-of-yabloc","title":"Availability of YabLoc","text":"<p>We use the output from <code>yabloc_monitor</code> via <code>/diagnostics</code> to evaluate whether YabLoc is available.</p> <ul> <li><code>/diagnostics</code></li> </ul>"},{"location":"use_case/yabloc/#evaluation-result","title":"Evaluation Result","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/yabloc/#yabloc-availability-normal","title":"YabLoc Availability Normal","text":"<p>Information related to the monitored topic is extracted from <code>/diagnostics</code> which Component State Monitor outputs. If the most recent information is \"OK\", it is considered as pass.</p>"},{"location":"use_case/yabloc/#yabloc-availability-error","title":"YabLoc Availability Error","text":"<p>The YabLoc availability evaluation output is marked as <code>Error</code> when conditions for <code>YabLoc Availability Normal</code> are not met.</p>"},{"location":"use_case/yabloc/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs/msg/DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"use_case/yabloc/#service-name-and-data-type-used-by-the-evaluation-node","title":"Service name and data type used by the evaluation node","text":"Service name Data type /localization/initialize autoware_internal_localization_msgs/srv/InitializeLocalization"},{"location":"use_case/yabloc/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> <li>pose_source: yabloc</li> <li>twist_source: gyro_odom</li> </ul>"},{"location":"use_case/yabloc/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/yabloc/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>The following example shows the topic list available in evaluation input rosbag.</p> Topic name Data type /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/yabloc/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must NOT be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/yabloc/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/yabloc/#scenario-format","title":"Scenario Format","text":"<p>See sample.</p>"},{"location":"use_case/yabloc/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>Examples of each evaluation are described below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Availability Result example:</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre>"},{"location":"ja/","title":"driving_log_replayer_v2 \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<p>\u30da\u30fc\u30b8\u30c8\u30c3\u30d7\u306e \"\u6587 A\" \u30a2\u30a4\u30b3\u30f3\u304b\u3089\u8a00\u8a9e\u306e\u5207\u308a\u66ff\u3048\u304c\u53ef\u80fd\u3067\u3059\u3002</p>"},{"location":"ja/#driving_log_replayer_v2_1","title":"driving_log_replayer_v2 \u306b\u3064\u3044\u3066","text":"<p>driving_log_replayer_v2 \u306f\u3001\u904e\u53bb\u306b\u8a18\u9332\u3055\u308c\u305f\u5165\u529b\u30c7\u30fc\u30bf\u3092\u3082\u3068\u306b Autoware.Universe \u306e\u6027\u80fd\u3092\u8a55\u4fa1\u3059\u308b ROS 2 \u30d1\u30c3\u30b1\u30fc\u30b8\u3067\u3059\u3002 \u30b7\u30b9\u30c6\u30e0\u904b\u7528\u306e\u524d\u63d0\u6761\u4ef6\u3092\u5b9a\u7fa9\u3057\u3001\u305d\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"ja/analyzer/","title":"driving_log_replayer_v2_analyzer","text":"<p>driving_log_replayer_v2 \u3067\u884c\u3063\u305f\u30c6\u30b9\u30c8\u306e\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u3092\u5206\u6790\u3059\u308b\u30d1\u30c3\u30b1\u30fc\u30b8\u3002</p>"},{"location":"ja/analyzer/#_1","title":"\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u69cb\u6210","text":"<p>\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u69cb\u6210\u3092\u53d6\u308b\u3002</p> <pre><code>driving_log_replayer_v2_analyzer\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 __main__.py      # CLI\u306e\u30a8\u30f3\u30c8\u30ea\u30fc\u30dd\u30a4\u30f3\u30c8\n\u251c\u2500\u2500 analysis         # CLI\u306e\u89e3\u6790\u30b3\u30de\u30f3\u30c9\n\u251c\u2500\u2500 config           # \u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3068\u8a2d\u5b9a\u3092\u8aad\u307f\u8fbc\u3080\u30e2\u30b8\u30e5\u30fc\u30eb\n\u251c\u2500\u2500 data             # jsonl\u304b\u3089\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\u30e2\u30b8\u30e5\u30fc\u30eb\n\u2514\u2500\u2500 plot             # \u30c7\u30fc\u30bf\u3092\u63cf\u753b\u3059\u308b\u30e2\u30b8\u30e5\u30fc\u30eb\n</code></pre> <p>ROS \u306b\u4f9d\u5b58\u3057\u306a\u3044\u30d1\u30c3\u30b1\u30fc\u30b8\u3067\u306f\u3042\u308b\u304c\u3001ROS \u306e\u30ce\u30fc\u30c9\u306b\u3082\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u3057\u3066 import \u3055\u308c\u308b\u306e\u3067\u3001ROS \u30d1\u30c3\u30b1\u30fc\u30b8\u3068\u3057\u3066\u3082\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u308b\u3002</p> <p>\u30e2\u30b8\u30e5\u30fc\u30eb\u306e\u5f79\u5272\u3092\u56f3\u306b\u793a\u3059\u3002</p> <p></p>"},{"location":"ja/analyzer/#_2","title":"\u6ce8\u610f","text":"<p>\u73fe\u72b6\u3067\u306f obstacle_segmentation \u306e result.jsonl \u306e\u5206\u6790\u306e\u307f\u53ef\u80fd \u5fc5\u8981\u306b\u5fdc\u3058\u3066\u3001\u5404 use case \u306b\u5bfe\u5fdc\u3057\u305f\u5206\u6790\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8ffd\u52a0\u3059\u308b\u3002 analysis, config, data \u306b use_case_name.py \u30d5\u30a1\u30a4\u30eb\u3092\u8ffd\u52a0\u3059\u308b\u3002</p>"},{"location":"ja/analyzer/#_3","title":"\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u65b9\u6cd5","text":"<ul> <li>driving_log_replayer_v2_cli \u3068\u4e00\u7dd2\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u308b</li> <li>driving_log_replayer_v2 \u3068\u4e00\u7dd2\u306b ros \u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3068\u3057\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u308b</li> </ul>"},{"location":"ja/analyzer/#_4","title":"\u4f7f\u3044\u65b9","text":"<pre><code>dlr-analyzer analysis ${use-case-name} ${result.jsonl_path} [-c ${config_path}]\n</code></pre>"},{"location":"ja/overview/command/","title":"\u30b3\u30de\u30f3\u30c9","text":"<p>driving_log_replayer_v2\u306f\u30b7\u30ca\u30ea\u30aa\u306e\u30d1\u30b9\u3092\u6307\u5b9a\u3059\u308b\u3053\u3068\u3067\u8d77\u52d5\u3067\u304d\u308b\u3002</p> <pre><code>ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=${scenario_path} [output_dir:=${output_dir} dataset_dir:=${dataset_dir}]\n</code></pre>"},{"location":"ja/overview/command/#wasim-driving_log_replayer_v2","title":"wasim \u306b\u3088\u308b driving_log_replayer_v2 \u5b9f\u884c","text":"<p>TIER IV \u304c\u63d0\u4f9b\u3057\u3066\u3044\u308bAutoware Evaluator\u3078 \u30a2\u30af\u30bb\u30b9\u6a29\u304c\u3042\u308b\u5834\u5408\u306fwasim\u3092\u5229\u7528\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u308b\u3002</p> <p>\u4f7f\u3044\u65b9\u306f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30b5\u30a4\u30c8\u3092\u53c2\u7167\u3002</p> <p>wasim \u306f Autoware Evaluator \u304b\u3089\u30b7\u30ca\u30ea\u30aa\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u5b9f\u884c\u3059\u308b\u306e\u3067\u3001\u30af\u30e9\u30a6\u30c9\u74b0\u5883\u306b\u767b\u9332\u6e08\u307f\u306e\u30b7\u30ca\u30ea\u30aa\u3057\u304b\u5b9f\u884c\u51fa\u6765\u306a\u3044\u3002</p>"},{"location":"ja/overview/command/#driving-log-replayer-v2-cli-driving_log_replayer_v2","title":"driving-log-replayer-v2-cli \u306b\u3088\u308b driving_log_replayer_v2 \u5b9f\u884c","text":"<p>cli\u3092\u5229\u7528\u3059\u308b\u3068\u30011\u56de\u306e\u30b3\u30de\u30f3\u30c9\u5165\u529b\u3067\u8907\u6570\u306e\u30b7\u30ca\u30ea\u30aa\u3092\u9023\u7d9a\u3067\u5b9f\u884c\u3067\u304d\u307e\u3059\u3002</p> <p>\u4f8b\u3048\u3070\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3001SCENARIO_ROOT\u914d\u4e0b\u306b\u8907\u6570\u306e\u30b7\u30ca\u30ea\u30aa\u304c\u30b5\u30d6\u30c7\u30a3\u30ec\u30af\u30c8\u30ea(SCENARIO_DIR1, SCENARIO_DIR2...)\u306b\u7f6e\u304b\u308c\u3066\u3044\u308b\u3068\u3057\u307e\u3059\u3002</p> <pre><code>SCENARIO_ROOT\n\u251c\u2500\u2500 SCENARIO_DIR1\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 out # output directyory\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 SCENARIO_DIR1_DATASET0 # t4_dataset\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 annotation\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 input_bag\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 map\n\u2502\u00a0\u00a0 \u2502  \u2514\u2500\u2500 status.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 SCENARIO_DIR1_DATASET1 # t4_dataset\n\u2502\u00a0\u00a0 \u2502  \u2514\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2502  ...\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 scenario.yaml  # scenario fixed name\n\u2502\n\u251c\u2500\u2500 SCENARIO_DIR2\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 out # output directyory\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 SCNERIO_DIR2_DATASET0 # t4_dataset\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 annotation\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 data\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 input_bag\n\u2502\u00a0\u00a0 \u2502  \u251c\u2500\u2500 map\n\u2502\u00a0\u00a0 \u2502  \u2514\u2500\u2500 status.json\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 scenario.yaml  # scenario fixed name\n...\n</code></pre> <p>\u4e0a\u8a18\u306eSCENARIO_ROOT\u306b\u3042\u308b\u8907\u6570\u30b7\u30ca\u30ea\u30aa\u3092ros2 launch\u30b3\u30de\u30f3\u30c9\u3067\u5b9f\u884c\u3059\u308b\u306b\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u8907\u6570\u56de\u306e\u30b3\u30de\u30f3\u30c9\u3092\u53e9\u304f\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002</p> <pre><code>source ${AUTOWARE_ROOT}/install/setup.bash\nros2 launch driving_log_replayer_v2 driving_log_replayer_v2 scenario_path:=${SCENARIO_ROOT}/SCENARIO_DIR1/scenario.yaml dataset_index:=0 # \u8907\u6570dataset\u3042\u308b\u5834\u5408\nros2 launch driving_log_replayer_v2 driving_log_replayer_v2 scenario_path:=${SCENARIO_ROOT}/SCENARIO_DIR1/scenario.yaml dataset_index:=1 # \u8907\u6570dataset\u3042\u308b\u5834\u5408\nros2 launch driving_log_replayer_v2 driving_log_replayer_v2 scenario_path:=${SCENARIO_ROOT}/SCENARIO_DIR2/scenario.yaml\n...\n</code></pre> <p>cli\u3092\u4f7f\u3046\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067\u6e08\u307f\u307e\u3059</p> <pre><code>source ${AUTOWARE_ROOT}/install/setup.bash\ndlr2 simulation run ${SCENARIO_ROOT}\n</code></pre>"},{"location":"ja/overview/command/#cli-installation","title":"cli installation","text":"<p>\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067cli\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3067\u304d\u308b\u3002</p> <pre><code># install\npipx install git+https://github.com/tier4/driving_log_replayer_v2.git\n\n# upgrade\npipx upgrade driving-log-replayer-v2\n\n# uninstall\npipx uninstall driving-log-replayer-v2\n</code></pre>"},{"location":"ja/overview/command/#cli-limitation","title":"cli limitation","text":"<p>cli\u3067\u30b7\u30ca\u30ea\u30aa\u30d5\u30a1\u30a4\u30eb\u3092\u81ea\u52d5\u3067\u63a2\u3059\u305f\u3081\u4ee5\u4e0b\u306e\u5236\u7d04\u304c\u3042\u308b\u3002</p> <ul> <li>\u30b7\u30ca\u30ea\u30aa\u30d5\u30a1\u30a4\u30eb\u306e\u540d\u524d\u304cscenario.yaml\u3067\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044</li> <li>SCENARIO_ROOT\u306e\u4e0b\u306e\u30b5\u30d6\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bscenario.yaml\u304c\u5b58\u5728\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044(\u30b5\u30d6\u30b5\u30d6\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306f\u4e0d\u53ef)</li> </ul>"},{"location":"ja/overview/command/#cli-output","title":"cli output","text":"<p>cli\u3092\u5229\u7528\u3059\u308b\u3068\u3001\u30b3\u30de\u30f3\u30c9\u5165\u529b\u3092\u77ed\u304f\u3059\u308b\u3060\u3051\u3067\u306a\u304f\u51fa\u529b\u3055\u308c\u308b\u30d5\u30a1\u30a4\u30eb\u304c\u5897\u3048\u308b\u3002</p> <p>\u4ee5\u4e0b\u304c\u3001cli\u3092\u5229\u7528\u3057\u305f\u5834\u5408\u306e\u51fa\u529b\u5148\u306e\u4f8b\u3067\u3042\u308b\u3002 simulation\u306e\u5b9f\u884c\u30b3\u30de\u30f3\u30c9\u3068\u3001\u30b3\u30f3\u30bd\u30fc\u30eb\u306e\u30ed\u30b0\u304c\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u3002 \u8907\u6570\u500b\u306e\u30c6\u30b9\u30c8\u3092\u9023\u7d9a\u3067\u5b9f\u884c\u3057\u3001\u5f8c\u3067\u30a8\u30e9\u30fc\u304c\u51fa\u305f\u30c6\u30b9\u30c8\u3060\u3051\u30c7\u30d0\u30c3\u30b0\u3059\u308b\u3068\u3044\u3063\u305f\u5834\u5408\u306b\u5229\u7528\u3059\u308b\u3002</p> <pre><code>OUTPUT_LATEST\n\u251c\u2500\u2500 0 # Datasets[0]\u306e\u7d50\u679c\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 result.jsonl\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 result_archive_path\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 result_bag\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 metadata.yaml\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 result_bag_0.db3\n\u251c\u2500\u2500 1 # Datasets[1]\u306e\u7d50\u679c\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 result.jsonl\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 result_archive_path\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 result_bag\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 metadata.yaml\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 result_bag_0.db3\n\u251c\u2500\u2500 console.log # \u30b3\u30f3\u30bd\u30fc\u30eb\u306b\u8868\u793a\u3055\u308c\u3066\u3044\u308b\u30ed\u30b0\u3092\u30d5\u30a1\u30a4\u30eb\u5316\u3057\u305f\u3082\u306e\n\u2514\u2500\u2500 run.bash # simulation\u306e\u5b9f\u884c\u30b3\u30de\u30f3\u30c9\n</code></pre>"},{"location":"ja/overview/command/#cli-command","title":"cli command","text":"<p><code>dlr2</code> \u30b3\u30de\u30f3\u30c9\u306f\u3001\u30b5\u30d6\u30b3\u30de\u30f3\u30c9\u3092\u6301\u3063\u3066\u3044\u307e\u3059\u3002 \u5404\u30b3\u30de\u30f3\u30c9\u306b\u5fc5\u8981\u306a\u5f15\u6570\u306f <code>--help</code> \u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u6307\u5b9a\u3059\u308b\u3068\u8868\u793a\u3067\u304d\u308b\u307e\u3059\u3002</p> <pre><code># dlr2 top level help\ndlr2 --help\n\n# show version\ndlr2 --version\n\n# show subcommand help\ndlr2 subcommand --help\n\n# show subsubcommand help\ndlr2 subcommand subsubcommand --help\n</code></pre>"},{"location":"ja/overview/command/#dlr2-simulation","title":"dlr2 simulation","text":"<p>simulation \u306b\u95a2\u3059\u308b\u30b5\u30d6\u30b3\u30de\u30f3\u30c9</p> <pre><code># scenario_root\u914d\u4e0b\u306escenario\u3092\u9023\u7d9a\u3067\u5b9f\u884c\u3059\u308b\ndlr2 simulation run ${scenario_root}\n\n# launch\u306eargument\u3092-l\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u8ffd\u52a0\u3059\u308b\u3002-l\u3092\u8907\u6570\u8a18\u8ff0\u3067\u304d\u308b\u3002\n# \u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u8868\u793a\u3055\u308c\u308bargument\u304c\u6307\u5b9a\u53ef\u80fd\n# ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py -s\n# ros2 launch autoware_launch logging_simulator.launch.xml -s\n\n# \u4f8b\uff1abag\u306e\u518d\u751f\u901f\u5ea6\u30920.5\u500d\u306b\u3057\u3066\u3001rviz\u3092\u7121\u52b9\u306b\u3059\u308b\ndl2 simulation run -l play_rate:=0.5 -l rviz:=false\n\n# output_directory\u4ee5\u4e0b\u306e\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u306e\u30b5\u30de\u30ea\u30fc\u3092\u8868\u793a\u3059\u308b\ndlr2 simulation show-result ${output_directory}\n</code></pre>"},{"location":"ja/overview/","title":"\u6982\u8981","text":"<p>driving_log_replayer_v2 \u306f\u3001log(rosbag2)\u3092\u7528\u3044\u3066 Autoware \u306e <code>logging_simulator.launch.xml</code> \u307e\u305f\u306f <code>planning_simulator.launch.xml</code> \u3092\u5b9f\u884c\u3057\u3001Autoware \u304c\u51fa\u529b\u3059\u308b\u30c8\u30d4\u30c3\u30af\u3092\u8a55\u4fa1\u3059\u308b\u30d1\u30c3\u30b1\u30fc\u30b8\u3067\u3059\u3002 Autoware \u306e\u5404\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u306e\u6027\u80fd\u78ba\u8a8d\u3068\u3001\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u306e\u30ea\u30b0\u30ec\u30c3\u30b7\u30e7\u30f3\u30c6\u30b9\u30c8\u306b\u4f7f\u7528\u3057\u307e\u3059\u3002</p>"},{"location":"ja/overview/#_2","title":"\u95a2\u9023\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ol> <li>AutowareDocumentation</li> <li>WebAutoDocumentation</li> </ol>"},{"location":"ja/overview/#_3","title":"\u95a2\u9023\u30ea\u30dd\u30b8\u30c8\u30ea","text":"<ol> <li>ros2bag_extensions</li> <li>perception_eval</li> <li>perception_dataset</li> </ol>"},{"location":"ja/overview/#_4","title":"\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":"<p>driving_log_replayer_v2 \u306f\u3001Autoware \u306e\u8a55\u4fa1\u30ce\u30fc\u30c9\u3092 Autoware \u306e\u6a19\u6e96\u6a5f\u80fd\u306b\u4ed8\u52a0\u3057\u305f\u69cb\u6210\u3068\u306a\u3063\u3066\u3044\u308b\u3002 \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u56f3\u3092\u4ee5\u4e0b\u306b\u793a\u3059\u3002</p> <p></p>"},{"location":"ja/overview/#_5","title":"\u30d1\u30c3\u30b1\u30fc\u30b8\u69cb\u6210","text":"<p>driving_log_replayer_v2 \u306e\u8a55\u4fa1\u30ce\u30fc\u30c9\u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u52d5\u4f5c\u3057\u307e\u3059\u3002</p> <ul> <li>\u8a55\u4fa1\u306e\u6761\u4ef6\u304c\u8a18\u8f09\u3055\u308c\u305f\u30b7\u30ca\u30ea\u30aa\u3092\u30d1\u30c3\u30b1\u30fc\u30b8\u304c\u8aad\u307f\u53d6\u308b</li> <li>autoware \u3092\u8d77\u52d5\u3059\u308b</li> <li>\u8a55\u4fa1\u7d50\u679c\u3092 jsonl \u30d5\u30a1\u30a4\u30eb\u5f62\u5f0f\u3067\u51fa\u529b\u3059\u308b</li> </ul> <p>\u30ce\u30fc\u30c9\u306e\u52d5\u4f5c\u306e\u8a73\u7d30\u3092\u4e0b\u56f3\u306b\u793a\u3059\u3002</p> <p></p>"},{"location":"ja/overview/#_6","title":"\u5229\u7528\u30d5\u30ed\u30fc","text":"<ol> <li>\u8a55\u4fa1\u7528\u306e rosbag \u3092\u5b9f\u8eca\u3067\u53d6\u5f97\u3059\u308b</li> <li>\u53d6\u5f97\u3057\u305f rosbag \u3092\u5fc5\u8981\u306a\u6642\u9593\u3001topic \u3060\u3051\u6b8b\u308b\u3088\u3046\u306b\u30d5\u30a3\u30eb\u30bf\u3059\u308b<ul> <li>\u30d5\u30a3\u30eb\u30bf\u51e6\u7406\u306b\u306f TIER IV \u3067\u958b\u767a\u3057\u305f ros2bag_extensions \u3092\u4f7f\u7528\u3059\u308b</li> <li>\u30d5\u30a3\u30eb\u30bf\u3067\u3069\u306etopic\u3092\u6b8b\u3059\u304b\u306f\u3001docs/use_case/\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u53c2\u7167</li> </ul> </li> <li>\u30b7\u30ca\u30ea\u30aa\u3092\u4f5c\u6210\u3059\u308b<ol> <li>sample folder \u5185\u306b\u30b7\u30ca\u30ea\u30aa\u306e\u4f8b\u3042\u308a</li> <li>\u8a18\u8ff0\u5185\u5bb9\u306f\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u5b9a\u7fa9\u3092\u53c2\u7167</li> </ol> </li> <li>dataset\u3092\u4f5c\u6210\u3059\u308b<ol> <li>localization, eagleye, yabloc, ar_tag_based_localizer, performance_diag\u306b\u95a2\u3057\u3066\u306f\u3001Evaluator\u3092\u5229\u7528\u3057\u306a\u3044\u306a\u3089\u4efb\u610f</li> <li>perception_dataset tools_overview\u3092\u53c2\u8003\u306bT4 non-annotated format data\u307e\u3067\u4f5c\u308b\u3002</li> <li>T4 non-annotated format data\u307e\u3067\u4f5c\u6210\u3059\u308b\u3068\u3001Vehicle Data Search\u4e0a\u3067\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u5185\u5bb9\u306e\u78ba\u8a8d\u304c\u53ef\u80fd\u306b\u306a\u308b\u3002</li> </ol> </li> <li>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u304c obstacle_segmentation, perception, perception_2d, traffic_light \u306e\u5834\u5408\u3001t4_dataset \u3078\u306e\u5909\u63db\u306b\u5bfe\u5fdc\u3057\u305f\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u30c4\u30fc\u30eb\u3067\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u65bd\u3059\u308b\u3002<ol> <li>Deepen.AI\u304c\u5229\u7528\u53ef\u80fd</li> <li>perception_dataset\u306b\u5909\u63db\u6a5f\u80fd\u3092\u8ffd\u52a0\u3059\u308c\u3070\u4ed6\u306e\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u30c4\u30fc\u30eb\u3082\u4f7f\u7528\u53ef\u80fd\u306b\u306a\u308b</li> </ol> </li> <li>\u8a55\u4fa1\u3092\u5b9f\u884c\u3059\u308b\u3002</li> </ol>"},{"location":"ja/quick_start/installation/","title":"\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<p>AWF Autoware Core/Universe\u3092<code>driving_log_replayer_v2</code>\u3068\u4e00\u7dd2\u306b\u30d3\u30eb\u30c9\u3059\u308b\u65b9\u6cd5\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002</p>"},{"location":"ja/quick_start/installation/#_2","title":"\u30d3\u30eb\u30c9\u65b9\u6cd5","text":"<ol> <li> <p>Autoware workspace \u306b\u79fb\u52d5\u3059\u308b:</p> <pre><code>cd autoware\n</code></pre> </li> <li> <p>\u4f9d\u5b58\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u8ffd\u52a0\u3059\u308b:</p> <pre><code>nano simulator.repos\n# \u4ee5\u4e0b\u306e\u5185\u5bb9\u3092\u8ffd\u52a0\u3059\u308b\n</code></pre> <pre><code>  simulator/perception_eval:\n    type: git\n    url: https://github.com/tier4/autoware_perception_evaluation.git\n    version: main\n  simulator/driving_log_replayer_v2:\n    type: git\n    url: https://github.com/tier4/driving_log_replayer_v2.git\n    version: main\n  simulator/vendor/ros2_numpy:\n    type: git\n    url: https://github.com/Box-Robotics/ros2_numpy.git\n    version: humble\n  simulator/vendor/ros2bag_extensions:\n    type: git\n    url: https://github.com/tier4/ros2bag_extensions.git\n    version: main\n  simulator/tool/autoware_tools:\n    type: git\n    url: https://github.com/autowarefoundation/autoware_tools.git\n    version: main\n</code></pre> </li> <li> <p>simulator \u306e\u4f9d\u5b58\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\u3059\u308b:</p> <pre><code>vcs import src &lt; simulator.repos\n</code></pre> </li> <li> <p>(Optional) \u57fa\u672c\u7684\u306bdriving_log_replayer_v2\u306emain\u30d6\u30e9\u30f3\u30c1\u306f\u6700\u65b0\u306eautoware\u3068\u5171\u306b\u5229\u7528\u3059\u308b\u3053\u3068\u3092\u524d\u63d0\u3068\u3057\u3066\u3044\u308b\u305f\u3081\u3001\u5fc5\u8981\u306b\u5fdc\u3058\u3066nightly.repos\u3092import\u3059\u308b</p> <pre><code>vcs import src &lt; autoware-nightly.repos\nvcs import src &lt; tools-nightly.repos\n</code></pre> </li> <li> <p>\u4f9d\u5b58\u89e3\u6c7a\u306e\u305f\u3081\u306b rosdep \u3092\u66f4\u65b0\u3059\u308b:</p> <pre><code>rosdep update\n</code></pre> </li> <li> <p>rosdep \u3067\u4f9d\u5b58\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b:</p> <pre><code>rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO\n</code></pre> </li> <li> <p>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u30d3\u30eb\u30c9\u3059\u308b:</p> <pre><code>colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE=Release\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/run/","title":"driving_log_replayer_v2 \u8a55\u4fa1\u5b9f\u884c","text":"<pre><code>cd ${AUTOWARE_WORKSPACE}\nsource install/setup.bash\nros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=${scenario_file}\n# example\n# ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=$HOME/driving_log_replayer_v2/yabloc.yaml\n</code></pre>"},{"location":"ja/quick_start/setup/","title":"\u8a2d\u5b9a","text":"<p>Note</p> <p>driving_log_replayer_v2\u3092\u5b9f\u884c\u3059\u308b\u306b\u306f\u3001Autoware\u306e\u30d3\u30eb\u30c9\u3068\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306b\u52a0\u3048\u3066\u3001driving_log_replayer_v2\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb \u304c\u5b8c\u4e86\u3057\u3066\u3044\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002</p> <p>Sample map: Copyright 2020 TIER IV, Inc.</p> <p>Sample Dataset: Copyright 2022 TIER IV, Inc.</p>"},{"location":"ja/quick_start/setup/#_2","title":"\u30ea\u30bd\u30fc\u30b9\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":"<ol> <li> <p>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3068\u5730\u56f3\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7(annotationless_perception, localization, obstacle_segmentation, perception)</p> <pre><code>mkdir -p ~/driving_log_replayer_v2\ngdown -O ~/driving_log_replayer_v2/sample_dataset_v2.tar.zst 'https://docs.google.com/uc?export=download&amp;id=1iCoykBBETI_rGfKEFYYb7LFydF-RJVkC'\ntar -I zstd -xvf ~/driving_log_replayer_v2/sample_dataset_v2.tar.zst -C ~/driving_log_replayer_v2/\ngdown -O ~/driving_log_replayer_v2/sample-map-planning.zip 'https://docs.google.com/uc?export=download&amp;id=1499_nsbUbIeturZaDj7jhUownh5fvXHd'\nunzip -d ~/driving_log_replayer_v2/ ~/driving_log_replayer_v2/sample-map-planning.zip\nmv ~/driving_log_replayer_v2/sample-map-planning ~/driving_log_replayer_v2/sample_dataset/map\n</code></pre> <p>\u30d6\u30e9\u30a6\u30b6\u304b\u3089\u624b\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u3053\u3068\u3082\u53ef\u80fd\u3067\u3059\u3002</p> <p>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8</p> <p>sample-map-planning</p> </li> <li> <p>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3068\u5730\u56f3\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7(yabloc, eagleye, ar_tag_based_localizer)</p> <pre><code>gdown -O ~/driving_log_replayer_v2/sample_bag.tar.zst 'https://docs.google.com/uc?export=download&amp;id=17ppdMKi4IC8J_2-_9nyYv-LAfW0M1re5'\ntar -I zstd -xvf ~/driving_log_replayer_v2/sample_bag.tar.zst -C ~/driving_log_replayer_v2/\nmv ~/driving_log_replayer_v2/sample_bag/*  ~/driving_log_replayer_v2/\nrmdir ~/driving_log_replayer_v2/sample_bag\ncp -r ~/driving_log_replayer_v2/ar_tag_based_localizer/map ~/driving_log_replayer_v2/eagleye/\ncp -r ~/driving_log_replayer_v2/ar_tag_based_localizer/map ~/driving_log_replayer_v2/yabloc/\n</code></pre> <p>\u30d6\u30e9\u30a6\u30b6\u304b\u3089\u624b\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u3053\u3068\u3082\u53ef\u80fd\u3067\u3059\u3002</p> <p>bag</p> </li> <li> <p>\u30b5\u30f3\u30d7\u30eb\u30b7\u30ca\u30ea\u30aa\u3092\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u30b3\u30d4\u30fc</p> <pre><code># autoware\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u3044\u308b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u6307\u5b9a\u3059\u308b\u3002\u74b0\u5883\u306b\u5408\u308f\u305b\u3066\u5909\u66f4\u3059\u308b\nAUTOWARE_PATH=$HOME/ros_ws/awf\n# SAMPLE_ROOT=${AUTOWARE_PATH}/src/simulator/driving_log_replayer_v2/sample\nSAMPLE_ROOT=${AUTOWARE_PATH}/src/simulator/driving_log_replayer_v2/sample\ncp ${SAMPLE_ROOT}/annotationless_perception/scenario.yaml ~/driving_log_replayer_v2/annotationless_perception.yaml\ncp ${SAMPLE_ROOT}/ar_tag_based_localizer/scenario.yaml ~/driving_log_replayer_v2/ar_tag_based_localizer.yaml\ncp ${SAMPLE_ROOT}/eagleye/scenario.yaml ~/driving_log_replayer_v2/eagleye.yaml\ncp ${SAMPLE_ROOT}/localization/scenario.yaml ~/driving_log_replayer_v2/localization.yaml\ncp ${SAMPLE_ROOT}/obstacle_segmentation/scenario.yaml ~/driving_log_replayer_v2/obstacle_segmentation.yaml\ncp ${SAMPLE_ROOT}/perception/scenario.yaml ~/driving_log_replayer_v2/perception.yaml\ncp ${SAMPLE_ROOT}/yabloc/scenario.yaml ~/driving_log_replayer_v2/yabloc.yaml\n</code></pre> </li> <li> <p>\u6a5f\u68b0\u5b66\u7fd2\u306e\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u306e\u5909\u63db\u3092\u884c\u3046</p> <pre><code>source ~/autoware/install/setup.bash\nros2 launch autoware_launch logging_simulator.launch.xml map_path:=$HOME/autoware_map/sample-map-planning vehicle_model:=sample_vehicle sensor_model:=sample_sensor_kit\n# ~/autoware/install/lidar_centerpoint/share/lidar_centerpoint/data\u306b\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u3067\u304d\u308b\u307e\u3067\u5f85\u3064\n# - pts_backbone_neck_head_centerpoint_tiny.engine\n# - pts_voxel_encoder_centerpoint_tiny.engine\n# \u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u305f\u3089Ctrl+C\u3067launch\u3092\u6b62\u3081\u308b\n</code></pre> </li> </ol>"},{"location":"ja/result_format/","title":"driving_log_replayer_v2 \u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>1 \u884c\u6bce\u306b json \u5f62\u5f0f\u306e\u6587\u5b57\u5217\u304c\u5165\u3063\u3066\u3044\u308b jsonl \u5f62\u5f0f\u3068\u306a\u3063\u3066\u3044\u308b\u3002</p>"},{"location":"ja/result_format/#_1","title":"\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u5404\u884c\u4ee5\u4e0b\u306e\u5f62\u5f0f\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u51fa\u529b\u3055\u308c\u308b\u3002 \u5b9f\u969b\u306b\u306f\u4e00\u884c\u306e\u6587\u5b57\u5217\u3060\u304c\u307f\u3084\u3059\u3055\u306e\u305f\u3081\u306b\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3057\u3066\u3044\u308b\u3002</p> <pre><code>{\n  \"Result\": {\n    \"Success\": \"true or false\",\n    \"Summary\": \"\u8a55\u4fa1\u3057\u305f\u7d50\u679c\u306e\u8981\u7d04\"\n  },\n  \"Stamp\": {\n    \"System\": \"PC\u306e\u6642\u523b\",\n    \"ROS\": \"\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u6642\u523b\"\n  },\n  \"Frame\": {\n    \"Ego\": { \"TransformStamped\": \"map\u304b\u3089base_link\u3078\u306etransform_stamped\" },\n    \"\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u6bce\u306b\u69cb\u6210\u304c\u7570\u306a\u308b\": \"...\"\n  }\n}\n</code></pre> <p>\u7d50\u679c\u51fa\u529b\u306f\u4ee5\u4e0b\u306e\u5c5e\u6027\u304b\u3089\u69cb\u6210\u3055\u308c\u308b\u3002</p> <ul> <li>Result: \u5b9f\u884c\u3057\u305f\u30b7\u30ca\u30ea\u30aa\u306e\u8a55\u4fa1\u7d50\u679c</li> <li>Stamp: \u8a55\u4fa1\u3057\u305f\u6642\u523b</li> <li>Frame: \u53d7\u3051\u53d6\u3063\u305f frame(topic) 1 \u56de\u5206\u306e\u8a55\u4fa1\u7d50\u679c\u3068\u3001\u5224\u5b9a\u306b\u4f7f\u7528\u3057\u305f\u5024\u306a\u3069\u306e\u4ed8\u5c5e\u60c5\u5831</li> </ul> <p>Frame \u306e\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001\u5404\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306e\u8a55\u4fa1\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u53c2\u7167\u3002</p>"},{"location":"ja/result_format/#_2","title":"\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u306e\u5206\u6790","text":"<p>vscode\u306eJSONL Converter\u3092\u7528\u3044\u308b\u3068\u30dc\u30bf\u30f3\u3092\u62bc\u3059\u3060\u3051\u3067\u5bb9\u6613\u306bjsonl &lt;-&gt; json\u306e\u5909\u63db\u304c\u3067\u304d\u308b</p> <p>https://marketplace.visualstudio.com/items?itemName=F-loat.jsonl-converter</p> <p>python \u3092\u7528\u3044\u308b\u5834\u5408\u306f\u3001pandas.read_json \u3067 lines=True \u3068\u3059\u308b\u3068 jsonl \u3092\u8aad\u307f\u8fbc\u3080\u3053\u3068\u304c\u3067\u304d\u308b</p>"},{"location":"ja/scenario_format/","title":"driving_log_replayer_v2 \u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u5b9a\u7fa9","text":"<p>driving_log_replayer_v2 \u3067\u7528\u3044\u308b\u30b7\u30ca\u30ea\u30aa\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306b\u3064\u3044\u3066\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/scenario_format/#_1","title":"\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306b\u95a2\u3059\u308b\u6ce8\u610f\u4e8b\u9805","text":"<ul> <li>\u30ad\u30fc\u306f CamelCase \u306b\u3066\u5b9a\u7fa9\u3059\u308b\u3002Scenario Format Version 3.0\u307e\u3067</li> <li>pydantic\u3092\u7528\u3044\u305f\u30b7\u30ca\u30ea\u30aa\u306e\u30d0\u30ea\u30c7\u30fc\u30b7\u30e7\u30f3\u306e\u305f\u3081\u3001\u65b0\u898f\u306b\u8ffd\u52a0\u3059\u308b\u30ad\u30fc\u306fsnake_case\u3092\u63a8\u5968 Scenario Format Version 3.1\u3088\u308a</li> <li>\u5ea7\u6a19\u7cfb\u306b\u95a2\u3057\u3066\u306f\u3001 <code>map</code> \u5ea7\u6a19\u7cfb\u3092\u4f7f\u7528\u3059\u308b</li> <li>\u5358\u4f4d\u7cfb\u306b\u95a2\u3057\u3066\u306f\u3001\u7279\u306b\u6307\u5b9a\u304c\u306a\u3051\u308c\u3070\u4ee5\u4e0b\u3092\u4f7f\u7528\u3059\u308b\u3002</li> </ul> <pre><code>\u8ddd\u96e2: m\n\u901f\u5ea6: m/s\n\u52a0\u901f\u5ea6: m/s^2\n\u6642\u9593: s\n</code></pre>"},{"location":"ja/scenario_format/#_2","title":"\u30b5\u30f3\u30d7\u30eb","text":"<p>\u30b7\u30ca\u30ea\u30aa\u306e\u30b5\u30f3\u30d7\u30eb\u3092sample \u30d5\u30a9\u30eb\u30c0\u306b\u7f6e\u3044\u3066\u3044\u308b\u3002</p>"},{"location":"ja/scenario_format/#_3","title":"\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u57fa\u672c\u69cb\u9020\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3002\u5404\u30ad\u30fc\u306e\u8a73\u7d30\u306f\u4ee5\u4e0b\u3067\u8a18\u8ff0\u3059\u308b\u3002</p>"},{"location":"ja/scenario_format/#driving_log_replayer_v2-scenario-format-version-3xx","title":"driving_log_replayer_v2 Scenario Format version 3.x.x","text":"<pre><code>ScenarioFormatVersion: 3.x.x\nScenarioName: String\nScenarioDescription: String\nSensorModel: String\nVehicleModel: String\nEvaluation:\n  UseCaseName: String\n  UseCaseFormatVersion: String\n  Conditions: Dictionary # refer use case\n  Datasets:\n    - DatasetName:\n        VehicleId: String\ninclude_use_case:\n  UseCaseName: String\n  UseCaseFormatVersion: String\n  Conditions: Dictionary\n</code></pre>"},{"location":"ja/scenario_format/#scenarioformatversion","title":"ScenarioFormatVersion","text":"<p>\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u60c5\u5831\u3092\u8a18\u8ff0\u3059\u308b\u3002\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u7528\u3044\u308b\u3002</p> <p>\u73fe\u5728\u306f\u30013.1.0</p> <p>\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306e\u66f4\u65b0\u306e\u5ea6\u306b\u30de\u30a4\u30ca\u30fc\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u66f4\u65b0\u3059\u308b\u3002</p>"},{"location":"ja/scenario_format/#scenarioname","title":"ScenarioName","text":"<p>\u30b7\u30ca\u30ea\u30aa\u306e\u540d\u524d\u3092\u8a18\u8ff0\u3059\u308b\u3002Autoware Evaluator \u4e0a\u3067\u30b7\u30ca\u30ea\u30aa\u306e\u8868\u793a\u540d\u3068\u3057\u3066\u4f7f\u7528\u3055\u308c\u308b\u3002</p>"},{"location":"ja/scenario_format/#scenariodescription","title":"ScenarioDescription","text":"<p>\u30b7\u30ca\u30ea\u30aa\u306e\u8aac\u660e\u3092\u8a18\u8ff0\u3059\u308b\u3002Autoware Evaluator \u4e0a\u3067\u30b7\u30ca\u30ea\u30aa\u306e\u8aac\u660e\u3068\u3057\u3066\u4f7f\u7528\u3055\u308c\u308b\u3002</p>"},{"location":"ja/scenario_format/#sensormodel","title":"SensorModel","text":"<p>autoware_launch/launch/logging_simulator.launch.xml \u306e\u5f15\u6570\u306e sensor_model \u3092\u6307\u5b9a\u3059\u308b</p>"},{"location":"ja/scenario_format/#vehiclemodel","title":"VehicleModel","text":"<p>autoware_launch/launch/logging_simulator.launch.xml \u306e\u5f15\u6570\u306e vehicle_model \u3092\u6307\u5b9a\u3059\u308b</p>"},{"location":"ja/scenario_format/#publish_profile","title":"publish_profile","text":"<p>(\u30aa\u30d7\u30b7\u30e7\u30f3) Publish\u3059\u308b\u30c8\u30d4\u30c3\u30af\u3092\u5236\u5fa1\u3059\u308b\u305f\u3081\u306e\u30c8\u30d4\u30c3\u30af\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u540d\u3092\u6307\u5b9a\u3059\u308b\u3002\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30d5\u30a1\u30a4\u30eb\u306f <code>config/publish/{profile_name}.yaml</code> \u306b\u914d\u7f6e\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3001\u4f8b: <code>planning_control</code>\u3002\u6307\u5b9a\u3057\u306a\u3044\u5834\u5408\u306f\u3001Rosbag\u4e2d\u3059\u3079\u3066\u306e\u30c8\u30d4\u30c3\u30af\u304cPublish\u3055\u308c\u308b\u3002</p>"},{"location":"ja/scenario_format/#evaluation","title":"Evaluation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u8a55\u4fa1\u6761\u4ef6\u3092\u5b9a\u7fa9\u3059\u308b\u3002</p>"},{"location":"ja/scenario_format/#usecasename","title":"UseCaseName","text":"<p>\u8a55\u4fa1\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u6307\u5b9a\u3059\u308b\u3002</p> <p>\u3053\u3053\u3067\u6307\u5b9a\u3055\u308c\u305f\u540d\u524d\u3068\u540c\u3058\u540d\u524d\u306e\u8a55\u4fa1\u30ce\u30fc\u30c9\u3092\u547c\u3073\u51fa\u3059\u3053\u3068\u3067\u8a55\u4fa1\u304c\u5b9f\u884c\u3055\u308c\u308b\u3002</p>"},{"location":"ja/scenario_format/#usecaseformatversion","title":"UseCaseFormatVersion","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u60c5\u5831\u3092\u8a18\u8ff0\u3059\u308b\u3002\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u7528\u3044\u308b\u3002 \u30e1\u30b8\u30e3\u30fc\u30d0\u30fc\u30b8\u30e7\u30f3\u304c 1 \u306b\u306a\u308b\u307e\u3067\u306f\u3001\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306e\u66f4\u65b0\u306e\u5ea6\u306b\u30de\u30a4\u30ca\u30fc\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u66f4\u65b0\u3059\u308b\u3002\u521d\u671f\u30d0\u30fc\u30b8\u30e7\u30f3\u306f 0.1.0\u3002</p>"},{"location":"ja/scenario_format/#conditions","title":"Conditions","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u6bce\u306b\u8a2d\u5b9a\u3067\u304d\u308b\u6761\u4ef6\u3092\u6307\u5b9a\u3059\u308b\u3002</p> <p>\u6307\u5b9a\u53ef\u80fd\u306a\u6761\u4ef6\u306f\u5404\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3092\u53c2\u7167\u3002</p>"},{"location":"ja/scenario_format/#datasets","title":"Datasets","text":"<p>\u8907\u6570\u500b\u306eDataset\u3092\u8a18\u8ff0\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3042\u308b\u304c\u3001\u8907\u6570\u500b\u306eDataset\u306b\u5bfe\u3057\u3066\u3001\u540c\u3058\u8a55\u4fa1\u6761\u4ef6\u3067\u4f7f\u7528\u3059\u308b\u5834\u5408\u306e\u307f\u5229\u7528\u3067\u304d\u308b\u3002 \u8907\u6570\u500b\u306eDataset\u3092\u8a18\u8ff0\u3057\u305f\u5834\u5408\u306f\u3001\u5229\u7528\u3057\u305f\u3044dataset\u306eindex\u3092launch\u306e\u8d77\u52d5\u5f15\u6570\u306b\u6e21\u3059\u5fc5\u8981\u304c\u3042\u308b\u3002 index\u306f0\u756a\u304b\u3089\u59cb\u307e\u308b\u3002 \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c1\u500b\u306e\u5834\u5408\u306fdataset_index:=0\u3068\u3057\u3066\u3082\u3088\u3044\u3002</p> <pre><code># \u30b7\u30ca\u30ea\u30aa\u306b\u8a18\u8ff0\u3057\u305fdataset\u6570\u304c1\u500b\u306e\u5834\u5408\u3002dataset_index:=0\u306f\u7701\u7565\u53ef\u80fd\nros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=${scenario_path} [dataset_index:=0]\n\n# \u30b7\u30ca\u30ea\u30aa\u306b\u8a18\u8ff0\u3057\u305fdataset\u6570\u304c\u8907\u6570\u306e\u5834\u5408\nros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=${scenario_path} dataset_index:=${index_number}\n</code></pre>"},{"location":"ja/scenario_format/#datasetname","title":"DatasetName","text":"<p>t4_dataset\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u540d</p>"},{"location":"ja/scenario_format/#vehicleid","title":"VehicleId","text":"<p>autoware_launch/launch/logging_simulator.launch.xml \u306e\u5f15\u6570\u306e vehicle_id \u3092\u6307\u5b9a\u3059\u308b\u3002</p> <p>\u8eca\u4e21 ID \u304c\u4e0d\u660e\u306a\u5834\u5408\u306f\u3001<code>default</code> \u3092\u8a2d\u5b9a\u3059\u308b\u3002</p>"},{"location":"ja/scenario_format/#include_use_case","title":"include_use_case","text":"<p>Evaluation\u3067\u6307\u5b9a\u3057\u305f\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3068\u306f\u5225\u306e\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306e\u8a55\u4fa1\u3092\u540c\u6642\u306b\u884c\u3046\u5834\u5408\u306b\u4f7f\u7528\u3059\u308b\u3002 \u3053\u3053\u306b\u8a18\u8f09\u3057\u305fuse_case\u306e\u30ce\u30fc\u30c9\u304c\u81ea\u52d5\u3067\u7acb\u3061\u4e0a\u304c\u308b\u308f\u3051\u3067\u306f\u306a\u3044\u3002</p> <p>\u5404use_case\u306eevaluator\u30ce\u30fc\u30c9\u306binclude_use_case\u3067\u6307\u5b9a\u3055\u308c\u305f\u6761\u4ef6\u3067\u8a55\u4fa1\u3059\u308b\u51e6\u7406\u3092\u8ffd\u52a0\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002 Evaluator\u3067\u306f\u3001result.jsonl\u306e\u6700\u7d42\u884c\u3092\u51e6\u7406\u3057\u3066\u3001\u6210\u5426\u306e\u5224\u5b9a\u304c\u884c\u308f\u308c\u308b\u306e\u3067\u3001Evaluation\u306e\u7d50\u679cresult.jsonl\u3068\u3001include_use_case\u3067\u51fa\u529b\u3055\u308c\u308bresult.jsonl\u306e\u7d50\u679c\u3092post_process\u3067\u30de\u30fc\u30b8\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002</p> <p>\u73fe\u72b6\u3001planning_control\u3067diagnostics\u3092\u8a55\u4fa1\u3059\u308b\u6a5f\u80fd\u304c\u5b9f\u88c5\u3055\u308c\u3066\u3044\u308b\u3002</p>"},{"location":"ja/trouble_shooting/","title":"\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":"<p>\u671f\u5f85\u901a\u308a\u306b\u52d5\u304b\u306a\u3044\u5834\u5408\u306b\u78ba\u8a8d\u3059\u308b</p>"},{"location":"ja/trouble_shooting/#autoware","title":"Autoware\u304c\u8d77\u52d5\u3057\u306a\u3044","text":""},{"location":"ja/trouble_shooting/#1","title":"\u539f\u56e01","text":"<p>\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305fsensor_model\u3001vehicle_model\u3001vehicle_id\u304c\u5229\u7528\u3059\u308bAutoware\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306b\u542b\u307e\u308c\u3066\u3044\u306a\u3044\u3002</p>"},{"location":"ja/trouble_shooting/#1_1","title":"\u4f8b1","text":"<pre><code>\u276f ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=$HOME/driving_log_replayer_v2/sample.yaml\n[INFO] [launch]: All log files can be found below /home/hyt/.ros/log/2024-06-07-12-37-19-365597-dpc2405001-1360746\n[INFO] [launch]: Default logging verbosity is set to INFO\n1717731451.040883 [77]       ros2: determined eno1 (udp/10.0.55.137) as highest quality interface, selected for automatic interface.\n[ERROR] [launch]: Caught exception in launch (see debug for traceback): executed command failed. Command: xacro /home/hyt/ros_ws/pilot-auto/install/tier4_vehicle_launch/share/tier4_vehicle_launch/urdf/vehicle.xacro vehicle_model:=sample_vehicle sensor_model:=sample_sensor_kit config_dir:=/home/hyt/ros_ws/pilot-auto/install/individual_params/share/individual_params/config/default/sample_sensor_kit\nCaptured stderr output: error: package not found: \"package 'sample_sensor_kit_description' not found, searching: ...\n...\n</code></pre>"},{"location":"ja/trouble_shooting/#1_2","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62401","text":"<p>\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u3067\u6307\u5b9a\u3057\u3066\u3044\u308bautoware_path\u306b\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u3001sensor_model\u3001vehicle_model\u3001vehicle_id\u304c\u5b58\u5728\u3059\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p>"},{"location":"ja/trouble_shooting/#autoware_1","title":"Autoware\u8d77\u52d5\u5f8c\u3059\u3050\u306b\u7d42\u4e86\u3057\u3066\u3057\u307e\u3046","text":""},{"location":"ja/trouble_shooting/#_2","title":"\u539f\u56e0","text":"<p>\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u304c\u4e0d\u6b63</p>"},{"location":"ja/trouble_shooting/#_3","title":"\u4f8b","text":"<p>\u30b3\u30f3\u30bd\u30fc\u30eb\u306b\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u51fa\u529b\u3055\u308c\u308b\u3002 \u307e\u305f\u3001\u540c\u69d8\u306e\u5185\u5bb9\u304cresult.jsonl\u306b\u51fa\u529b\u3055\u308c\u308b</p> <pre><code>[localization_evaluator_node.py-55] [ERROR] [1717734608.157798307] [driving_log_replayer_v2.localization_evaluator]: An error occurred while loading the scenario. 1 validation error for LocalizationScenario\n[localization_evaluator_node.py-55] Evaluation.UseCaseFormatVersion\n[localization_evaluator_node.py-55]   Input should be '1.2.0' or '1.3.0' [type=literal_error, input_value='1.0.0', input_type=str]\n[localization_evaluator_node.py-55]     For further information visit https://errors.pydantic.dev/2.7/v/literal_error\n\nscenario: direct\n--------------------------------------------------\nTestResult: Failed\nScenarioFormatError\n--------------------------------------------------\n</code></pre> <pre><code>{\"Condition\":{}}\n{\"Result\":{\"Success\":false,\"Summary\":\"NoData\"},\"Stamp\":{\"System\":1717734608.157981},\"Frame\":{}}\n{\"Result\":{\"Success\":false,\"Summary\":\"ScenarioFormatError\"},\"Stamp\":{\"System\":0},\"Frame\":{\"ErrorMsg\":\"1 validation error for LocalizationScenario\\nEvaluation.UseCaseFormatVersion\\n  Input should be '1.2.0' or '1.3.0' [type=literal_error, input_value='1.0.0', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.7/v/literal_error\"}}\n</code></pre>"},{"location":"ja/trouble_shooting/#_4","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u6240","text":"<p>result.jsonl\u306b\u4f55\u304c\u554f\u984c\u304b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u6307\u793a\u901a\u308a\u6cbb\u3059\u3002 \u4f8b\u3060\u3068\u3001UseCaseFormatVersion\u306f1.2.0\u304b1.3.0\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308b\u306e\u306b\u30011.0.0\u306a\u306e\u3067\u5229\u7528\u3067\u304d\u306a\u3044\u3002 \u53e4\u3044\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u5229\u7528\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u30ea\u30dd\u30b8\u30c8\u30ea\u306esample\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u3042\u308b\u30b7\u30ca\u30ea\u30aa\u3092\u53c2\u8003\u306b\u4fee\u6b63\u3059\u308b\u3002</p>"},{"location":"ja/trouble_shooting/#nodata","title":"\u8a55\u4fa1\u7d50\u679c\u304cNoData\u3068\u306a\u308b","text":""},{"location":"ja/trouble_shooting/#1_3","title":"\u539f\u56e01","text":"<p>Autoware\u304b\u3089\u8a55\u4fa1\u5bfe\u8c61\u306etopic\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u306a\u3044</p>"},{"location":"ja/trouble_shooting/#1-1","title":"\u4f8b1-1","text":"<p>\u8a55\u4fa1\u5bfe\u8c61\u306etopic\u3092\u51fa\u529b\u3059\u308b\u30ce\u30fc\u30c9\u304claunch\u304b\u3089\u8d77\u52d5\u3055\u308c\u3066\u3044\u306a\u3044 launch\u30d5\u30a1\u30a4\u30eb\u306etrue/false\u306e\u5024\u306e\u8a2d\u5b9a\u9593\u9055\u3044</p>"},{"location":"ja/trouble_shooting/#1-1_1","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62401-1","text":"<p>\u8a55\u4fa1\u5bfe\u8c61\u306etopic\u3092\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u304b\u3089\u63a2\u3057\u3066\u3001topic info\u3057\u3066publisher\u304c\u5b58\u5728\u3059\u308b\u304b\u78ba\u8a8d\u3059\u308b Publisher count: 0\u306e\u5834\u5408\u306f\u3001\u305d\u3082\u305d\u3082\u8d77\u52d5\u3067\u304d\u3066\u306a\u3044\u53ef\u80fd\u6027\u304c\u9ad8\u3044\u3002</p> <pre><code>\u276f ros2 topic info /perception/traffic_light_recognition/traffic_signals -v\nType: autoware_auto_perception_msgs/msg/TrafficSignalArray\n\nPublisher count: 1 &lt;- 0\u3058\u3083\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\n\nNode name: crosswalk_traffic_light_estimator\nNode namespace: /perception/traffic_light_recognition\nTopic type: autoware_auto_perception_msgs/msg/TrafficSignalArray\nEndpoint type: PUBLISHER\nGID: 01.10.d8.43.57.21.7c.2d.98.25.db.df.00.00.46.03.00.00.00.00.00.00.00.00\nQoS profile:\n  Reliability: RELIABLE\n  History (Depth): KEEP_LAST (1)\n  Durability: VOLATILE\n  Lifespan: Infinite\n  Deadline: Infinite\n  Liveliness: AUTOMATIC\n  Liveliness lease duration: Infinite\n</code></pre>"},{"location":"ja/trouble_shooting/#1-2","title":"\u4f8b1-2","text":"<p>\u30ce\u30fc\u30c9\u304claunch\u3067\u8d77\u52d5\u306f\u3057\u3066\u3044\u308b\u304c\u3001\u8d77\u52d5\u5f8c\u3059\u3050\u306b\u6b7b\u3093\u3067\u3044\u308b</p>"},{"location":"ja/trouble_shooting/#1-2_1","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62401-2","text":"<p>\u8d77\u52d5\u3057\u305f\u30bf\u30fc\u30df\u30ca\u30eb\u3001\u307e\u305f\u306f\u3001console.log\u3092ERROR\u3067\u691c\u7d22\u3059\u308b\u3002</p> <p>\u4ee5\u4e0b\u306f\u3001\u70b9\u7fa4\u304c\u4e00\u5207\u51fa\u306a\u304b\u3063\u305f\u30b1\u30fc\u30b9\u306e\u30ed\u30b0\u3067\u3042\u308b\u3002 ERROR\u3067\u691c\u7d22\u3059\u308b\u3068pointcloud_preprocessor\u304c\u6b7b\u3093\u3067\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308b\u3002 topic\u3092\u51fa\u529b\u3059\u308bcomponent_container\u304c\u30a8\u30e9\u30fc\u3092\u5410\u3044\u3066\u306a\u3044\u304b\u78ba\u8a8d\u3059\u308b\u3002</p> <pre><code>[ERROR] [component_container_mt-18]: process has died [pid 95, exit code -6, cmd '/opt/ros/galactic/lib/rclcpp_components/component_container_mt --ros-args -r __node:=pointcloud_preprocessor_container -r __ns:=/sensing/lidar/pointcloud_preprocessor --params-file /tmp/launch_params_rh_9gxcs'].\n</code></pre>"},{"location":"ja/trouble_shooting/#1-3","title":"\u4f8b1-3","text":"<p>cuda, cuDNN, TensorRT\u306e\u4e0d\u6574\u5408\u304c\u767a\u751f\u3057\u3066\u7d50\u679c\u3068\u3057\u3066\u3001perception\u306e\u8a8d\u8b58\u7d50\u679c\u304c\u51fa\u3066\u3053\u306a\u3044\u3002 apt upgrade\u3067nvidia driver\u304c\u66f4\u65b0\u3055\u308c\u305f\u3068\u304d\u306b\u767a\u751f\u3059\u308b\u3053\u3068\u304c\u3042\u308b\u3002</p> <pre><code>hyt@dpc1909014-2204:~/ros_ws/awf$ ros2 launch lidar_centerpoint lidar_centerpoint.launch.xml model_name:=centerpoint_tiny model_path:=/home/hyt/autoware_data/lidar_centerpoint model_param_path:=$(ros2 pkg prefix lidar_centerpoint --share)/config/centerpoint_tiny.param.yaml build_only:=true\n[INFO] [launch]: All log files can be found below /home/hyt/.ros/log/2024-01-22-14-36-04-069409-dpc1909014-2204-3835027\n[INFO] [launch]: Default logging verbosity is set to INFO\n[INFO] [lidar_centerpoint_node-1]: process started with pid [3835028]\n[lidar_centerpoint_node-1] 1705901764.307868 [77] lidar_cent: determined enp4s0 (udp/10.0.53.59) as highest quality interface, selected for automatic interface.\n[lidar_centerpoint_node-1] terminate called after throwing an instance of 'thrust::system::system_error'\n[lidar_centerpoint_node-1]   what():  This program was not compiled for SM 75\n[lidar_centerpoint_node-1] : cudaErrorInvalidDevice: invalid device ordinal\n[ERROR] [lidar_centerpoint_node-1]: process has died [pid 3835028, exit code -6, cmd '/home/hyt/ros_ws/awf/install/lidar_centerpoint/lib/lidar_centerpoint/lidar_centerpoint_node --ros-args -r __node:=lidar_centerpoint --params-file /tmp/launch_params_60_o26mq --params-file /tmp/launch_params_79jodq9o --params-file /tmp/launch_params_spwl7uq2 --params-file /tmp/launch_params_ur_yt_y2 --params-file /tmp/launch_params_iqs0hf9o --params-file /tmp/launch_params_t6bo4aow --params-file /tmp/launch_params_ufdn98_7 --params-file /tmp/launch_params_7m7aj130 --params-file /tmp/launch_params_yr4emr64 --params-file /tmp/launch_params_u4_e0ngh --params-file /home/hyt/ros_ws/awf/install/lidar_centerpoint/share/lidar_centerpoint/config/centerpoint_tiny.param.yaml --params-file /home/hyt/ros_ws/awf/install/lidar_centerpoint/share/lidar_centerpoint/config/detection_class_remapper.param.yaml -r ~/input/pointcloud:=/sensing/lidar/pointcloud -r ~/output/objects:=objects'].\n</code></pre>"},{"location":"ja/trouble_shooting/#1-3_1","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62401-3","text":"<p>cudaErrorInvalidDevice: invalid device ordinal\u304c\u51fa\u3066\u306a\u3044\u304b\u78ba\u8a8d\u3059\u308b\u3002 \u51fa\u3066\u3044\u305f\u3089\u3001nvidia-driver, cuda, cuDNN, TensorRT\u3092\u518d\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002</p> <pre><code>sudo apt-mark unhold cuda-*\nsudo apt-mark unhold nvidia-*\nsudo apt-mark unhold libcudnn*\nsudo apt-mark unhold libnv*\n\nsudo apt purge cuda-*\nsudo apt purge nvidia-*\nsudo apt purge libcudnn*\nsudo apt purge libnv*\n\n# install nvidia driver and run Autoware's setup-dev-env.sh\n</code></pre>"},{"location":"ja/trouble_shooting/#2","title":"\u539f\u56e02","text":"<p>Autoware\u304b\u3089\u8a55\u4fa1\u5bfe\u8c61\u306etopic\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304c\u30ce\u30fc\u30c9\u304csubscribe\u3067\u304d\u306a\u3044\u3002</p>"},{"location":"ja/trouble_shooting/#2-1","title":"\u4f8b2-1","text":"<p>QoS\u306e\u4e0d\u4e00\u81f4\u3067\u53d6\u5f97\u3067\u304d\u3066\u3044\u306a\u3044</p> <pre><code>[component_container_mt-13] [WARN 1633081042.510824100] [localization.util.random_downsample_filter]: New subscription discovered on topic '/localization/util/downsample/pointcloud', requesting incompatible QoS. No messages will be sent to it. Last incompatible policy: RELIABILITY_QOS_POLICY\n[component_container_mt-19] [WARN 1633081042.593132498] [sensing.lidar.occupancy_grid_map_outlier_filter]: New subscription discovered on topic '/sensing/lidar/no_ground/pointcloud', requesting incompatible QoS. No messages will be sent to it. Last incompatible policy: RELIABILITY_QOS_POLICY\n[component_container_mt-19] [WARN 1633081042.597116410] [sensing.lidar.concatenate_data]: New subscription discovered on topic '/sensing/lidar/concatenated/pointcloud', requesting incompatible QoS. No messages will be sent to it. Last incompatible policy: RELIABILITY_QOS_POLICY\n</code></pre>"},{"location":"ja/trouble_shooting/#2-1_1","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62402-1","text":"<p>\u8d77\u52d5\u3057\u305f\u30bf\u30fc\u30df\u30ca\u30eb\u3082\u3057\u304f\u306f\u3001console.log\u3092QoS\u3067\u691c\u7d22\u3059\u308b\u3002</p> <p>Autoware\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3068driving_log_replayer_v2\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u304c\u5bfe\u5fdc\u3057\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002 Autoware Foundation\u306emain\u3068driving_log_replayer_v2\u306emain\u3092\u4f7f\u7528\u3057\u3066\u3001\u3053\u306e\u554f\u984c\u304c\u767a\u751f\u3057\u3066\u3044\u308b\u5834\u5408\u3001github\u306eissue\u3067\u5831\u544a\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"ja/trouble_shooting/#2-2","title":"\u4f8b2-2","text":"<p>\u30e1\u30c3\u30bb\u30fc\u30b8\u578b\u306e\u4e0d\u4e00\u81f4\u3067\u53d6\u5f97\u3067\u304d\u3066\u3044\u306a\u3044\u3002 Autoware\u304c\u51fa\u529b\u3059\u308b\u578b\u304cdriving_log_replayer_v2\u304c\u671f\u5f85\u3057\u3066\u3044\u308b\u578b\u3068\u7570\u306a\u3063\u3066\u3044\u308b\u305f\u3081\u306b\u767a\u751f\u3059\u308b\u3002</p> <p>2024\u5e746\u6708\u306bautoware_auto_msg\u304b\u3089autoware_msg\u306b\u5909\u66f4\u3055\u308c\u305f\u3002\u3053\u308c\u306b\u3088\u3063\u3066\u3001autoware\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3068driving_log_replayer_v2\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u304c\u5bfe\u5fdc\u3057\u3066\u3044\u306a\u3044\u3068\u3053\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u3067\u308b\u3002</p> <pre><code>[ros2-67] [ERROR] [1717610261.542314281] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610261.721551659] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610261.903905941] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610262.084860123] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610262.263855979] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610262.442275790] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n</code></pre>"},{"location":"ja/trouble_shooting/#2-2_1","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62402-2","text":"<p>\u5927\u304d\u306a\u6a5f\u80fd\u5909\u66f4\u304c\u3042\u308b\u5834\u5408\u3001driving_log_replayer_v2\u306eReleaseNotes.md\u306bAutoware\u306e\u5fc5\u8981\u306a\u6a5f\u80fd(PR\u756a\u53f7\u7b49)\u304c\u8a18\u8f09\u3057\u3066\u3042\u308b\u3002 \u5229\u7528\u3059\u308bAutoware\u306b\u5fc5\u8981\u306a\u6a5f\u80fd\u304c\u5165\u3063\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p> <p>Autoware Foundation\u306emain\u3068driving_log_replayer_v2\u306emain\u3092\u4f7f\u7528\u3057\u3066\u3001\u3053\u306e\u554f\u984c\u304c\u767a\u751f\u3057\u3066\u3044\u308b\u5834\u5408\u3001github\u306eissue\u3067\u5831\u544a\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"ja/trouble_shooting/#_5","title":"\u8a55\u4fa1\u6570\u304c\u7570\u5e38\u306b\u5c11\u306a\u3044","text":""},{"location":"ja/trouble_shooting/#1_4","title":"\u539f\u56e01","text":"<p>PC\u306e\u6027\u80fd\u4e0d\u8db3\u3067Autoware\u304c\u6240\u5b9a\u306e\u5468\u671f(\u70b9\u7fa4\u306a\u308910Hz)\u3067topic\u3092publish\u51fa\u6765\u3066\u3044\u306a\u3044\u3002</p>"},{"location":"ja/trouble_shooting/#1_5","title":"\u4f8b1","text":"<pre><code>\u276f ros2 topic hz /perception/obstacle_segmentation/pointcloud\n1718083964.779455 [77]       ros2: determined eno1 (udp/10.0.55.137) as highest quality interface, selected for automatic interface.\naverage rate: 5.619\n min: 0.109s max: 0.207s std dev: 0.03246s window: 7\naverage rate: 5.333\n min: 0.109s max: 0.214s std dev: 0.02783s window: 12\n</code></pre>"},{"location":"ja/trouble_shooting/#1_6","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62401","text":"<p>\u5bfe\u8c61\u306etopic\u304c\u671f\u5f85\u901a\u308a\u306e\u5468\u671f\u3067\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304bros2 topic hz\u3067\u78ba\u8a8d\u3059\u308b\u3002 play_rate\u304c0.5\u3067\u3042\u308c\u307010*0.5=5\u3067\u6b63\u5e38\u3067\u3042\u308b\u3053\u3068\u306b\u6ce8\u610f\u3002</p> <p>\u51fa\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u3001play_rate\u5f15\u6570\u3092\u4f4e\u304f\u3059\u308b</p> <pre><code>ros2 launch driving_log_replayer_v2 driving_log_replayer_v2 scenario_path:=$HOME/driving_log_replayer_v2/sample.yaml play_rate:=0.2\n</code></pre>"},{"location":"ja/trouble_shooting/#2_1","title":"\u539f\u56e02","text":"<p>topic\u304csimulation\u958b\u59cb\u6642\u70b9\u3067\u306f\u51fa\u3066\u3053\u305a\u306b\u3001simulation\u306e\u7d42\u308f\u308a\u9803\u306b\u3088\u3046\u3084\u304f\u51fa\u3066\u304f\u308b\u3002 \u4e8b\u524d\u306bml model\u3092engine\u306b\u5909\u63db\u3057\u3066\u3044\u306a\u3044\u5834\u5408\u3001simulation\u5b9f\u884c\u6642\u306bengine\u5909\u63db\u304c\u59cb\u307e\u308a\u3001engine\u5909\u63db\u304c\u7d42\u308f\u3063\u305f\u3042\u3068\u306btopic\u304c\u51fa\u3066\u304f\u308b\u3002</p>"},{"location":"ja/trouble_shooting/#2_2","title":"\u4f8b2","text":"<pre><code>[component_container_mt-52] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +894, GPU +174, now: CPU 1009, GPU 852 (MiB)\n[component_container_mt-52] [I] [TRT] ----------------------------------------------------------------\n[component_container_mt-52] [I] [TRT] Input filename:   /home/autoware/autoware_data/traffic_light_classifier/traffic_light_classifier_mobilenetv2_batch_6.onnx\n[component_container_mt-52] [I] [TRT] ONNX IR version:  0.0.8\n[component_container_mt-52] [I] [TRT] Opset version:    11\n[component_container_mt-52] [I] [TRT] Producer name:    pytorch\n[component_container_mt-52] [I] [TRT] Producer version: 1.13.1\n[component_container_mt-52] [I] [TRT] Domain:\n[component_container_mt-52] [I] [TRT] Model version:    0\n[component_container_mt-52] [I] [TRT] Doc string:\n[component_container_mt-52] [I] [TRT] ----------------------------------------------------------------\n[component_container_mt-52] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 116, GPU 678 (MiB)\n\n[component_container_mt-52] [I] [TRT] Applying optimizations and building TRT CUDA engine. Please wait for a few minutes...\n</code></pre>"},{"location":"ja/trouble_shooting/#2_3","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62402","text":"<p>\u5b9f\u884c\u3057\u305f\u30bf\u30fc\u30df\u30ca\u30eb\u307e\u305f\u306fconsole.log\u306b\u4f8b\u306b\u793a\u3057\u305f\u3088\u3046\u306a\u30ed\u30b0\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002 \u51fa\u3066\u3044\u308b\u5834\u5408\u306f\u3001driving_log_replayer_v2\u3067\u8a55\u4fa1\u3092\u884c\u3046\u524d\u306b\u4e8b\u524d\u306bonnx\u304b\u3089engine\u306e\u5909\u63db\u3092\u884c\u3046\u3002</p> <p>logging_simulator.launch.xml\u3092perception:=true\u3067\u8d77\u52d5\u3057\u3066\u3057\u3070\u3089\u304f\u653e\u7f6e\u3059\u308b\u3002 \u307e\u305f\u306f\u3001\u30e2\u30c7\u30eb\u3060\u3051\u30d3\u30eb\u30c9\u3059\u308blaunch\u3092\u8d77\u52d5\u3059\u308b\u3002</p> <pre><code># \u8d77\u52d5\u3057\u3066\u3057\u3070\u3089\u304f\u653e\u7f6e\u3059\u308b\nros2 launch autoware_launch logging_simulator.launch.xml map_path:=$HOME/autoware_map/sample-map-planning vehicle_model:=sample_vehicle sensor_model:=sample_sensor_kit\n\n# lidar_centerpoint \u3092 build_only\u3067launch\u3092\u8d77\u52d5\nros2 launch lidar_centerpoint lidar_centerpoint.launch.xml model_name:=centerpoint_tiny model_path:=$HOME/autoware_data/lidar_centerpoint model_param_path:=$(ros2 pkg prefix lidar_centerpoint --share)/config/centerpoint_tiny.param.yaml build_only:=true\n</code></pre>"},{"location":"ja/trouble_shooting/#_6","title":"\u7d42\u4e86\u3057\u306a\u3044\u3001\u9014\u4e2d\u3067\u7d42\u4e86\u3059\u308b","text":""},{"location":"ja/trouble_shooting/#_7","title":"\u539f\u56e0","text":"<p>\u610f\u56f3\u3057\u306a\u3044\u5165\u529b\u30c7\u30fc\u30bf\u306a\u3069\u306b\u3088\u308a\u4f8b\u5916\u304c\u767a\u751f\u3057\u3066\u3001\u30ce\u30fc\u30c9\u304c\u6b62\u307e\u308b\u3002\u307e\u305f\u306f\u7d42\u4e86\u3059\u308b\u3002</p>"},{"location":"ja/trouble_shooting/#_8","title":"\u4f8b","text":"<p>perception\u306eobject\u306e\u4e2d\u8eab\u304c\u60f3\u5b9a\u3057\u305f\u901a\u308a\u306b\u306a\u3063\u3066\u304a\u3089\u305a\u306b\u4f8b\u5916\u304c\u51fa\u529b\u3055\u308c\u305f\u3002</p> <pre><code>[perception_evaluator_node.py-115] [ERROR] [1711460672.978143229] [driving_log_replayer_v2.perception_evaluator]: Unexpected footprint length: len(perception_object.shape.footprint.points)=2\n[perception_evaluator_node.py-115] Exception in thread Thread-2 (run_func):\n[perception_evaluator_node.py-115] Traceback (most recent call last):\n[perception_evaluator_node.py-115]   File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n[perception_evaluator_node.py-115]     self.run()\n[perception_evaluator_node.py-115]   File \"/usr/lib/python3.10/threading.py\", line 953, in run\n[perception_evaluator_node.py-115]     self._target(*self._args, **self._kwargs)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/lib/python3.10/site-packages/tf2_ros/transform_listener.py\", line 95, in run_func\n[perception_evaluator_node.py-115]     self.executor.spin()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 294, in spin\n[perception_evaluator_node.py-115]     self.spin_once()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 739, in spin_once\n[perception_evaluator_node.py-115]     self._spin_once_impl(timeout_sec)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 728, in _spin_once_impl\n[perception_evaluator_node.py-115]     handler, entity, node = self.wait_for_ready_callbacks(timeout_sec=timeout_sec)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 711, in wait_for_ready_callbacks\n[perception_evaluator_node.py-115]     return next(self._cb_iter)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 612, in _wait_for_ready_callbacks\n[perception_evaluator_node.py-115]     raise ExternalShutdownException()\n[perception_evaluator_node.py-115] rclpy.executors.ExternalShutdownException\n[ros2-117] [INFO] [1711460673.168213400] [rosbag2_recorder]: Subscribed to topic '/driving_log_replayer_v2/marker/results'\n[ros2-117] [INFO] [1711460673.174638594] [rosbag2_recorder]: Subscribed to topic '/driving_log_replayer_v2/marker/ground_truth'\n[simple_object_merger_node-69] [INFO] [1711460673.191825620] [sensing.radar.simple_object_merger]: waiting for object msg...\n[perception_evaluator_node.py-115] Traceback (most recent call last):\n[perception_evaluator_node.py-115]   File \"/home/autoware/autoware.proj/install/driving_log_replayer_v2/lib/driving_log_replayer_v2/perception_evaluator_node.py\", line 336, in &lt;module&gt;\n[perception_evaluator_node.py-115]     main()\n[perception_evaluator_node.py-115]   File \"/home/autoware/autoware.proj/install/driving_log_replayer_v2/local/lib/python3.10/dist-packages/driving_log_replayer_v2/evaluator.py\", line 448, in wrapper\n[perception_evaluator_node.py-115]     rclpy.shutdown()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/__init__.py\", line 126, in shutdown\n[perception_evaluator_node.py-115]     _shutdown(context=context)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/utilities.py\", line 58, in shutdown\n[perception_evaluator_node.py-115]     return context.shutdown()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/context.py\", line 100, in shutdown\n[perception_evaluator_node.py-115]     raise RuntimeError('Context must be initialized before it can be shutdown')\n[perception_evaluator_node.py-115] RuntimeError: Context must be initialized before it can be shutdown\n[perception_evaluator_node.py-115] The following exception was never retrieved: Expected BOUNDING_BOX, but got polygon, which should have footprint.\n</code></pre>"},{"location":"ja/trouble_shooting/#_9","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u6240","text":"<p>\u8d77\u52d5\u3057\u305f\u30bf\u30fc\u30df\u30ca\u30eb\u304b\u3001console.log\u3092evaluator\u306e\u6587\u5b57\u5217\u3067\u691c\u7d22\u3057\u3066\u3001\u4f8b\u306e\u3088\u3046\u306b\u4f8b\u5916\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u306a\u3044\u304b\u78ba\u8a8d\u3059\u308b\u3002</p>"},{"location":"ja/use_case/all_components/","title":"\u5168\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u306e\u8a55\u4fa1","text":"<p>Autoware\u306e\u5168\u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3092\u52d5\u4f5c\u3055\u305b\u3066\u3001\u6b63\u5e38\u306btopic\u304c\u51fa\u529b\u3055\u308c\u308b\u304b\u3001\u307e\u305f\u51fa\u529b\u30ec\u30fc\u30c8\u304c\u5b89\u5b9a\u3057\u3066\u3044\u308b\u304b\u3092\u30c6\u30b9\u30c8\u3059\u308b\u3002</p>"},{"location":"ja/use_case/all_components/#_2","title":"\u5b9f\u884c\u65b9\u6cd5","text":"<p>launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u308b\u3002\u8a55\u4fa1\u306f\u884c\u308f\u305a\u3001\u5f8c\u89e3\u6790\u306e\u305f\u3081\u306ebag\u30d5\u30a1\u30a4\u30eb\u3092\u8a18\u9332\u306e\u307f\u884c\u3046\u3002</p> <ol> <li>launch \u3067 <code>logging_simulator.launch</code>\u3068<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001\u5404component\u304ctopic\u3092\u51fa\u529b\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066bag record\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/all_components/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<ul> <li>sensing: true</li> <li>perception: true</li> <li>planning: true</li> <li>control: true</li> <li>localization: true</li> <li>pose_source: ndt</li> <li>twist_source: gyro_odom</li> </ul>"},{"location":"ja/use_case/all_components/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/all_components/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /localization/kinematic_state nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>CAN \u306e\u4ee3\u308f\u308a\u306b vehicle \u306e topic \u3092\u542b\u3081\u3066\u3082\u826f\u3044\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /localization/kinematic_state nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_auto_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_auto_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_auto_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_auto_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_auto_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/all_components/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/all_components/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/all_components/#_3","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/all_components/#_4","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u306e\u5185\u5bb9\u306f\u5e38\u306b\u540c\u3058\u3002</p> <p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/annotationless_perception/","title":"Annotationless\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1","text":"<p>perception_online_evaluator\u3092\u5229\u7528\u3057\u3066\u3001Autoware\u306e\u8a8d\u8b58\u6a5f\u80fd(perception)\u3092\u3001\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u306a\u3057\u3067\u8a55\u4fa1\u3059\u308b\u3002</p> <p>\u4ee5\u4e0b\u306ePR\u306e\u6a5f\u80fd\u3092\u6301\u3064Autoware\u304c\u5fc5\u8981\u3002 https://github.com/autowarefoundation/autoware.universe/pull/6556</p>"},{"location":"ja/use_case/annotationless_perception/#_1","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p>launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>annotationless_perception_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001perception \u30e2\u30b8\u30e5\u30fc\u30eb\u304c\u8a8d\u8b58\u3092\u884c\u3046</li> <li>perception_online_evaluator \u304c <code>/perception/perception_online_evaluator/metrics</code>\u306b\u8a3a\u65ad\u7d50\u679c\u3092\u51fa\u529b\u3059\u308b</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c topic \u3092 subscribe \u3057\u3066\u3001\u5404\u57fa\u6e96\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3057\u3066\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/annotationless_perception/#_2","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>perception_online_evaluator\u304c\u51fa\u529b\u3059\u308btopic\u306f\u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u306e\u3088\u3046\u306a\u5f62\u5f0f\u3068\u306a\u3063\u3066\u3044\u308b\u3002 topic\u30b5\u30f3\u30d7\u30eb</p> <p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u8a8d\u8b58\u30af\u30e9\u30b9\u6bce\u306b\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <p>\u5168\u3066\u306e\u30af\u30e9\u30b9\u3067\u6b63\u5e38\u3068\u306a\u3063\u305f\u5834\u5408\u3001\u30c6\u30b9\u30c8\u306f\u6b63\u5e38\u3068\u306a\u308b\u3002</p>"},{"location":"ja/use_case/annotationless_perception/#_3","title":"\u6b63\u5e38","text":"<p>\u5224\u5b9a\u306b\u306f\u3001\u30b7\u30ca\u30ea\u30aa\u307e\u305f\u306flaunch\u306e\u5f15\u6570\u3067\u6307\u5b9a\u3055\u308c\u305f\u4ee5\u4e0b\u306e2\u3064\u306e\u5024\u3092\u5229\u7528\u3059\u308b\u3002</p> <ul> <li>\u95be\u5024</li> <li>\u5408\u683c\u7bc4\u56f2(\u95be\u5024\u3092\u88dc\u6b63\u3059\u308b\u4fc2\u6570)</li> </ul> <p><code>/perception/perception_online_evaluator/metrics</code> \u306estatus.name\u6bce\u306b\u4ee5\u4e0b\u306e\u30eb\u30fc\u30eb\u306b\u5f93\u3044\u6210\u5426\u306e\u5224\u5b9a\u304c\u884c\u308f\u308c\u308b\u3002 \u95be\u5024\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u306a\u3044\u9805\u76ee(min, max, mean)\u306b\u95a2\u3057\u3066\u306f\u5e38\u306b\u6b63\u5e38\u3068\u5224\u5b9a\u3055\u308c\u308b\u3002\u6307\u5b9a\u304c\u3042\u308b\u3082\u306e\u306e\u307f\u304c\u8a55\u4fa1\u5bfe\u8c61\u306b\u306a\u308b\u3002</p>"},{"location":"ja/use_case/annotationless_perception/#min","title":"min","text":"<p>\u95be\u5024\u00d7\u4e0b\u9650\u5024\u3000\uff1c\uff1d\u3000min\u306e\u6700\u5c0f\u5024\u3000\uff1c\uff1d\u3000\u95be\u5024\u00d7\u4e0a\u9650\u5024\u3067\u3042\u308c\u3070\u6b63\u5e38\u3068\u3059\u308b\u3002</p>"},{"location":"ja/use_case/annotationless_perception/#max","title":"max","text":"<p>\u95be\u5024\u00d7\u4e0b\u9650\u5024\u3000\uff1c\uff1d\u3000max\u306e\u6700\u5927\u5024\u3000\uff1c\uff1d\u3000\u95be\u5024\u00d7\u4e0a\u9650\u5024\u3067\u3042\u308c\u3070\u6b63\u5e38\u3068\u3059\u308b\u3002</p> <p>\u4e0b\u9650\u5024\u306f0.0\u306b\u3059\u308b\u3053\u3068\u3092\u63a8\u5968</p>"},{"location":"ja/use_case/annotationless_perception/#mean","title":"mean","text":"<p>\u95be\u5024\u00d7\u4e0b\u9650\u5024\u3000\uff1c\uff1d\u3000mean\u306e\u5e73\u5747\u5024\u3000\uff1c\uff1d\u3000\u95be\u5024\u00d7\u4e0a\u9650\u5024\u3067\u3042\u308c\u3070\u6b63\u5e38\u3068\u3059\u308b\u3002</p>"},{"location":"ja/use_case/annotationless_perception/#metric_value","title":"metric_value","text":"<p>\u95be\u5024\u00d7\u4e0b\u9650\u5024\u3000\uff1c\uff1d\u3000metric_value\u306e\u5024\u3000\uff1c\uff1d\u3000\u95be\u5024\u00d7\u4e0a\u9650\u5024\u3067\u3042\u308c\u3070\u6b63\u5e38\u3068\u3059\u308b\u3002</p> <p>metric_value\u306f\u73fe\u5728\u306e\u5024\u3060\u3051\u3067\u5224\u5b9a\u3055\u308c\u3001min, max, mean\u306emetrics\u306e\u5024\u3092\u66f4\u65b0\u3057\u306a\u3044\u3002</p> <p>\u30a4\u30e1\u30fc\u30b8\u56f3\u3092\u4ee5\u4e0b\u306b\u793a\u3059 </p>"},{"location":"ja/use_case/annotationless_perception/#_4","title":"\u7570\u5e38","text":"<p>\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u3068\u304d</p>"},{"location":"ja/use_case/annotationless_perception/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> Topic name Data type /perception/perception_online_evaluator/metrics diagnostic_msgs/msg/DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"ja/use_case/annotationless_perception/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> <li>use_perception_online_evaluator: true</li> </ul>"},{"location":"ja/use_case/annotationless_perception/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/annotationless_perception/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /localization/kinematic_state nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>CAN \u306e\u4ee3\u308f\u308a\u306b vehicle \u306e topic \u3092\u542b\u3081\u3066\u3082\u826f\u3044\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /localization/kinematic_state nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_auto_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_auto_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_auto_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_auto_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_auto_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/annotationless_perception/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/annotationless_perception/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/annotationless_perception/#_5","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/annotationless_perception/#_6","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>\u4ee5\u4e0b\u306b\u3001\u305d\u308c\u305e\u308c\u306e\u8a55\u4fa1\u306e\u4f8b\u3092\u8a18\u8ff0\u3059\u308b\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <pre><code>{\n  \"Frame\": {\n    \"Ego\": {},\n    \"OBJECT_CLASSIFICATION\": {\n      // \u8a8d\u8b58\u3057\u305f\u30af\u30e9\u30b9\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" }, // Total\u3068Frame\u306e\u7d50\u679c\u306f\u540c\u3058\u3002\u4ed6\u306e\u8a55\u4fa1\u3068\u30c7\u30fc\u30bf\u69cb\u9020\u3092\u540c\u3058\u306b\u3059\u308b\u305f\u3081\u306b\u540c\u3058\u5024\u3092\u51fa\u529b\u3057\u3066\u3044\u308b\n      \"Info\": {\n        \"name_min_max_mean\": { \"min\": \"\u6700\u5c0f\u5024\", \"max\": \"\u6700\u5927\u5024\", \"mean\": \"\u5e73\u5747\u5024\" },\n        \"name_metric_value\": { \"metric_value\": \"\u5024\"},\n        ...\n      },\n      \"Metrics\": {\n        \"name_min_max_mean\": {\n          \"min\": \"min\u306e\u6700\u5c0f\u5024\",\n          \"max\": \"max\u306e\u6700\u5927\u5024\",\n          \"mean\": \"mean\u306e\u5e73\u5747\u5024\"\n        },\n        ...\n      }\n    }\n  }\n}\n</code></pre> <p>\u9805\u76ee\u306e\u610f\u5473\u306f\u4ee5\u4e0b\u306e\u56f3\u3092\u53c2\u7167</p> <p></p> <p></p>"},{"location":"ja/use_case/ar_tag_based_localizer/","title":"ArTagBasedLocalizer\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u306e\u8a55\u4fa1","text":"<p>Autoware \u306eArTagBasedLocalizer\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u304c\u5b89\u5b9a\u3057\u3066\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#_1","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p>launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>ar_tag_based_localizer_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u3092\u884c\u3046</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c topic \u3092 subscribe \u3057\u3066\u3001\u5404\u57fa\u6e96\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3057\u3066\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/ar_tag_based_localizer/#artagbasedlocalizer_1","title":"ArTagBasedLocalizer \u306e\u53ef\u7528\u6027","text":"<p>\u672c\u9805\u76ee\u3067\u306f\u3001ArTagBasedLocalizer\u306e\u53ef\u7528\u6027\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u3002\u3053\u308c\u306f\u3001\u306a\u3093\u3089\u304b\u306e\u4e8b\u60c5\u3067\u30ce\u30fc\u30c9\u304c\u843d\u3061\u308b\u30b1\u30fc\u30b9\u3092\u691c\u77e5\u3059\u308b\u3053\u3068\u3092\u76ee\u7684\u3068\u3059\u308b\u3002</p> <p>\u672c\u30c4\u30fc\u30eb\u306f\u3001\u4e0b\u8a18\u306e\u30c8\u30d4\u30c3\u30af\u3092\u76e3\u8996\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u305d\u306e\u60c5\u5831\u3092\u53d6\u5f97\u3059\u308b\u3002</p> <ul> <li>/diagnostics</li> </ul>"},{"location":"ja/use_case/ar_tag_based_localizer/#_2","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#_3","title":"\u53ef\u7528\u6027\u6b63\u5e38","text":"<p>ArTagBasedLocalizer Monitor\u304c\u51fa\u529b\u3059\u308b <code>/diagnostics</code> \u306e\u4e2d\u304b\u3089\u3001\u76e3\u8996\u30c8\u30d4\u30c3\u30af\u306b\u95a2\u3059\u308b\u60c5\u5831\u3092\u62bd\u51fa\u3059\u308b\u3002 \u6700\u65b0\u306e\u60c5\u5831\u306b\u304a\u3051\u308b<code>Number of Detected AR Tags</code>\u304c0\u4ee5\u4e0a\u3067\u3042\u308b\u5834\u5408\u3001\u6b63\u5e38\u3067\u3042\u308b\u3068\u5224\u65ad\u3059\u308b\u3002</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#_4","title":"\u53ef\u7528\u6027\u7570\u5e38","text":"<p>\u53ef\u7528\u6027\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs/msg/DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"ja/use_case/ar_tag_based_localizer/#service","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Service \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"service \u540d \u30c7\u30fc\u30bf\u578b /localization/initialize autoware_internal_localization_msgs/srv/InitializeLocalization"},{"location":"ja/use_case/ar_tag_based_localizer/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> <li>pose_source: artag</li> <li>twist_source: gyro_odom</li> </ul>"},{"location":"ja/use_case/ar_tag_based_localizer/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/ar_tag_based_localizer/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#_5","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#_6","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>\u4ee5\u4e0b\u306b\u3001\u305d\u308c\u305e\u308c\u306e\u8a55\u4fa1\u306e\u4f8b\u3092\u8a18\u8ff0\u3059\u308b\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>Availability\u306e\u7d50\u679c(Frame \u306e\u4e2d\u306b Availability \u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre>"},{"location":"ja/use_case/diagnostics/","title":"Diagnostics\u306e\u8a55\u4fa1","text":"<p>diagnostics\u304c\u6307\u5b9a\u306e\u6642\u9593\u306b\u6307\u5b9a\u306e\u30ec\u30d9\u30eb\u306b\u306a\u3063\u3066\u3044\u308b\u304b\u3092\u8a55\u4fa1\u3059\u308b</p> <p>\u985e\u4f3c\u306e\u8a55\u4fa1\u306bperformance_diag\u304c\u3042\u308b\u304c\u3001\u305d\u3061\u3089\u306fLiDAR\u306b\u7279\u5316\u3057\u3066\u3044\u308b\u3002 diagnostics_evaluator_node\u306f\u3001level\u3092\u8a55\u4fa1\u3059\u308b\u30b7\u30f3\u30d7\u30eb\u306a\u6a5f\u80fd\u3057\u304b\u306a\u3044\u304c\u3001\u4efb\u610f\u306estatus.name\u306b\u5bfe\u5fdc</p>"},{"location":"ja/use_case/diagnostics/#_1","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p>launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>diagnostics_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001<code>/diagnostics</code>\u306b\u8a3a\u65ad\u60c5\u5831\u3092\u51fa\u529b\u3059\u308b</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c topic \u3092 subscribe \u3057\u3066\u3001\u5404\u57fa\u6e96\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3057\u3066\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/diagnostics/#_2","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>\u53d7\u4fe1\u3057\u305fmsg\u306emsg.status[0].hardware_id\u304c\u30b7\u30ca\u30ea\u30aa\u306b\u6307\u5b9a\u3057\u305fhardware_id\u3068\u4e00\u81f4\u3057\u3001\u304b\u3064msg.header.stamp\u304c\u30b7\u30ca\u30ea\u30aa\u306b\u6307\u5b9a\u3057\u305f\u6642\u9593\u3092\u6e80\u305f\u3057\u3066\u3044\u308c\u3070\u8a55\u4fa1\u3055\u308c\u308b\u3002 \u8a55\u4fa1\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408\u306f\u3001\u30ed\u30b0\u3082\u51fa\u529b\u3055\u308c\u306a\u3044\u3002</p>"},{"location":"ja/use_case/diagnostics/#_3","title":"\u6b63\u5e38","text":"<p>msg.status\u306b\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305fname\u304b\u3064\u3001level\u3092\u6e80\u305f\u3059status\u304c\u5b58\u5728\u3057\u3066\u3044\u308b\u3002</p>"},{"location":"ja/use_case/diagnostics/#_4","title":"\u7570\u5e38","text":"<p>\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u3068\u304d</p>"},{"location":"ja/use_case/diagnostics/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs::msg::DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"ja/use_case/diagnostics/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<p>\u306a\u3057(\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u307e\u307e\u8d77\u52d5)</p> <p>bag\u306e\u4e2d\u306b\u5165\u3063\u3066\u3044\u308b\u3001/sensing/lidar/concatenated/pointcloud\u3092\u5229\u7528\u3059\u308b\u5834\u5408\u306f\u3001launch\u306e\u5f15\u6570\u306bsensing:=false\u3092\u8ffd\u52a0\u3059\u308b perception\u3001planning\u3082\u540c\u69d8\u306bbag\u304b\u3089\u51fa\u529b\u3059\u308b\u5834\u5408\u306f\u3001launch\u306e\u5f15\u6570\u306bperception:=false planning:=false\u3092\u8ffd\u52a0\u3059\u308b</p> <pre><code>ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=${daignostics_scenario_path} sensing:=false perception:=false planning:=false\n</code></pre>"},{"location":"ja/use_case/diagnostics/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/diagnostics/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"<p>\u3069\u306etopic\u304c\u5fc5\u8981\u304b\u306f\u3084\u308a\u305f\u3044\u3053\u3068\u6b21\u7b2c\u3002</p>"},{"location":"ja/use_case/diagnostics/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/diagnostics/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/diagnostics/#_5","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/diagnostics/#_6","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>\u4ee5\u4e0b\u306b\u3001\u305d\u308c\u305e\u308c\u306e\u8a55\u4fa1\u306e\u4f8b\u3092\u8a18\u8ff0\u3059\u308b\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>\u8a2d\u5b9a\u3057\u305f\u5168\u3066\u306e\u8a55\u4fa1\u6761\u4ef6\u3067\u6210\u529f\u3057\u3066\u3044\u308b\u5834\u5408\u306b\u6210\u529f\u3068\u5224\u5b9a\u3055\u308c\u308b\u3002</p> <pre><code>{\n  \"Frame\": {\n    \"Condition_IDNEX\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"TotalPassed\": \"\u8a55\u4fa1\u6761\u4ef6\u3092\u30d1\u30b9\u3057\u305ftopic\u306e\u7dcf\u6570\",\n        \"Level\": \"\u53d6\u5f97\u3057\u305fstatus\u306eLevel\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"ja/use_case/eagleye/","title":"Eagleye\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u306e\u8a55\u4fa1","text":"<p>Autoware \u306eEagleye\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u304c\u5b89\u5b9a\u3057\u3066\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p>"},{"location":"ja/use_case/eagleye/#_1","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p>launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>eagleye_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u3092\u884c\u3046</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c topic \u3092 subscribe \u3057\u3066\u3001\u5404\u57fa\u6e96\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3057\u3066\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/eagleye/#eagleye_1","title":"Eagleye \u306e\u53ef\u7528\u6027","text":"<p>\u672c\u9805\u76ee\u3067\u306f\u3001Eagleye\u306e\u53ef\u7528\u6027\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u3002\u3053\u308c\u306f\u3001\u5177\u4f53\u7684\u306b\u306f\u3001\u4e0b\u8a18\u306e\u3088\u3046\u306a\u30b1\u30fc\u30b9\u3092\u691c\u77e5\u3059\u308b\u3053\u3068\u3092\u76ee\u7684\u3068\u3059\u308b\u3002</p> <ul> <li>Runtime error\u7b49\u306b\u3088\u308a\u3001Heading\u306e\u63a8\u5b9a\u304c\u3046\u307e\u304f\u52d5\u4f5c\u3057\u3066\u3044\u306a\u3044</li> <li>\u521d\u671f\u4f4d\u7f6e\u63a8\u5b9a\u5468\u308a\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u5909\u66f4\u304c\u4e0d\u5341\u5206\u3067\u3001\u305d\u3082\u305d\u3082Eagleye\u304c\u521d\u671f\u5316\u3055\u308c\u306a\u3044</li> </ul> <p>\u305d\u306e\u305f\u3081\u306b\u3001\u672c\u9805\u76ee\u3067\u306f\u4e0b\u8a18\u306e\u51fa\u529b\u304c\u5b9a\u671f\u7684\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <ul> <li>/localization/pose_twist_estimator/eagleye/enu_absolute_pos_interpolate</li> </ul> <p>\u3053\u308c\u306f\u3001Eagleye Monitor\u3068\u3044\u3046Autoware\u5185\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u9593\u63a5\u7684\u306b\u5229\u7528\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u5b9f\u73fe\u3055\u308c\u308b\u3002\u672c\u30c4\u30fc\u30eb\u306f\u3001\u4e0b\u8a18\u306e\u30c8\u30d4\u30c3\u30af\u3092\u76e3\u8996\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u305d\u306e\u60c5\u5831\u3092\u53d6\u5f97\u3059\u308b\u3002</p> <ul> <li>/diagnostics</li> </ul>"},{"location":"ja/use_case/eagleye/#_2","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/eagleye/#_3","title":"\u53ef\u7528\u6027\u6b63\u5e38","text":"<p>Eagleye Monitor\u304c\u51fa\u529b\u3059\u308b <code>/diagnostics</code> \u306e\u4e2d\u304b\u3089\u3001\u76e3\u8996\u30c8\u30d4\u30c3\u30af\u306b\u95a2\u3059\u308b\u60c5\u5831\u3092\u62bd\u51fa\u3059\u308b\u3002 \u6700\u65b0\u306e\u60c5\u5831\u306b\u304a\u3051\u308bAvailability\u304c <code>OK</code> \u3067\u3042\u308b\u5834\u5408\u3001\u6b63\u5e38\u3067\u3042\u308b\u3068\u5224\u65ad\u3059\u308b\u3002</p>"},{"location":"ja/use_case/eagleye/#_4","title":"\u53ef\u7528\u6027\u7570\u5e38","text":"<p>\u53ef\u7528\u6027\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/eagleye/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs/msg/DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"ja/use_case/eagleye/#service","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Service \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"service \u540d \u30c7\u30fc\u30bf\u578b /localization/initialize autoware_internal_localization_msgs/srv/InitializeLocalization"},{"location":"ja/use_case/eagleye/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> <li>pose_source: eagleye</li> <li>twist_source: eagleye</li> </ul>"},{"location":"ja/use_case/eagleye/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/eagleye/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/eagleye/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/eagleye/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/eagleye/#_5","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/eagleye/#_6","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>\u4ee5\u4e0b\u306b\u3001\u305d\u308c\u305e\u308c\u306e\u8a55\u4fa1\u306e\u4f8b\u3092\u8a18\u8ff0\u3059\u308b\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>Availability\u306e\u7d50\u679c(Frame \u306e\u4e2d\u306b Availability \u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre>"},{"location":"ja/use_case/ground_segmentation/","title":"\u5730\u9762\u70b9\u7fa4\u9664\u53bb\u306e\u8a55\u4fa1","text":"<p>\u5165\u529b\u70b9\u7fa4\u306b\u5bfe\u3057\u3066\u5730\u9762\u70b9\u7fa4\u3092\u30bb\u30b0\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\u3057\u3001\u9664\u53bb\u3059\u308b\u6a5f\u80fd\u306b\u3064\u3044\u3066\u8a55\u4fa1\u3059\u308b\u3002</p>"},{"location":"ja/use_case/ground_segmentation/#ground-truth","title":"Ground Truth\u30c7\u30fc\u30bf","text":"<p>\u8a55\u4fa1\u306e\u305f\u3081\u306b\u5fc5\u8981\u3068\u306a\u308bGround Truth\u30c7\u30fc\u30bf\u306f\u4ee5\u4e0b\u306e\u65b9\u6cd5\u3067\u4e0e\u3048\u3089\u308c\u308b\uff0e</p>"},{"location":"ja/use_case/ground_segmentation/#annotated_pcd","title":"annotated_pcd","text":"<p>3D Semantic Segmentation\u306e\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u304c\u542b\u307e\u308c\u308b t4_dataset\u3092\u7528\u3044\u308b\u65b9\u6cd5\u3002(format)</p> <ol> <li>\u5730\u9762\u9664\u53bb\u3055\u308c\u305f\u70b9\u7fa4\u3068 t4_dataset\u5185\u306e<code>/sensing/lidar/concatenated/pointcloud</code>\u306b\u76f8\u5f53\u3059\u308b\u70b9\u7fa4(<code>dataset/data/LIDAR_CONCAT/*.pcd.bin</code>)\u3092\u6700\u8fd1\u508d\u63a2\u7d22\u3067\u30de\u30c3\u30c1\u30f3\u30b0\u3055\u305b\u308b</li> <li>\u305d\u306e\u70b9\u7fa4\u304c\u5730\u9762\u3067\u3042\u308b\u306e\u304b\u969c\u5bb3\u7269\u3067\u3042\u308b\u306e\u304b\u30c1\u30a7\u30c3\u30af\u3059\u308b</li> </ol>"},{"location":"ja/use_case/ground_segmentation/#_2","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p>launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch\u30b3\u30de\u30f3\u30c9 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001perception\u30e2\u30b8\u30e5\u30fc\u30eb\u5185\u3067\u5730\u9762\u70b9\u7fa4\u9664\u53bb\u3092\u884c\u3046</li> <li>\u5730\u9762\u70b9\u7fa4\u9664\u53bb\u5f8c\u306e\u70b9\u7fa4\u30c7\u30fc\u30bf\u3092\u542b\u3080\u51fa\u529b\u30c8\u30d4\u30c3\u30af\u3092\u4fdd\u5b58\u7528rosbag\u306b\u4fdd\u5b58\u3059\u308b</li> <li>rosbag\u306e\u518d\u751f\u304c\u7d42\u308f\u3063\u305f\u5f8c\u3001\u4fdd\u5b58\u7528rosbag\u4e2d\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u30d1\u30fc\u30b9\u3057\uff0c\u30bf\u30fc\u30b2\u30c3\u30c8\u3068\u306a\u308b\u30c8\u30d4\u30c3\u30af\u3092\u8a55\u4fa1\u3059\u308b</li> </ol>"},{"location":"ja/use_case/ground_segmentation/#_3","title":"\u8a55\u4fa1\u6642\u306e\u6ce8\u610f\u70b9","text":"<ul> <li>annotated_pcd\u30e2\u30fc\u30c9    \u8a55\u4fa1\u51e6\u7406\u306b\u6642\u9593\u304c\u304b\u304b\u308b\u305f\u3081\u3001rosbag\u306e\u518d\u751f\u30ec\u30fc\u30c8\u3092\u4e0b\u3052\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002   <code>ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py scenario_path:=${scenario_file} play_rate:=0.1</code></li> </ul>"},{"location":"ja/use_case/ground_segmentation/#_4","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/ground_segmentation/#_5","title":"\u6b63\u5e38","text":"<p>\u8a55\u4fa1\u306b\u3088\u308a\u5f97\u3089\u308c\u305fAccuracy\u304c\u30b7\u30ca\u30ea\u30aa\u306b\u8a18\u8ff0\u3055\u308c\u3066\u3044\u308b<code>Evaluation.Conditions.accuracy_min</code>\u4ee5\u4e0a\u306e\u5834\u5408\u3001\u6b63\u5e38\u3068\u3059\u308b\u3002</p>"},{"location":"ja/use_case/ground_segmentation/#_6","title":"\u7570\u5e38","text":"<p>\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u3068\u304d\u3001\u7570\u5e38\u3068\u3059\u308b\u3002</p>"},{"location":"ja/use_case/ground_segmentation/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/lidar/concatenated/pointcloud \u3000\u3000 sensor_msgs/msg/PointCloud2 /perception/obstacle_segmentation/pointcloud sensor_msgs/msg/PointCloud2 <p>\u6ce8:<code>/perception/obstacle_segmentation/pointcloud</code>topic\u306f\u3001launch\u5f15\u6570<code>evaluation_target_topic</code>\u3067\u5909\u66f4\u53ef\u80fd\u3067\u3042\u308b\u3002</p> <p>Published topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b - -"},{"location":"ja/use_case/ground_segmentation/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> <li>sensing: false</li> <li>perception_mode: lidar</li> </ul>"},{"location":"ja/use_case/ground_segmentation/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/ground_segmentation/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /tf tf2_msgs/msg/TFMessage"},{"location":"ja/use_case/ground_segmentation/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/ground_segmentation/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/ground_segmentation/#_7","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/ground_segmentation/#_8","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>ground_segmentation \u3067\u306f\u3001Accuracy\u3001Precision\u3001Recall\u3001Specificity\u3001F1-score\u3092\u8a55\u4fa1\u3057\u305f\u7d50\u679c\u3092\u5404 frame \u6bce\u306b\u51fa\u529b\u3059\u308b\u3002</p> <p>\u4ee5\u4e0b\u306b\u3001\u8a55\u4fa1\u306e\u4f8b\u3092\u8a18\u8ff0\u3059\u308b\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <pre><code>{\n  \"GroundSegmentation\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n    \"Info\": {\n      \"TP\": \"\u5730\u9762\u70b9\u3068\u3057\u3066\u8a8d\u8b58\u3055\u308c\u305f\u5730\u9762\u70b9\u306e\u6570\",\n      \"FP\": \"\u5730\u9762\u70b9\u3068\u3057\u3066\u8a8d\u8b58\u3055\u308c\u305f\u969c\u5bb3\u7269\u70b9\u306e\u6570\",\n      \"TN\": \"\u969c\u5bb3\u7269\u70b9\u3068\u3057\u3066\u8a8d\u8b58\u3055\u308c\u305f\u969c\u5bb3\u7269\u70b9\u306e\u6570\",\n      \"FN\": \"\u969c\u5bb3\u7269\u70b9\u3068\u3057\u3066\u8a8d\u8b58\u3055\u308c\u305f\u5730\u9762\u70b9\u306e\u6570\",\n      \"Accuracy\": \"Accuracy\u306e\u5024\",\n      \"Precision\": \"Precision\u306e\u5024\",\n      \"Recall\": \"Recall\u306e\u5024\",\n      \"Specificity\": \"Specificity\u306e\u5024\",\n      \"F1-score\": \"F1-score\u306e\u5024\"\n    }\n  }\n}\n</code></pre>"},{"location":"ja/use_case/","title":"\u8a55\u4fa1\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9","text":"<p>driving_log_replayer_v2 \u3092\u7528\u3044\u3066\u3069\u306e\u3088\u3046\u306a\u8a55\u4fa1\u3092\u884c\u3048\u308b\u304b\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/#driving_log_replayer_v2","title":"driving_log_replayer_v2 \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u4e00\u89a7","text":"<ul> <li>Localization</li> <li>YabLoc</li> <li>Eagleye</li> <li>AR-Tag Based Localizer</li> <li>Obstacle Segmentation</li> <li>Perception</li> <li>Performance Diag</li> <li>Annotationless Perception</li> <li>Traffic Light</li> <li>Perception 2D</li> <li>Planning Control</li> <li>Perception Reproducer</li> <li>Diagnostics</li> <li>GroundSegmentation</li> <li>AllComponents</li> </ul>"},{"location":"ja/use_case/localization/","title":"NDT \u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u306e\u8a55\u4fa1","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9 <code>localization</code> \u3067\u306f NDT \u306b\u3088\u308b Autoware \u306e\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u304c\u5b89\u5b9a\u3057\u3066\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002 Driving Log Replayer \u306f Autoware \u306e <code>logging_simulator</code> \u3092\u7528\u3044\u3066\u30b7\u30ca\u30ea\u30aa\u3092\u518d\u751f\u3057\u3001\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u4e2d\u304a\u3088\u3073\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5f8c\u306b\u8a55\u4fa1\u3092\u884c\u3063\u3066\u3044\u308b\u3002 \u672c\u30da\u30fc\u30b8\u306f\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u3068\u8a55\u4fa1\u304c\u3069\u306e\u3088\u3046\u306b\u884c\u308f\u308c\u3066\u3044\u308b\u304b\u3092\u8a18\u8ff0\u3059\u308b\u3002</p>"},{"location":"ja/use_case/localization/#_1","title":"\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u8a73\u7d30","text":"<p>\u672c\u30bb\u30af\u30b7\u30e7\u30f3\u3067\u306f\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u8a73\u7d30\u3084\u5b9f\u884c\u3059\u308b\u305f\u3081\u306b\u5fc5\u8981\u306a\u3082\u306e\u3092\u8a18\u8ff0\u3059\u308b\u3002</p>"},{"location":"ja/use_case/localization/#_2","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/localization/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> <li>pose_source: ndt</li> <li>twist_source: gyro_odom</li> </ul>"},{"location":"ja/use_case/localization/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"<p>\u5165\u529b rosbag \u306b\u306f Autoware \u306e localization \u30b3\u30f3\u30dd\u30fc\u30cd\u30f3\u30c8\u3092\u52d5\u304b\u3059\u306e\u306b\u5fc5\u8981\u306a\u30c8\u30d4\u30c3\u30af\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002</p> <p>ECU CAN \u306e\u30c7\u30fc\u30bf\u3092\u7528\u3044\u308b\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u30c8\u30d4\u30c3\u30af\u3092 rosbag \u306b\u542b\u3081\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002</p> Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan <p>\u307e\u305f\u3001ECU \u306e CAN \u3092\u4f7f\u308f\u305a\u306b vehicle \u7cfb\u306e\u30c8\u30d4\u30c3\u30af\u3067\u4ee3\u7528\u3057\u3066\u3082\u826f\u3044</p> Topic name Data type /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/localization/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/localization/#localization_evaluator_node","title":"localization_evaluator_node","text":"<p>Driving Log Replayer \u306f <code>logging_simulator</code> \u3068\u5171\u306b <code>localization_evaluator_node</code> \u3092 launch \u3057\u3001\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u30c7\u30fc\u30bf\u3092\u53ce\u96c6\u3057\u3066\u3044\u308b\u3002</p> <p><code>localization_evaluator_node</code> \u306f\u4ee5\u4e0b\u306e\u30c8\u30d4\u30c3\u30af\u3092\u30b5\u30d6\u30b9\u30af\u30e9\u30a4\u30d6\u3059\u308b\u3002</p> Topic name Data type /diagnostics diagnostic_msgs::msg::DiagnosticArray /localization/pose_estimator/transform_probability autoware_internal_debug_msgs::msg::Float32Stamped /localization/pose_estimator/nearest_voxel_transformation_likelihood autoware_internal_debug_msgs::msg::Float32Stamped /localization/pose_estimator/initial_to_result_relative_pose geometry_msgs::msg::PoseStamped /localization/pose_estimator/exe_time_ms autoware_internal_debug_msgs::msg::Float32Stamped /localization/pose_estimator/iteration_num autoware_internal_debug_msgs::msg::Int32Stamped /tf tf2_msgs/msg/TFMessage /localization/util/downsample/pointcloud sensor_msgs::msg::PointCloud2 /localization/pose_estimator/points_aligned sensor_msgs::msg::PointCloud2 <p>\u307e\u305f\u3001<code>localization_evaluator_node</code> \u306f\u4ee5\u4e0b\u306e\u30c8\u30d4\u30c3\u30af\u3092\u30d1\u30d6\u30ea\u30c3\u30b7\u30e5\u3059\u308b\u3002</p> Topic name Data type /driving_log_replayer_v2/localization/lateral_distance example_interfaces/msg/Float64 <p>\u307e\u305f\u3001<code>localization_evaluator_node</code> \u306f\u4ee5\u4e0b\u306e\u30b5\u30fc\u30d3\u30b9\u3092\u30b3\u30fc\u30eb\u3059\u308b\u3002</p> Service name Data type /localization/initialize autoware_internal_localization_msgs/srv/InitializeLocalization"},{"location":"ja/use_case/localization/#_3","title":"\u8a55\u4fa1\u5185\u5bb9\u8a73\u7d30","text":"<p>\u5177\u4f53\u7684\u306b\u306f\u4ee5\u4e0b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <ul> <li>NDT \u306e\u53ef\u7528\u6027</li> <li>NDT \u306e\u53ce\u675f\u6027</li> <li>NDT \u306e\u4fe1\u983c\u5ea6</li> <li>\u53c2\u7167\u8ecc\u8de1\uff08\u4f4d\u7f6e\u59ff\u52e2\u30fb\u901f\u5ea6\u30fb\u52a0\u901f\u5ea6\uff09\u3068\u306e\u4e56\u96e2</li> <li>diagnostics \u306e\u30a8\u30e9\u30fc\u7387</li> <li>diagnostics \u306e\u7acb\u3061\u4e0a\u304c\u308a/\u7acb\u3061\u4e0b\u304c\u308a\u30bf\u30a4\u30df\u30f3\u30b0</li> </ul> <p>Driving Log Replayer \u3092 launch \u3059\u308b\u3068\u4ee5\u4e0b\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>localization_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u3092\u884c\u3046</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c topic \u3092 subscribe \u3057\u3066\u3001NDT \u306e\u4fe1\u983c\u5ea6\u3001\u53ce\u675f\u6027\u3001\u53ef\u7528\u6027\u304c\u57fa\u6e96\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3057\u3066\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b\u3002</li> <li>rosbag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068 <code>logging_simulator</code> \u3082\u7d42\u4e86\u3057\u3001\u96c6\u8a08\u3055\u308c\u305f\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u3092\u7528\u3044\u3066\u53c2\u7167\u8ecc\u8de1\u3068\u306e\u4e56\u96e2\u3001diagnostics \u306e\u30a8\u30e9\u30fc\u7387\u3084\u7acb\u3061\u4e0a\u304c\u308a/\u7acb\u3061\u4e0b\u304c\u308a\u30bf\u30a4\u30df\u30f3\u30b0\u3092 <code>autoware_localization_evaluation_scripts</code> \u3092\u7528\u3044\u3066\u8a55\u4fa1\u3059\u308b\u3002</li> <li>\u4e0a\u8a18\u8a55\u4fa1\u7d50\u679c\u306e\u51fa\u529b\u5f8c\u3001\u81ea\u52d5\u7684\u306b\u30d7\u30ed\u30b0\u30e9\u30e0\u304c\u7d42\u4e86\u3059\u308b\u3002</li> </ol> <p>\u5168\u8a55\u4fa1\u9805\u76ee\u304c Success \u3068\u5224\u5b9a\u3055\u308c\u305f\u3068\u304d\u3001\u672c\u8a55\u4fa1\u306f Success \u3068\u5224\u5b9a\u3055\u308c\u308b\u3002</p> <p>\u4ee5\u4e0b\u306f\u5404\u8a55\u4fa1\u9805\u76ee\u306e\u8a55\u4fa1\u65b9\u6cd5\u306e\u8a73\u7d30\u3067\u3042\u308b\u3002</p>"},{"location":"ja/use_case/localization/#ndt_1","title":"NDT \u306e\u53ef\u7528\u6027","text":"<p>\u5168\u3066\u306e localization \u30b7\u30ca\u30ea\u30aa\u304a\u3044\u3066\u672c\u8a55\u4fa1\u9805\u76ee\u306f\u57fa\u672c\u7684\u306b\u8a55\u4fa1\u3055\u308c\u308b\u304c\u3001\u30b7\u30ca\u30ea\u30aa\u30d5\u30a1\u30a4\u30eb\u306e <code>Conditions</code> \u306b <code>availability</code> \u304c\u5b9a\u7fa9\u3055\u308c\u3066\u304a\u308a\u304b\u3064 <code>enable</code> \u304c <code>false</code> \u3068\u8a2d\u5b9a\u3055\u308c\u305f\u3068\u304d\u306e\u307f\u5b9f\u884c\u3055\u308c\u306a\u3044\u3002</p> <p>NDT\u306e\u53ef\u7528\u6027\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u3001\u4e0b\u8a18\u306e\u3088\u3046\u306a\u30b1\u30fc\u30b9\u3092 <code>logging_simulator</code> \u4e2d\u306b\u691c\u77e5\u3059\u308b\u3002</p> <ul> <li>Runtime error\u7b49\u306b\u3088\u308a <code>pointcloud_preprocessor</code> \u304c\u843d\u3061\u3066\u3044\u308b\uff08\u3053\u308c\u306b\u3088\u308a\u3001 <code>ndt_scan_matcher</code> \u3078\u306eLiDAR\u30b9\u30ad\u30e3\u30f3\u304c\u9001\u4fe1\u3055\u308c\u306a\u304f\u306a\u308b\uff09</li> <li>Runtime error\u7b49\u306b\u3088\u308a <code>ndt_scan_matcher</code> \u304c\u843d\u3061\u3066\u3044\u308b</li> </ul> <p>\u305d\u306e\u305f\u3081\u306b\u4e0b\u8a18\u306e\u51fa\u529b\u304c\u5b9a\u671f\u7684\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u3092\u3001Component State Monitor\u3068\u3044\u3046Autoware\u5185\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u9593\u63a5\u7684\u306b\u5229\u7528\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u8a55\u4fa1\u3059\u308b\u3002</p> <ul> <li>/localization/pose_estimator/exe_time_ms</li> </ul> <p>\u306a\u304a\u3001NDT\u306e\u51fa\u529b\u30c8\u30d4\u30c3\u30af\u306e\u4e2d\u3067 <code>/localization/pose_estimator/exe_time_ms</code> \u304c\u9078\u3070\u308c\u305f\u306e\u306f\u3001\u300c\u30c8\u30d4\u30c3\u30af\u304c\u5b9a\u671f\u7684\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u300d\u3053\u3068\u3092\u78ba\u8a8d\u3057\u3084\u3059\u3044\u304b\u3089\u3067\u3042\u308b\u3002\u4f8b\u3048\u3070 <code>/localization/pose_estimator/pose</code> \u306f NVTL \u3084 TP \u306a\u3069\u306e\u30b9\u30b3\u30a2\u304c\u4f4e\u3044\u5834\u5408\u3082\u51fa\u529b\u3055\u308c\u306a\u3044\u306e\u3067\u3001\u51fa\u529b\u3092\u76e3\u8996\u3059\u308b\u3060\u3051\u3067\u306f <code>ndt_scan_matcher</code> \u306e\u53ef\u7528\u6027\u3092\u5224\u5b9a\u3059\u308b\u3053\u3068\u304c\u96e3\u3057\u304f\u672c\u76ee\u7684\u306b\u306f\u9069\u3055\u306a\u3044\u3002</p> <p><code>logging_simulator</code> \u306e\u6700\u5f8c\u307e\u3067 <code>/localization/pose_estimator/exe_time_ms</code> \u30c8\u30d4\u30c3\u30af\u304c\u78ba\u8a8d\u3067\u304d\u308c\u3070\u672c\u8a55\u4fa1\u306f Success\u3001\u78ba\u8a8d\u3067\u304d\u306a\u304b\u308c\u3070 Fail \u3068\u5224\u5b9a\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/localization/#ndt_2","title":"NDT \u306e\u53ce\u675f\u6027","text":"<p>\u672c\u8a55\u4fa1\u9805\u76ee\u306f\u30b7\u30ca\u30ea\u30aa\u30d5\u30a1\u30a4\u30eb\u306e <code>Conditions</code> \u306b <code>Convergence</code> \u304c\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b\u3068\u304d\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <pre><code>Evaluation:\n  Conditions:\n    Convergence:\n      AllowableDistance: 0.2 # Lateral distance to be considered convergence\n      AllowableExeTimeMs: 100.0 # If the NDT computation time is less than or equal to this value, it is considered successful.\n      AllowableIterationNum: 30 # If the number of NDT calculations is less than or equal to this value, it is considered a success.\n      PassRate: 95.0 # How much (%) of the evaluation attempts are considered successful.\n</code></pre> <p>\u4ee5\u4e0b 3 \u3064\u306e topic \u3092 <code>logging_simulator</code> \u4e2d\u306b\u8a55\u4fa1\u3059\u308b\u3002</p> Topic name Success condition /localization/pose_estimator/initial_to_result_relative_pose value of lateral factor &lt;= AllowableDistance /localization/pose_estimator/exe_time_ms value &lt;= AllowableExeTimeMs /localization/pose_estimator/iteration_num value &lt;= AllowableIterationNum <p>\u3042\u308b\u30d5\u30ec\u30fc\u30e0\u306b\u304a\u3044\u3066\u3001\u4e0a\u8a18\u306e 3 \u6761\u4ef6\u304c\u5168\u3066\u6e80\u305f\u3055\u308c\u305f\u5834\u5408\u306b NDT \u304c\u53ce\u675f\u3057\u305f\u3068\u3057\u3066\u5224\u5b9a\u3055\u308c\u308b\u3002\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u901a\u3058\u3066\u3053\u306e\u53ce\u675f\u7387\u304c <code>PassRate</code> \u4ee5\u4e0a\u3067\u3042\u308c\u3070\u672c\u8a55\u4fa1\u306f Success\u3001<code>PassRate</code> \u672a\u6e80\u3067\u3042\u308c\u3070 Fail \u3068\u5224\u5b9a\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/localization/#ndt_3","title":"NDT \u306e\u4fe1\u983c\u5ea6","text":"<p>\u672c\u8a55\u4fa1\u9805\u76ee\u306f\u30b7\u30ca\u30ea\u30aa\u30d5\u30a1\u30a4\u30eb\u306e <code>Conditions</code> \u306b <code>Reliability</code> \u304c\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b\u3068\u304d\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <pre><code>Evaluation:\n  Conditions:\n    Reliability:\n      Method: NVTL # NVTL or TP which method to use for evaluation\n      AllowableLikelihood: 2.3 # If above this value, the localization reliability value is considered normal.\n      NGCount: 10 # If the reliability value is lower than the threshold value for more than this number in the sequence. the evaluation is considered to have failed.\n</code></pre> <p>\u4ee5\u4e0b\u306e 2 \u3064\u306e topic \u306e\u3046\u3061\u3001\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u65b9\u3092 <code>logging_simulator</code> \u4e2d\u306b\u8a55\u4fa1\u3059\u308b\u3002</p> Method Topic Name Success Condition TP /localization/pose_estimator/transform_probability value &gt;= AllowableLikelihood NVTL /localization/pose_estimator/nearest_voxel_transformation_likelihood value &gt;= AllowableLikelihood <p>\u4e0a\u8a18\u30c8\u30d4\u30c3\u30af\u304c\u793a\u3059\u6570\u5024\u304c <code>AllowableLikelihood</code> \u4ee5\u4e0a\u3067\u3042\u308c\u3070 NDT \u306e\u7d50\u679c\u306f\u4fe1\u983c\u3067\u304d\u308b\u3082\u306e\u3068\u3057\u3066\u8a55\u4fa1\u3057\u3001\u4e0b\u56de\u3063\u3066\u3044\u308c\u3070\u7570\u5e38\u3068\u307f\u306a\u3057\u3066\u8a55\u4fa1\u3059\u308b\u3002\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u901a\u3058\u3066 TP \u3082\u3057\u304f\u306f NVTL \u304c <code>NGCount</code> \u56de\u9023\u7d9a\u3067\u95be\u5024\u3092\u4e0b\u56de\u3063\u3066\u5834\u5408\u306f Fail\u3001\u305d\u3046\u3067\u306a\u3044\u5834\u5408\u306f Success \u3068\u5224\u5b9a\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/localization/#_4","title":"\u53c2\u7167\u8ecc\u8de1\u3068\u306e\u4e56\u96e2","text":"<p>\u5168\u3066\u306e localization \u30b7\u30ca\u30ea\u30aa\u304a\u3044\u3066\u3001\u672c\u8a55\u4fa1\u9805\u76ee\u306f\u57fa\u672c\u7684\u306b\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <p><code>logging_simulator</code> \u7d42\u4e86\u5f8c <code>autoware_localization_evaluation_scripts</code> \u3092\u901a\u3058\u3066\u3001\u4f4d\u7f6e\u59ff\u52e2\u30fb\u901f\u5ea6\u30fb\u52a0\u901f\u5ea6\u306e\u53c2\u7167\u8ecc\u8de1\u3068\u5b9f\u969b\u306e\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u7d50\u679c\u306b\u4e56\u96e2\u304c\u306a\u3044\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002\u5177\u4f53\u7684\u306a\u4e56\u96e2\u306e\u5b9a\u7fa9\u306a\u3069\u3001\u8a73\u7d30\u306a\u51e6\u7406\u306f <code>autoware_localization_evaluation_scripts</code> \u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u3002</p> <p>\u8a55\u4fa1\u3067\u304d\u308b\u8ecc\u8de1\u306e\u8981\u7d20\u306f</p> <ul> <li>\u4f4d\u7f6e</li> <li>\u59ff\u52e2</li> <li>\u9032\u884c\u65b9\u5411\u306e\u901f\u5ea6</li> <li>\u89d2\u901f\u5ea6</li> <li>\u9032\u884c\u65b9\u5411\u306e\u52a0\u901f\u5ea6</li> </ul> <p>\u306e 5 \u70b9\u3067\u3042\u308a\u3001\u30b7\u30ca\u30ea\u30aa\u30d5\u30a1\u30a4\u30eb\u4e2d\u306e <code>OverallCriteriaMask</code> \u3092\u5b9a\u7fa9\u3059\u308b\u3053\u3068\u3067\u8a55\u4fa1\u3092\u3059\u308b\u304b\u3057\u306a\u3044\u304b\u3092\u6c7a\u5b9a\u3067\u304d\u308b\u3002\uff08<code>mean_relative_*</code> \u306e\u9805\u76ee\uff09\u3082\u3057\u3082 <code>OverallCriteriaMask</code> \u306e\u5b9a\u7fa9\u304c\u306a\u3044\u5834\u5408\u306f\u5168\u3066\u306e\u8981\u7d20\u306b\u5bfe\u3057\u3066\u8a55\u4fa1\u3092\u884c\u3046\u3002\u5168\u3066\u306e\u8a55\u4fa1\u9805\u76ee\u3067\u4e56\u96e2\u304c\u306a\u304b\u3063\u305f\u5834\u5408\u306f Success \u3068\u5224\u5b9a\u3055\u308c\u3001\u305d\u3046\u3067\u306a\u3044\u5834\u5408\u306f Fail \u3068\u5224\u5b9a\u3055\u308c\u308b\u3002</p> <pre><code>Evaluation:\n  Conditions:\n    OverallCriteriaMask: # Toggle the mask below to perform or not to perform evaluation of the according criteria. The evaluator will automatically set all to `true` if this block is not defined.\n      mean_relative_position: true\n      mean_relative_angle: true\n      mean_relative_linear_velocity: true\n      mean_relative_angular_velocity: true\n      mean_relative_acceleration: true\n      diagnostics_not_ok_rate: true\n</code></pre>"},{"location":"ja/use_case/localization/#diagnostics","title":"diagnostics \u306e\u30a8\u30e9\u30fc\u7387","text":"<p>\u5168\u3066\u306e localization \u30b7\u30ca\u30ea\u30aa\u304a\u3044\u3066\u3001\u672c\u8a55\u4fa1\u9805\u76ee\u306f\u57fa\u672c\u7684\u306b\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <p><code>logging_simulator</code> \u7d42\u4e86\u5f8c <code>autoware_localization_evaluation_scripts</code> \u3092\u901a\u3058\u3066\u3001localization \u306b\u95a2\u9023\u3059\u308b diagnostics \u304c\u60f3\u5b9a\u4ee5\u4e0a\u306e ERROR \u3092\u51fa\u3057\u3066\u3044\u306a\u3044\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002\u5177\u4f53\u7684\u306b\u306f\u4ee5\u4e0b\u306e\u540d\u524d\u306e diagnostics \u306b\u3064\u3044\u3066\u8a55\u4fa1\u3059\u308b\u3002</p> <ul> <li>ndt_scan_matcher: scan_matching_status</li> <li>localization: ekf_localizer</li> <li>localization_error_monitor: ellipse_error_status</li> <li>localization: pose_instability_detector</li> </ul> <p>\u8a73\u7d30\u306a\u51e6\u7406\u306f <code>autoware_localization_evaluation_scripts</code> \u306e README \u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u3002</p> <p>\u5168\u3066\u306e diagnostics \u306b\u304a\u3044\u3066\u3001ERROR \u7387\u304c\u5341\u5206\u4f4e\u304b\u3063\u305f\u5834\u5408\u306f Success \u3068\u5224\u5b9a\u3055\u308c\u3001\u305d\u3046\u3067\u306a\u3044\u5834\u5408\u306f Fail \u3068\u5224\u5b9a\u3055\u308c\u308b\u3002</p> <p>\u307e\u305f\u3001\u30b7\u30ca\u30ea\u30aa\u30d5\u30a1\u30a4\u30eb\u4e2d\u306e <code>OverallCriteriaMask</code> \u306e\u5b9a\u7fa9\u306b\u3088\u3063\u3066\u306f\u672c\u8a55\u4fa1\u306e\u7121\u52b9\u5316\u304c\u3067\u304d\u308b\u3002\uff08<code>diagnostics_not_ok_rate</code> \u306e\u9805\u76ee\uff09\u3082\u3057\u3082 <code>OverallCriteriaMask</code> \u306e\u5b9a\u7fa9\u304c\u306a\u3044\u5834\u5408\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u8a55\u4fa1\u3092\u884c\u3046\u3002</p> <pre><code>Evaluation:\n  Conditions:\n    OverallCriteriaMask: # Toggle the mask below to perform or not to perform evaluation of the according criteria. The evaluator will automatically set all to `true` if this block is not defined.\n      mean_relative_position: true\n      mean_relative_angle: true\n      mean_relative_linear_velocity: true\n      mean_relative_angular_velocity: true\n      mean_relative_acceleration: true\n      diagnostics_not_ok_rate: true\n</code></pre>"},{"location":"ja/use_case/localization/#diagnostics_1","title":"diagnostics \u306e\u7acb\u3061\u4e0a\u304c\u308a/\u7acb\u3061\u4e0b\u304c\u308a\u30bf\u30a4\u30df\u30f3\u30b0","text":"<p>\u672c\u8a55\u4fa1\u9805\u76ee\u306f\u30b7\u30ca\u30ea\u30aa\u30d5\u30a1\u30a4\u30eb\u306e <code>Conditions</code> \u306b <code>DiagnosticsFlagCheck</code> \u304c\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b\u3068\u304d\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <pre><code>Evaluation:\n  Conditions:\n    DiagnosticsFlagCheck:\n      pose_is_passed_delay_gate: # name of the diagnostics to check\n        flag: rise # which flag to detect (`rise` or `fall`)\n        at_sec: 113 # The `sec` part of the expected time to rise/fall\n        at_nanosec: 750000000 # The `nanosec` part of the expected time to rise/fall\n      pose_no_update_count:\n        flag: rise\n        at_sec: 117\n        at_nanosec: 900000000\n</code></pre> <p><code>logging_simulator</code> \u7d42\u4e86\u5f8c <code>autoware_localization_evaluation_scripts</code> \u3092\u901a\u3058\u3066\u3001localization \u306b\u95a2\u9023\u3059\u308b diagnostics \u304c\u60f3\u5b9a\u30bf\u30a4\u30df\u30f3\u30b0\u3067\u7acb\u3061\u4e0a\u304c\u308b\u3082\u3057\u304f\u306f\u7acb\u3061\u4e0b\u304c\u308b\u304b\u3069\u3046\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002\u8a73\u7d30\u306a\u51e6\u7406\u306f <code>autoware_localization_evaluation_scripts</code> \u306e README \u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u3002</p> <p>diagnostics \u306e\u6307\u5b9a\u306e\u9805\u76ee\u304c <code>at_sec</code> \u3068 <code>at_nanosec</code> \u3067\u5b9a\u7fa9\u3055\u308c\u308b\u60f3\u5b9a\u6642\u9593\u306e +/- 0.2 \u79d2\u306e\u9593\u306b\u7acb\u3061\u4e0a\u304c\u3063\u305f/\u7acb\u3061\u4e0b\u304c\u3063\u305f\u5834\u5408\u306b Success \u3068\u5224\u5b9a\u3055\u308c\u3001\u305d\u3046\u3067\u306a\u3044\u5834\u5408\u306f Fail \u3068\u5224\u5b9a\u3055\u308c\u308b\u3002\u60f3\u5b9a\u6642\u9593\u3088\u308a\u3082\u65e9\u304f\u306b\u7acb\u3061\u4e0a\u304c\u308a/\u7acb\u3061\u4e0b\u304c\u308a\u304c\u3042\u3063\u305f\u5834\u5408\u306b\u3082 Fail \u3068\u5224\u5b9a\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/localization/#_5","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>\u4ee5\u4e0b\u306b\u3001\u305d\u308c\u305e\u308c\u306e\u8a55\u4fa1\u306e\u4f8b\u3092\u8a18\u8ff0\u3059\u308b\u3002</p> <p>\u53ef\u7528\u6027\u306e\u7d50\u679c(Frame \u306e\u4e2d\u306b Availability \u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre> <p>\u53ce\u675f\u6027\u306e\u7d50\u679c(Frame \u306e\u4e2d\u306b Convergence \u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Convergence\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n    \"Info\": {\n      \"LateralDistance\": \"initial_to_result_relative_pose.pose.position.y\",\n      \"HorizontalDistance\": \"initial_to_result_relative_pose.pose.position\u306e\u6c34\u5e73\u8ddd\u96e2\u3002\u53c2\u8003\u5024\",\n      \"ExeTimeMs\": \"ndt\u306e\u8a08\u7b97\u306b\u304b\u304b\u3063\u305f\u6642\u9593\",\n      \"IterationNum\": \"ndt\u306e\u518d\u8a08\u7b97\u56de\u6570\"\n    }\n  }\n}\n</code></pre> <p>\u4fe1\u983c\u5ea6\u306e\u7d50\u679c(Frame \u306b Reliability \u306e\u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Reliability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n    \"Info\": {\n      \"Value\": {\n        \"stamp\": {\n          \"sec\": \"stamp\u306e\u79d2\",\n          \"nanosec\": \"stamp\u306enano\u79d2\"\n        },\n        \"data\": \"NVTL or TP\u306e\u5024\"\n      },\n      \"Reference\": {\n        \"stamp\": {\n          \"sec\": \"stamp\u306e\u79d2\",\n          \"nanosec\": \"stamp\u306enano\u79d2\"\n        },\n        \"data\": \"\u8a55\u4fa1\u306b\u4f7f\u7528\u3057\u306a\u304b\u3063\u305f\u5c24\u5ea6\u3002\u53c2\u8003\u5024\u3002Value\u304cNVTL\u306a\u3089TP\u304c\u5165\u308b\"\n      }\n    }\n  }\n}\n</code></pre> <p>NDT\u306e\u53ef\u7528\u6027\u30fb\u53ce\u675f\u6027\u30fb\u4fe1\u983c\u5ea6\u306e\u6700\u7d42\u7d50\u679c\u304a\u3088\u3073\u53c2\u7167\u8ecc\u8de1\u3068\u306e\u4e56\u96e2\u3001diagnostics \u306e\u30a8\u30e9\u30fc\u7387\u3001diagnostics \u306e\u7acb\u3061\u4e0a\u304c\u308a/\u7acb\u3061\u4e0b\u304c\u308a\u30bf\u30a4\u30df\u30f3\u30b0\u306e\u7d50\u679c\u306f\u307e\u3068\u3081\u3066 result.json \u306e\u6700\u7d42\u30d5\u30ec\u30fc\u30e0\u306b\u8a18\u8f09\u3055\u308c\u308b\u3002</p> <pre><code>{\n  \"Result\": {\n    \"Success\": false,\n    \"Summary\": \"Failed: Convergence (Fail): 570 / 632 -&gt; 90.19%, Reliability (Fail): NVTL Sequential NG Count: 10 (Total Test: 632, Average: 2.46835, StdDev: 0.16043), NDT Availability (Success): NDT available, mean_position_norm=0.166 [m]|mean_angle_norm=0.032 [deg]|mean_linear_velocity_norm=0.003 [m/s]|mean_angular_velocity_norm=0.001 [rad/s]|localization__ekf_localizer 13.447 [%] is too large.|localization__pose_instability_detector 0.000 [%]|localization_error_monitor__ellipse_error_status 13.447 [%] is too large.|ndt_scan_matcher__scan_matching_status 57.177 [%] is too large.|Diagnostics flag 'pose_is_passed_delay_gate' OK.|Diagnostics flag 'pose_no_update_count' OK.\"\n  }\n}\n</code></pre>"},{"location":"ja/use_case/obstacle_segmentation/","title":"\u70b9\u7fa4\u751f\u6210\u306e\u8a55\u4fa1","text":"<p>Autoware \u306e\u70b9\u7fa4\u51e6\u7406\u306e\u30d7\u30ed\u30bb\u30b9(sensing\u2192perception)\u304c\u52d5\u4f5c\u3057\u3066\u3001/perception/obstacle_segmentation/pointcloud \u304c\u610f\u56f3\u901a\u308a\u306b\u51fa\u529b\u3055\u308c\u308b\u304b\u3069\u3046\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <p>\u70b9\u7fa4\u304c\u610f\u56f3\u901a\u308a\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u306e\u5224\u5b9a\u306f\u3001t4_dataset \u3068\u70b9\u7fa4\u3092\u7528\u3044\u3066\u884c\u3046\u3002\u4ee5\u4e0b\u306e\u8a55\u4fa1\u3092\u540c\u6642\u306b\u884c\u3046\u3002</p> <ul> <li>\u4e8b\u524d\u306b\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u3057\u3066\u304a\u3044\u305f\u8eca\u4e21\u3084\u6b69\u884c\u8005\u306a\u3069\u304c\u691c\u77e5\u51fa\u6765\u3066\u3044\u308b\u304b\u306e\u8a55\u4fa1\uff08detection: \u691c\u77e5\uff09</li> <li>\u30ec\u30fc\u30f3\u3068\u30b7\u30ca\u30ea\u30aa\u3067\u5b9a\u7fa9\u3057\u305f\u81ea\u8eca\u4e21\u5468\u308a\u306e\u30dd\u30ea\u30b4\u30f3\u304c\u91cd\u306a\u308b\u30a8\u30ea\u30a2\u306b\u4f59\u5206\u306a\u70b9\u7fa4\u304c\u51fa\u3066\u3044\u306a\u3044\u304b\u306e\u8a55\u4fa1\uff08non_detection: \u975e\u691c\u77e5\uff09</li> </ul> <p>\u307e\u305f\u3001\u8a55\u4fa1\u6761\u4ef6\u306b null \u3092\u6307\u5b9a\u3059\u308c\u3070\u8a55\u4fa1\u3057\u306a\u3044\u3053\u3068\u3082\u53ef\u80fd\u3067\u3042\u308b\u3002\u3059\u306a\u308f\u3061\u4ee5\u4e0b\u306e 3 \u30e2\u30fc\u30c9\u3067\u8a55\u4fa1\u3092\u5b9f\u65bd\u3067\u304d\u308b\u3002</p> <ol> <li>detection \u3068 non_detection \u3092\u540c\u6642\u306b\u8a55\u4fa1\u3059\u308b</li> <li>detection \u3060\u3051\u8a55\u4fa1\u3059\u308b(NonDetection: null)</li> <li>non_detection \u3060\u3051\u8a55\u4fa1\u3059\u308b(Detection: null)</li> </ol> <p>\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u30c4\u30fc\u30eb\u306fDeepen\u304c\u63a8\u5968\u3067\u3042\u308b\u304c\u3001t4_dataset \u3078\u306e\u5909\u63db\u304c\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u3066\u3044\u308b\u30c4\u30fc\u30eb\u3067\u3042\u308c\u3070\u3088\u3044\u3002 \u5909\u63db\u30c4\u30fc\u30eb\u3055\u3048\u4f5c\u6210\u3067\u304d\u308c\u3070\u8907\u6570\u306e\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u30c4\u30fc\u30eb\u3092\u5229\u7528\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3042\u308b\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#_2","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p>launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>obstacle_segmentation_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001/perception/obstacle_segmentation/pointcloud \u3092\u51fa\u529b\u3059\u308b</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c/perception/obstacle_segmentation/pointcloud \u3092 subscribe \u3057\u3066\u3001header \u306e\u6642\u523b\u3067\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306e polygon \u3092\u8a08\u7b97\u3059\u308b\u3002</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u70b9\u7fa4\u3068\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306epolygon\u3092perception_eval \u306b\u6e21\u3057\u3066\u8a55\u4fa1\u3059\u308b\u3002\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/obstacle_segmentation/#polygon","title":"\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306epolygon\u306e\u8a08\u7b97\u65b9\u6cd5","text":"<p>\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306f\u3001\u30b7\u30ca\u30ea\u30aa\u3067\u4e0e\u3048\u3089\u308c\u305fpolygon\u3068\u3001\u8d70\u884c\u8def(road_lanelet)\u306e\u91cd\u306a\u308a\u5408\u3063\u305f\u30a8\u30ea\u30a2\u3068\u3057\u3066\u7b97\u51fa\u3055\u308c\u308b\u3002 \u4ee5\u4e0b\u306e\u30b9\u30c6\u30c3\u30d7\u306b\u5f93\u3063\u3066\u8a08\u7b97\u3055\u308c\u308b\u3002</p> <ol> <li>pointcloud\u306eheader.stamp\u306e\u6642\u523b\u3067\u306emap_to_base_link\u306etransform\u3092\u53d6\u5f97\u3057\u3066\u3001polygon\u3092map\u5ea7\u6a19\u7cfb\u306b\u5909\u63db\u3059\u308b</li> <li>\u8eca\u4e21\u306e\u3044\u308bpoint\u304b\u3089\u3001search_range(\u4e0b\u56f3\u53c2\u7167)\u306e\u7bc4\u56f2\u306eroad_lanelet\u3092\u53d6\u5f97\u3059\u308b</li> <li>2\u3067\u53d6\u5f97\u3057\u305froad_lanelet\u3068polygon\u306eintersection\u3092\u53d6\u308b</li> <li>3\u3067\u53d6\u5f97\u3057\u305fpolygon\u306e\u914d\u5217\u3092base_link\u5ea7\u6a19\u7cfb\u3078\u623b\u3059(pointcloud\u3092\u30d5\u30a3\u30eb\u30bf\u3059\u308b\u305f\u3081\u306b\u5ea7\u6a19\u7cfb\u3092\u4e00\u81f4\u3055\u305b\u308b)</li> </ol> <p></p> <p>\u30b9\u30c6\u30c3\u30d72\u3067\u3001polygon\u304c\u5b58\u5728\u3057\u5f97\u308b\u7bc4\u56f2\u306elanelet\u306b\u7d5e\u308b\u3053\u3068\u3067\u3001\u30b9\u30c6\u30c3\u30d73\u3067\u7a7a\u306epolygon\u304c\u8fd4\u3063\u3066\u304f\u308b\u3068\u308f\u304b\u308a\u304d\u3063\u3066\u3044\u308blanelet\u3068\u306eintersection\u51e6\u7406\u3092\u7701\u3044\u3066\u3044\u308b\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#_3","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#_4","title":"\u691c\u77e5\u6b63\u5e38","text":"<p>\u4ee5\u4e0b\u306e\u6761\u4ef6\u3092\u3059\u3079\u3066\u6e80\u305f\u3059\u5834\u5408\u3001\u691c\u77e5\u6b63\u5e38\u3068\u306a\u308b\u3002</p> <ol> <li>\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f UUID \u3092\u6301\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u5185\u306b\u3001\u6307\u5b9a\u3057\u305f\u70b9\u6570\u4ee5\u4e0a\u306e\u70b9\u7fa4\uff08/perception/obstacle_segmentation/pointcloud\uff09\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u3053\u3068\u3002<ul> <li>\u8907\u6570\u306e UUID \u3092\u6307\u5b9a\u3057\u305f\u5834\u5408\u306f\u3001\u6307\u5b9a\u3057\u305f\u3059\u3079\u3066\u306e\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306b\u3064\u3044\u3066\u6761\u4ef6\u3092\u6e80\u305f\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002</li> </ul> </li> <li>Autoware \u306e\u8a3a\u65ad\u6a5f\u80fd\u3067\u63d0\u4f9b\u3055\u308c\u308b\u70b9\u7fa4\u306e\u51fa\u529b\u30ec\u30fc\u30c8\u304c\u30a8\u30e9\u30fc\u72b6\u614b\u3067\u306a\u3044\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u3057\u304d\u3044\u5024\u306f 1.0Hz \u3067\u3059\u3002</li> </ol>"},{"location":"ja/use_case/obstacle_segmentation/#_5","title":"\u691c\u77e5\u8b66\u544a","text":"<p>\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f UUID \u3092\u6301\u3064 bounding box \u306e visibility \u304c none(occlusion \u72b6\u614b)\u3067\u3042\u308a\u3001\u8a55\u4fa1\u51fa\u6765\u306a\u3044\u5834\u5408\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#_6","title":"\u691c\u77e5\u7570\u5e38","text":"<p>\u691c\u77e5\u8b66\u544a\u3067\u3082\u3001\u691c\u77e5\u6b63\u5e38\u3067\u3082\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/obstacle_segmentation/#_7","title":"\u975e\u691c\u77e5\u6b63\u5e38","text":"<p>\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306b\u70b9\u7fa4\u304c 1 \u70b9\u3082\u306a\u3044\u3053\u3068\u3002</p> <p>\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306f\u8a55\u4fa1\u65b9\u6cd5\u306e\u30b9\u30c6\u30c3\u30d7 3 \u3067\u8a08\u7b97\u3055\u308c\u308b\u9818\u57df\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#_8","title":"\u975e\u691c\u77e5\u7570\u5e38","text":"<p>\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306b\u70b9\u7fa4\u304c\u51fa\u3066\u3044\u308b\u3053\u3068\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /perception/obstacle_segmentation/pointcloud sensor_msgs/msg/PointCloud2 /diagnostics diagnostic_msgs/msg/DiagnosticArray /tf tf2_msgs/msg/TFMessage /planning/scenario_planning/status/stop_reasons tier4_planning_msgs/msg/StopReasonArray /planning/trajectory autoware_planning_msgs/msg/Trajectory <p>Published topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /driving_log_replayer_v2/marker/detection visualization_msgs/msg/MarkerArray /driving_log_replayer_v2/marker/non_detection visualization_msgs/msg/MarkerArray /driving_log_replayer_v2/pcd/detection sensor_msgs/msg/PointCloud2 /driving_log_replayer_v2/pcd/non_detection sensor_msgs/msg/PointCloud2 /planning/mission_planning/goal geometry_msgs/msg/PoseStamped"},{"location":"ja/use_case/obstacle_segmentation/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<ul> <li>localization: false</li> <li>control: false</li> <li>scenario_simulation: true</li> </ul>"},{"location":"ja/use_case/obstacle_segmentation/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"<p>t4_dataset \u3067\u5fc5\u8981\u306a\u30c8\u30d4\u30c3\u30af\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u3053\u3068</p> <p>\u8eca\u4e21\u306e ECU \u306e CAN \u3068\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b sensor \u306e topic \u304c\u5fc5\u8981 \u4ee5\u4e0b\u306f\u4f8b\u3067\u3042\u308a\u3001\u9055\u3046\u30bb\u30f3\u30b5\u30fc\u3092\u4f7f\u3063\u3066\u3044\u308b\u5834\u5408\u306f\u9069\u5b9c\u8aad\u307f\u66ff\u3048\u308b\u3002</p> <p>LiDAR \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e LiDAR \u306e packets \u3092\u542b\u3081\u308b\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /localization/kinematic_state Type: nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>CAN \u306e\u4ee3\u308f\u308a\u306b vehicle \u306e topic \u3092\u542b\u3081\u3066\u3082\u826f\u3044\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /localization/kinematic_state Type: nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/obstacle_segmentation/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/obstacle_segmentation/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#_9","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/obstacle_segmentation/#_10","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>obstacle_segmentation \u3067\u306f\u3001\u691c\u77e5(Detection)\u3068\u975e\u691c\u77e5(NonDetection)\u306e 2 \u3064\u3092\u8a55\u4fa1\u3057\u3066\u3044\u308b\u3002 1 \u56de\u306e\u70b9\u7fa4\u306e callback \u3067\u540c\u6642\u306b\u8a55\u4fa1\u3057\u3066\u3044\u308b\u304c\u3001\u305d\u308c\u305e\u308c\u5225\u306b\u30ab\u30a6\u30f3\u30c8\u3057\u3066\u3044\u308b\u3002 Result \u306f\u691c\u77e5\u3068\u975e\u691c\u77e5\u4e21\u65b9\u306e\u30d1\u30b9\u3057\u3066\u3044\u308c\u3070 true \u3067\u305d\u308c\u4ee5\u5916\u306f false \u5931\u6557\u3068\u306a\u308b\u3002</p> <p>\u4ee5\u4e0b\u306b\u3001\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u793a\u3059\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <pre><code>{\n  \"Frame\": {\n    \"FrameName\": \"\u8a55\u4fa1\u306b\u4f7f\u7528\u3057\u305ft4_dataset\u306e\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\",\n    \"FrameSkip\": \"object\u306e\u8a55\u4fa1\u3092\u4f9d\u983c\u3057\u305f\u304cdataset\u306b75msec\u4ee5\u5185\u306e\u771f\u5024\u304c\u306a\u304f\u8a55\u4fa1\u3092\u98db\u3070\u3055\u308c\u305f\u56de\u6570\",\n    \"StopReasons\": \"Planning module\u304c\u51fa\u529b\u3059\u308b\u505c\u6b62\u7406\u7531\u3002\u53c2\u8003\u5024\",\n    \"TopicRate\": \"\u70b9\u7fa4\u306e\u51fa\u529b\u30ec\u30fc\u30c8\u304c\u6b63\u5e38\u304b\u3069\u3046\u304b\u3092\u793a\u3059diag\u306e\u7d50\u679c\",\n    \"Detection\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, Warn or Invalid\" },\n      \"Info\": {\n        \"DetectionSuccess or DetectionFail or DetectionWarn\": {\n          \"Annotation\": {\n            \"Scale\": {\n              \"x\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306ex\u65b9\u5411\u306e\u9577\u3055\",\n              \"y\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306ey\u65b9\u5411\u306e\u9577\u3055\",\n              \"z\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306ez\u65b9\u5411\u306e\u9577\u3055\"\n            },\n            \"Position\": {\n              \"position\": {\n                \"x\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u4f4d\u7f6ex\",\n                \"y\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u4f4d\u7f6ey\",\n                \"z\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u4f4d\u7f6ez\"\n              },\n              \"orientation\": {\n                \"x\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u5411\u304dx\",\n                \"y\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u5411\u304dy\",\n                \"z\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u5411\u304dz\",\n                \"w\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u5411\u304dw\"\n              }\n            },\n            \"UUID\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306eUUID\",\n            \"StampFloat\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306eunix_time[us]\u306efloat\u306b\u3057\u305f\u3082\u306e\"\n          },\n          \"PointCloud\": {\n            \"NumPoints\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u5185\u306b\u542b\u307e\u308c\u308b\u70b9\u7fa4\u306e\u6570\",\n            \"Nearest\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u5185\u3067base_link\u304b\u3089\u6700\u3082\u8fd1\u3044\u70b9\u306e[x,y,z]\u5ea7\u6a19\",\n            \"Stamp\": {\n              \"sec\": \"\u4f7f\u7528\u3057\u305f\u70b9\u7fa4\u306eheader.stamp\u306esec\",\n              \"nanosec\": \"\u4f7f\u7528\u3057\u305f\u70b9\u7fa4\u306eheader.stamp\u306enanosec\"\n            }\n          }\n        }\n      }\n    },\n    \"NonDetection\": {\n      \"Result\": \"Success, Fail, or Invalid\",\n      \"Info\": {\n        \"PointCloud\": {\n          \"NumPoints\": \"\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306b\u51fa\u3066\u3044\u308b\u70b9\u7fa4\u306e\u6570\",\n          \"Distance\": {\n            \"0-1\": \"base_link\u304b\u30890-1m\u306e\u9593\u306e\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306b\u51fa\u3066\u3044\u308b\u70b9\u7fa4\u6570\",\n            \"x-x+1\": \"\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306b\u51fa\u3066\u3044\u308b\u70b9\u7fa4\u306e\u8ddd\u96e2\u6bce\u306e\u5206\u5e03\",\n            \"99-100\": \"base_link\u304b\u308999-100m\u306e\u9593\u306e\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306b\u51fa\u3066\u3044\u308b\u70b9\u7fa4\u6570\"\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"ja/use_case/perception/","title":"\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1","text":"<p>Autoware \u306e\u8a8d\u8b58\u6a5f\u80fd(perception)\u306e\u8a8d\u8b58\u7d50\u679c\u304b\u3089 mAP(mean Average Precision)\u306a\u3069\u306e\u6307\u6a19\u3092\u8a08\u7b97\u3057\u3066\u6027\u80fd\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <p>Autoware \u306e\u5b9f\u884c\u6642\u306b\u306f perception topic \u3092\u4fdd\u5b58\u3059\u308b\u3002\u305d\u306e\u5f8c\u3001\u5f8c\u51e6\u7406\u306e\u4e2d\u3067\u8a55\u4fa1\u3092\u884c\u3046\u3002</p> <p>pass/fail \u3092\u5224\u5b9a\u3059\u308b topic \u306f scenario.yaml \u306b\u8a18\u8ff0\u3055\u308c\u308b evaluation_task \u306b\u57fa\u3065\u304f\u3002\u89e3\u6790\u3057\u305f\u3044 topic \u306f\u30bf\u30fc\u30df\u30ca\u30eb\u5f15\u6570\u304b\u3089\u6307\u5b9a\u3059\u308b\u3002\u6307\u5b9a\u3057\u306a\u3044\u5834\u5408\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u5024\u304c\u4f7f\u7528\u3055\u308c\u308b\u3002</p> <p>\u307e\u305f\u3001\u901a\u5e38\u306epass/fail \u306e\u5224\u5b9a\u306b\u52a0\u3048\u3066\u3001planning_control \u306e\u8a55\u4fa1\u9805\u76ee\u3067\u3042\u308b planning_factor \u3092\u4f7f\u7528\u3067\u304d\u308b\u3002\u8a73\u7d30\u306f\u3053\u3061\u3089\u3092\u53c2\u7167\u3002</p>"},{"location":"ja/use_case/perception/#_2","title":"\u4e8b\u524d\u6e96\u5099","text":"<p>perception \u3067\u306f\u3001\u6a5f\u68b0\u5b66\u7fd2\u306e\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3059\u308b\u3002 \u30e2\u30c7\u30eb\u3092\u4e8b\u524d\u306b\u6e96\u5099\u3057\u3066\u3044\u306a\u3044\u3068 Autoware \u304b\u3089\u8a8d\u8b58\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u306a\u3044\u3002 \u4f55\u3082\u8a55\u4fa1\u7d50\u679c\u304c\u51fa\u3066\u3053\u306a\u3044\u5834\u5408\u306f\u3001\u3053\u306e\u4f5c\u696d\u304c\u6b63\u3057\u304f\u51fa\u6765\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception/#_3","title":"\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u30e2\u30c7\u30eb\u306f Autoware \u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u6642\u306b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u308b\u3002 \u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u65b9\u6cd5\u306f\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b\u306b Autoware \u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u3088\u3063\u3066\u7570\u306a\u308b\u306e\u3067\u3069\u3061\u3089\u306e\u624b\u6cd5\u304c\u4f7f\u308f\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002 \u4ee5\u4e0b\u306e\u30d1\u30bf\u30fc\u30f3\u304c\u5b58\u5728\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception/#ansible","title":"ansible\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u30b9\u30af\u30ea\u30d7\u30c8\u5b9f\u884c\u6642\u306b<code>Download artifacts? [y/N]</code>\u3068\u51fa\u3066\u304f\u308b\u306e\u3067<code>y</code>\u3092\u5165\u529b\u3057\u3066\u30a8\u30f3\u30bf\u30fc\u3092\u62bc\u3059(Autoware foundation\u306emain\u3060\u3068\u3053\u3061\u3089) https://github.com/autowarefoundation/autoware/blob/main/ansible/roles/artifacts/tasks/main.yaml</p>"},{"location":"ja/use_case/perception/#_4","title":"\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d3\u30eb\u30c9\u6642\u306b\u81ea\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u5c11\u3057\u53e4\u3044 Autoware.universe \u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u3053\u3061\u3089\u3001<code>13b96ad3c636389b32fea3a47dfb7cfb7813cadc</code>\u306e\u30b3\u30df\u30c3\u30c8\u30cf\u30c3\u30b7\u30e5\u307e\u3067\u306f\u3053\u3061\u3089\u304c\u4f7f\u7528\u3055\u308c\u308b\u3002 lidar_centerpoint/CMakeList.txt</p>"},{"location":"ja/use_case/perception/#_5","title":"\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u5909\u63db","text":"<p>\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f onnx \u30d5\u30a1\u30a4\u30eb\u306f\u305d\u306e\u307e\u307e\u4f7f\u7528\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001TensorRT \u306e engine \u30d5\u30a1\u30a4\u30eb\u306b\u5909\u63db\u3057\u3066\u5229\u7528\u3059\u308b\u3002 \u5909\u63db\u7528\u306e\u30b3\u30de\u30f3\u30c9\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001Autoware \u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092 source \u3057\u3066\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3002</p> <p><code>$HOME/autoware</code>\u306b Autoware \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u3068\u3057\u3066\u8aac\u660e\u3059\u308b\u3002</p> <pre><code>source $HOME/autoware/install/setup.bash\nros2 launch lidar_centerpoint lidar_centerpoint.launch.xml build_only:=true\n</code></pre> <p>\u5909\u63db\u30b3\u30de\u30f3\u30c9\u304c\u7d42\u4e86\u3059\u308b\u3068\u3001engine \u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u3002 \u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u65b9\u6cd5\u306b\u5408\u308f\u305b\u3066\u51fa\u529b\u5148\u304c\u5909\u308f\u308b\u306e\u3067\u3001\u9069\u5207\u306a\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception/#ansible_1","title":"ansible\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <pre><code>$HOME/autoware_data/lidar_centerpoint/pts_backbone_neck_head_centerpoint_tiny.engine\n$HOME/autoware_data/lidar_centerpoint/pts_voxel_encoder_centerpoint_tiny.engine\n</code></pre>"},{"location":"ja/use_case/perception/#_6","title":"\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d3\u30eb\u30c9\u6642\u306b\u81ea\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<pre><code>$HOME/autoware/install/lidar_centerpoint/share/lidar_centerpoint/data/pts_backbone_neck_head_centerpoint_tiny.engine\n$HOME/autoware/install/lidar_centerpoint/share/lidar_centerpoint/data/pts_voxel_encoder_centerpoint_tiny.engine\n</code></pre>"},{"location":"ja/use_case/perception/#_7","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p>\u307e\u305a\u306f\u3058\u3081\u306b\u3001\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u624b\u9806\u306b\u5f93\u3063\u3066\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u3092\u5b8c\u4e86\u3055\u305b\u307e\u3059\u3002</p> <p>\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u304c\u7d42\u4e86\u3057\u305f\u3089\u3001<code>~/driving_log_replayer_v2/sample_dataset</code>\u306b\u3042\u308b\u30b5\u30f3\u30d7\u30eb rosbag\u3092\u4f7f\u7528\u3057\u3066\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p> <pre><code>ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py \\\n    scenario_path:=$HOME/driving_log_replayer_v2/perception.yaml \\\n    sensing:=false\n</code></pre> <p>\u3042\u308b\u3044\u306f</p> <pre><code>ros2 launch driving_log_replayer_v2 driving_log_replayer_v2.launch.py \\\n    scenario_path:=$HOME/driving_log_replayer_v2/perception.yaml \\\n    remap_arg:=\"/sensing/lidar/top/velodyne_packets,/sensing/lidar/left/velodyne_packets,/sensing/lidar/right/velodyne_packets\"\n</code></pre> <p>[!NOTE] \u30b5\u30f3\u30d7\u30eb rosbag\u306f\u3001\u70b9\u7fa4\u3092\u751f\u6210\u3059\u308b\u305f\u3081\u306epackets\u3068/sensing/lidar/concatenated/pointcloud\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u3002\u305d\u306e\u305f\u3081\u3001\u30c8\u30d4\u30c3\u30af\u3092\u91cd\u8907\u3055\u305b\u306a\u3044\u305f\u3081\u306bremap\u3082\u3057\u304f\u306fsensing\u306e\u975e\u6709\u52b9\u5316\u3092\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002</p> <p>launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u304c\u9806\u306b\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li><code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>rosbag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 Autoware \u304c\u53d7\u3051\u53d6\u308a\u3001perception \u30e2\u30b8\u30e5\u30fc\u30eb\u304c\u8a8d\u8b58\u3092\u884c\u3046</li> <li>\u305d\u3053\u3067\u51fa\u529b\u3055\u308c\u305f\u5bfe\u8c61\u306e topic \u3092\u4fdd\u5b58\u3057\u3066\u304a\u304f</li> <li>rosbag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3057\u305f\u5f8c\u3001\u4fdd\u5b58\u3057\u305f rosbag \u30921\u3064\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u3054\u3068\u306bparse\u3055\u305b\u5bfe\u8c61\u306e topic \u3092\u8a55\u4fa1\u3059\u308b</li> </ol>"},{"location":"ja/use_case/perception/#_8","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>pass/fail \u3092\u5224\u5b9a\u3059\u308b topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/perception/#_9","title":"\u6b63\u5e38","text":"<p>\u30b7\u30ca\u30ea\u30aa\u306eCriterion\u30bf\u30b0\u306eCriteria\u3092\u6e80\u305f\u3059\u3053\u3068\u3002</p> <p>sample \u306e scenario.yaml \u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u3063\u3066\u304a\u308a\u3001</p> <pre><code>Criterion:\n  - PassRate: 95.0 # How much (%) of the evaluation attempts are considered successful.\n    CriteriaMethod: num_gt_tp # refer https://github.com/tier4/driving_log_replayer_v2/blob/develop/driving_log_replayer_v2/driving_log_replayer_v2/criteria/perception.py#L136-L152\n    CriteriaLevel: hard # Level of criteria (perfect/hard/normal/easy, or custom value 0.0-100.0)\n    Filter:\n      Distance: 0.0-50.0 # [m] null [Do not filter by distance] or lower_limit-(upper_limit) [Upper limit can be omitted. If omitted value is 1.7976931348623157e+308]\n  - PassRate: 95.0 # How much (%) of the evaluation attempts are considered successful.\n    CriteriaMethod: num_gt_tp # refer https://github.com/tier4/driving_log_replayer_v2/blob/develop/driving_log_replayer_v2/driving_log_replayer_v2/criteria/perception.py#L136-L152\n    CriteriaLevel: easy # Level of criteria (perfect/hard/normal/easy, or custom value 0.0-100.0)\n    Filter:\n      Distance: 50.0- # [m] null [Do not filter by distance] or lower_limit-(upper_limit) [Upper limit can be omitted. If omitted value is 1.7976931348623157e+308]\n</code></pre> <ul> <li>pass/fail \u3092\u5224\u5b9a\u3059\u308b topic \u306esubscribe 1\u56de\u306b\u5bfe\u3057\u3066\u30010.0-50.0[m]\u306e\u8ddd\u96e2\u306b\u3042\u308bobject\u3067\u3001tp\u306eobject\u6570\u304chard(75.0%)\u4ee5\u4e0a\u306e\u5834\u5408\u3002Result\u306eFrame\u304cSuccess\u306b\u306a\u308b\u3002</li> <li>pass/fail \u3092\u5224\u5b9a\u3059\u308b topic \u306esubscribe 1\u56de\u306b\u5bfe\u3057\u3066\u300150.0-1.7976931348623157e+308[m]\u306e\u8ddd\u96e2\u306b\u3042\u308bobject\u3067\u3001tp\u306eobject\u6570\u304ceasy(25.0%)\u4ee5\u4e0a\u306e\u5834\u5408\u3002Result\u306eFrame\u304cSuccess\u306b\u306a\u308b\u3002</li> <li>\u307e\u305f\u3001<code>PassRate &gt;= \u6b63\u5e38\u6570 / \u5168\u53d7\u4fe1\u6570 * 100</code>\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3059\u3068\u304d\u3001Result\u306eTotal\u304cSuccess\u306b\u306a\u308b\u3002</li> </ul>"},{"location":"ja/use_case/perception/#_10","title":"\u7570\u5e38","text":"<p>\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/perception/#_11","title":"\u8a55\u4fa1\u30b9\u30ad\u30c3\u30d7","text":"<p>\u4ee5\u4e0b\u306e\u5834\u5408\u306b\u3001FrameSkip\u306b1\u8db3\u3059\u51e6\u7406\u306e\u307f\u884c\u3046\u3002 FrameSkip\u306f\u8a55\u4fa1\u3092skip\u3057\u305f\u56de\u6570\u306e\u30ab\u30a6\u30f3\u30bf\u3002</p> <ul> <li>\u53d7\u4fe1\u3057\u305fobject\u306e\u30d8\u30c3\u30c0\u30fc\u6642\u523b\u306e\u524d\u5f8c75msec\u4ee5\u5185\u306b\u771f\u5024\u304c\u5b58\u5728\u3057\u306a\u3044\u5834\u5408</li> <li>\u53d7\u4fe1\u3057\u305fobject\u306efootprint.points\u306e\u6570\u304c1\u304b2\u306e\u5834\u5408(\u3053\u306e\u6761\u4ef6\u306fperception_eval\u304c\u66f4\u65b0\u3055\u308c\u305f\u3089\u306a\u304f\u306a\u308b\u4e88\u5b9a)</li> </ul>"},{"location":"ja/use_case/perception/#nogtnoobject","title":"\u8a55\u4fa1\u30b9\u30ad\u30c3\u30d7NoGTNoObject","text":"<ul> <li>\u30d5\u30a3\u30eb\u30bf\u6761\u4ef6\u306b\u3088\u3063\u3066\u771f\u5024\u3068\u8a8d\u8b58\u7d50\u679c\u304c\u30d5\u30a3\u30eb\u30bf\u3055\u308c\u8a55\u4fa1\u3055\u308c\u306a\u304b\u3063\u305f\u5834\u5408(\u8a55\u4fa1\u7d50\u679cPassFail\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u4e2d\u8eab\u304c\u7a7a\u306e\u5834\u5408)</li> </ul>"},{"location":"ja/use_case/perception/#topic","title":"\u8a55\u4fa1\u30b9\u30af\u30ea\u30d7\u30c8\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>pass/fail \u3092\u5224\u5b9a\u3059\u308b topic \u306f scenario.yaml \u3067\u5b9a\u7fa9\u3059\u308b evaluation_task \u306b\u57fa\u3065\u304f\u3002</p> evaluation_task \u30c7\u30fc\u30bf\u578b detection autoware_perception_msgs/msg/DetectedObjects tracking autoware_perception_msgs/msg/TrackedObjects prediction TBD fp_validation autoware_perception_msgs/msg/DetectedObjects <p>pass/fail \u3068\u306f\u95a2\u4fc2\u306a\u3057\u306b\u5206\u6790\u3092\u3057\u305f\u3044 topic \u306f\u30bf\u30fc\u30df\u30ca\u30eb\u5f15\u6570\u306e USE_CASE_ARGS \u3067\u5b9a\u7fa9\u3067\u304d\u308b\u3002</p> \u5f15\u6570 \u30c7\u30fc\u30bf\u578b evaluation_detection_topic_regex autoware_perception_msgs/msg/DetectedObjects evaluation_tracking_topic_regex autoware_perception_msgs/msg/TrackedObjects evaluation_prediction_topic_regex TBD evaluation_fp_validation_topic_regex autoware_perception_msgs/msg/DetectedObjects <p>\u307e\u305f\u3001\u8a55\u4fa1\u3092\u901a\u3058\u3066\u5f97\u3089\u308c\u305f\u7d50\u679c\u3092 rosbag \u306b\u66f8\u304d\u8fbc\u3080\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /driving_log_replayer_v2/marker/ground_truth visualization_msgs/msg/MarkerArray /driving_log_replayer_v2/marker/results visualization_msgs/msg/MarkerArray"},{"location":"ja/use_case/perception/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> </ul> <p>\u6ce8:\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u6642\u3068\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u6642\u3067\u81ea\u5df1\u4f4d\u7f6e\u3092\u5408\u308f\u305b\u305f\u3044\u306e\u3067 bag \u306b\u5165\u3063\u3066\u3044\u308b tf \u3092\u4f7f\u3044\u56de\u3059\u3002\u305d\u306e\u305f\u3081 localization \u306f\u7121\u52b9\u3067\u3042\u308b\u3002</p>"},{"location":"ja/use_case/perception/#_12","title":"\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea","text":"<p>\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1\u306fperception_eval\u306b\u4f9d\u5b58\u3057\u3066\u3044\u308b\u3002</p>"},{"location":"ja/use_case/perception/#driving_log_replayer_v2","title":"\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u306e driving_log_replayer_v2 \u306e\u5f79\u5272\u5206\u62c5","text":"<p>driving_log_replayer_v2 \u304c ROS \u3068\u306e\u95a2\u4fc2\u90e8\u5206\u3084 pass/fail \u3092\u5224\u5b9a\u3059\u308b\u90e8\u5206\u3092\u62c5\u5f53\u3059\u308b\u3002perception_eval \u304c\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f7f\u3063\u3066\u5b9f\u969b\u306b\u8a55\u4fa1\u3059\u308b\u90e8\u5206\u3092\u62c5\u5f53\u3059\u308b\u3068\u3044\u3046\u5206\u62c5\u306b\u306a\u3063\u3066\u3044\u308b\u3002 perception_eval \u306f ROS \u975e\u4f9d\u5b58\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306a\u306e\u3067\u3001ROS \u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u53d7\u3051\u53d6\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u3044\u3002 \u307e\u305f\u3001timestamp \u304c ROS \u3067\u306f\u30ca\u30ce\u79d2\u3001t4_dataset \u306f <code>nuScenes</code> \u3092\u30d9\u30fc\u30b9\u3057\u3066\u3044\u308b\u305f\u3081\u30de\u30a4\u30af\u30ed\u79d2\u304c\u63a1\u7528\u3055\u308c\u3066\u3044\u308b\u3002 \u3053\u306e\u305f\u3081\u3001\u30e9\u30a4\u30d6\u30e9\u30ea\u4f7f\u7528\u524d\u306b\u9069\u5207\u306a\u5909\u63db\u304c\u5fc5\u8981\u3068\u306a\u308b\u3002</p> <p>\u307e\u305f\u3001perception_eval \u304b\u3089\u8fd4\u3063\u3066\u304f\u308b\u8a55\u4fa1\u7d50\u679c\u3092 ROS \u306e topic \u3067 \u4fdd\u5b58\u3057\u53ef\u8996\u5316\u3059\u308b\u90e8\u5206\u3082\u62c5\u5f53\u3059\u308b\u3002</p> <p>perception_eval \u306f\u3001driving_log_replayer_v2 \u304b\u3089\u6e21\u3055\u308c\u305f\u691c\u77e5\u7d50\u679c\u3068 GroundTruth \u3092\u6bd4\u8f03\u3057\u3066\u6307\u6a19\u3092\u8a08\u7b97\u3057\u3001\u8a55\u4fa1\u3092\u51fa\u529b\u3059\u308b\u90e8\u5206\u3092\u62c5\u5f53\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/perception/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"<p>t4_dataset \u3067\u5fc5\u8981\u306a\u30c8\u30d4\u30c3\u30af\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u3053\u3068</p> <p>\u8eca\u4e21\u306e ECU \u306e CAN \u3068\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b sensor \u306e topic \u304c\u5fc5\u8981 \u4ee5\u4e0b\u306f\u4f8b\u3067\u3042\u308a\u3001\u9055\u3046\u30bb\u30f3\u30b5\u30fc\u3092\u4f7f\u3063\u3066\u3044\u308b\u5834\u5408\u306f\u9069\u5b9c\u8aad\u307f\u66ff\u3048\u308b\u3002 CAMERA \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e camera_info \u3068 image_rect_color_compressed \u3092\u542b\u3081\u308b\u3002 \u5c1a\u3001sensing \u306e true or false \u306b\u3088\u3063\u3066/sensing/lidar/concatenated/pointcloud\u306f\u91cd\u8907\u3057\u306a\u3044\u3088\u3046\u306b remap \u3055\u308c\u308b\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>CAN \u306e\u4ee3\u308f\u308a\u306b vehicle \u306e topic \u3092\u542b\u3081\u3066\u3082\u826f\u3044\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/perception/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/perception/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/perception/#_13","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u8a55\u4fa1\u3068\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e 2 \u7a2e\u985e\u306e\u8a55\u4fa1\u304c\u3042\u308b\u3002 \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306f 1 \u500b\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u884c\u3046\u8a55\u4fa1\u3067\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306f\u8907\u6570\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7528\u3044\u3066\u3001\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6bce\u306e\u7d50\u679c\u306e\u5e73\u5747\u3092\u53d6\u308b\u8a55\u4fa1\u3067\u3042\u308b\u3002</p> <p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u5024\u306e\u5909\u66f4\u304c\u3042\u308a\u5f97\u308b\u306e\u3067 vehicle_id \u3092\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6bce\u306b\u8a2d\u5b9a\u51fa\u6765\u308b\u3088\u3046\u306b\u3059\u308b\u3002 \u307e\u305f\u3001Sensing \u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8d77\u52d5\u3059\u308b\u304b\u3069\u3046\u304b\u306e\u8a2d\u5b9a\u3082\u884c\u3046\u3002</p> <p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/perception/#_14","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>perception \u3067\u306f\u3001\u30b7\u30ca\u30ea\u30aa\u306b\u6307\u5b9a\u3057\u305f\u6761\u4ef6\u3067 perception_eval \u304c\u8a55\u4fa1\u3057\u305f\u7d50\u679c\u3092\u5404 frame \u6bce\u306b\u51fa\u529b\u3059\u308b\u3002 \u5168\u3066\u306e\u30c7\u30fc\u30bf\u3092\u6d41\u3057\u7d42\u308f\u3063\u305f\u3042\u3068\u306b\u3001\u6700\u7d42\u7684\u306a\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u8a08\u7b97\u3057\u3066\u3044\u308b\u305f\u3081\u3001\u6700\u7d42\u884c\u3060\u3051\u3001\u4ed6\u306e\u884c\u3068\u5f62\u5f0f\u304c\u7570\u306a\u308b\u3002</p> <p>\u4ee5\u4e0b\u306b\u3001\u5404\u30d5\u30ec\u30fc\u30e0\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3068\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u793a\u3059\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>\u5404\u30d5\u30ec\u30fc\u30e0\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <pre><code>{\n  \"Frame\": {\n    \"FrameName\": \"\u8a55\u4fa1\u306b\u4f7f\u7528\u3057\u305ft4_dataset\u306e\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\",\n    \"FrameSkip\": \"\u8a55\u4fa1\u304c\u98db\u3070\u3055\u308c\u305f\u56de\u6570\u306e\u5408\u8a08\u3002\u767a\u751f\u3059\u308b\u6761\u4ef6\u306f\u8a55\u4fa1\u7d50\u679c\u306e\u9805\u76ee\u3092\u53c2\u7167\",\n    \"criteria0\": {\n      // criteria0\u306e\u7d50\u679c\u3001\u771f\u5024\u3068\u8a8d\u8b58\u7d50\u679c\u304c\u5b58\u5728\u3059\u308b\u5834\u5408\n      \"PassFail\": {\n        \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n        \"Info\": {\n          \"TP\": \"\u30d5\u30a3\u30eb\u30bf\u6e08\u307fobject\u306e\u4e2d\u3067TP\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\",\n          \"FP\": \"\u30d5\u30a3\u30eb\u30bf\u6e08\u307fobject\u306e\u4e2d\u3067FP\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\",\n          \"FN\": \"\u30d5\u30a3\u30eb\u30bf\u6e08\u307fobject\u306e\u4e2d\u3067FN\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\"\n        },\n        \"Objects\": {\n          // \u8a55\u4fa1\u3057\u305fobject\u306e\u60c5\u5831 \u5225\u9014\u8aac\u660e\u3059\u308b\n        }\n      }\n    },\n    \"criteria1\": {\n      // criteria1\u306e\u7d50\u679c\u3001\u771f\u5024\u3068\u8a8d\u8b58\u7d50\u679c\u304c\u5b58\u5728\u3057\u306a\u3044\u5834\u5408\n      \"NoGTNoObj\": \"\u771f\u5024\u3068\u8a8d\u8b58\u7d50\u679c\u304c\u30d5\u30a3\u30eb\u30bf\u3055\u308c\u3066\u8a55\u4fa1\u3067\u304d\u306a\u304b\u3063\u305f\u56de\u6570\"\n    }\n  }\n}\n</code></pre> <p>\u60c5\u5831\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <pre><code>{\n  \"Frame\": {\n    \"Info\": \"\u60c5\u5831\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\",\n    \"FrameSkip\": \"\u8a55\u4fa1\u304c\u98db\u3070\u3055\u308c\u305f\u56de\u6570\u306e\u5408\u8a08\u3002object\u306e\u8a55\u4fa1\u3092\u4f9d\u983c\u3057\u305f\u304cdataset\u306b75msec\u4ee5\u5185\u306e\u771f\u5024\u304c\u306a\u304f\u5834\u5408\u3001\u307e\u305f\u306f\u3001footprint.points\u306e\u6570\u304c1\u304b2\u306e\u5834\u5408\u306b\u767a\u751f\u3059\u308b\"\n  }\n}\n</code></pre> <p>\u8b66\u544a\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <pre><code>{\n  \"Frame\": {\n    \"Warning\": \"\u8b66\u544a\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\",\n    \"FrameSkip\": \"\u8a55\u4fa1\u304c\u98db\u3070\u3055\u308c\u305f\u56de\u6570\u306e\u5408\u8a08\u3002object\u306e\u8a55\u4fa1\u3092\u4f9d\u983c\u3057\u305f\u304cdataset\u306b75msec\u4ee5\u5185\u306e\u771f\u5024\u304c\u306a\u304f\u5834\u5408\u3001\u307e\u305f\u306f\u3001footprint.points\u306e\u6570\u304c1\u304b2\u306e\u5834\u5408\u306b\u767a\u751f\u3059\u308b\"\n  }\n}\n</code></pre> <p>Objects\u30c7\u30fc\u30bf\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <p>json schema\u3092\u53c2\u7167</p> <p>\u30e1\u30c8\u30ea\u30af\u30b9\u30c7\u30fc\u30bf\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <p>evaluation_task\u304cdetection\u307e\u305f\u306ftracking\u306e\u5834\u5408</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"Score\": {\n        \"TP\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eTP\u7387\",\n          \"label0\": \"label0\u306eTP\u7387\",\n          \"label1\": \"label1\u306eTP\u7387\"\n        },\n        \"FP\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eFP\u7387\",\n          \"label0\": \"label0\u306eFP\u7387\",\n          \"label1\": \"label1\u306eFP\u7387\"\n        },\n        \"FN\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eFN\u7387\",\n          \"label0\": \"label0\u306eFN\u7387\",\n          \"label1\": \"label1\u306eFN\u7387\"\n        },\n        \"TN\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eTN\u7387\",\n          \"label0\": \"label0\u306eTN\u7387\",\n          \"label1\": \"label1\u306eTN\u7387\"\n        },\n        \"AP(Center Distance)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAP\u7387(Center Distance)\",\n          \"label0\": \"label0\u306eAP\u7387(Center Distance)\",\n          \"label1\": \"label1\u306eAP\u7387(Center Distance)\"\n        },\n        \"APH(Center Distance)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAPH\u7387(Center Distance)\",\n          \"label0\": \"label0\u306eAPH\u7387(Center Distance)\",\n          \"label1\": \"label1\u306eAPH\u7387(Center Distance)\"\n        },\n        \"AP(IoU 2D)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAP\u7387(IoU 2D)\",\n          \"label0\": \"label0\u306eAP\u7387(IoU 2D)\",\n          \"label1\": \"label1\u306eAP\u7387(IoU 2D)\"\n        },\n        \"APH(IoU 2D)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAPH\u7387(IoU 2D)\",\n          \"label0\": \"label0\u306eAPH\u7387(IoU 2D)\",\n          \"label1\": \"label1\u306eAPH\u7387(IoU 2D)\"\n        },\n        \"AP(IoU 3D)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAP\u7387(IoU 3D)\",\n          \"label0\": \"label0\u306eAP\u7387(IoU 3D)\",\n          \"label1\": \"label1\u306eAP\u7387(IoU 3D)\"\n        },\n        \"APH(IoU 3D)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAPH\u7387(IoU 3D)\",\n          \"label0\": \"label0\u306eAPH\u7387(IoU 3D)\",\n          \"label1\": \"label1\u306eAPH\u7387(IoU 3D)\"\n        },\n        \"AP(Plane Distance)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAP\u7387(Plane Distance)\",\n          \"label0\": \"label0\u306eAP\u7387(Plane Distance)\",\n          \"label1\": \"label1\u306eAP\u7387(Plane Distance)\"\n        },\n        \"APH(Plane Distance)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAPH\u7387(Plane Distance)\",\n          \"label0\": \"label0\u306eAPH\u7387(Plane Distance)\",\n          \"label1\": \"label1\u306eAPH\u7387(Plane Distance)\"\n        }\n      },\n      \"MOTA\": {\"https://github.com/tier4/autoware_perception_evaluation/blob/develop/docs/ja/perception/metrics.md#tracking\"},\n      \"MOTA\": {\"https://github.com/tier4/autoware_perception_evaluation/blob/develop/docs/ja/perception/metrics.md#tracking\"},\n      \"IDswitch\": {\"https://github.com/tier4/autoware_perception_evaluation/blob/develop/docs/ja/perception/metrics.md#id-switch\"},\n      \"Error\": {\n        \"ALL\": {\n          \"average\": {\n            \"x\": \"x\u5ea7\u6a19\",\n            \"y\": \"y\u5ea7\u6a19\",\n            \"yaw\": \"\u30e8\u30fc\u89d2\",\n            \"length\": \"\u9577\u3055\",\n            \"width\": \"\u5e45\",\n            \"vx\": \"x\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"vy\": \"y\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"nn_plane\": \"\u6700\u8fd1\u508d\u9762\u306e\u8ddd\u96e2\"\n          },\n          \"rms\": {\n            \"x\": \"x\u5ea7\u6a19\",\n            \"y\": \"y\u5ea7\u6a19\",\n            \"yaw\": \"\u30e8\u30fc\u89d2\",\n            \"length\": \"\u9577\u3055\",\n            \"width\": \"\u5e45\",\n            \"vx\": \"x\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"vy\": \"y\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"nn_plane\": \"\u6700\u8fd1\u508d\u9762\u306e\u8ddd\u96e2\"\n          },\n          \"std\": {\n            \"x\": \"x\u5ea7\u6a19\",\n            \"y\": \"y\u5ea7\u6a19\",\n            \"yaw\": \"\u30e8\u30fc\u89d2\",\n            \"length\": \"\u9577\u3055\",\n            \"width\": \"\u5e45\",\n            \"vx\": \"x\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"vy\": \"y\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"nn_plane\": \"\u6700\u8fd1\u508d\u9762\u306e\u8ddd\u96e2\"\n          },\n          \"max\": {\n            \"x\": \"x\u5ea7\u6a19\",\n            \"y\": \"y\u5ea7\u6a19\",\n            \"yaw\": \"\u30e8\u30fc\u89d2\",\n            \"length\": \"\u9577\u3055\",\n            \"width\": \"\u5e45\",\n            \"vx\": \"x\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"vy\": \"y\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"nn_plane\": \"\u6700\u8fd1\u508d\u9762\u306e\u8ddd\u96e2\"\n          },\n          \"min\": {\n            \"x\": \"x\u5ea7\u6a19\",\n            \"y\": \"y\u5ea7\u6a19\",\n            \"yaw\": \"\u30e8\u30fc\u89d2\",\n            \"length\": \"\u9577\u3055\",\n            \"width\": \"\u5e45\",\n            \"vx\": \"x\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"vy\": \"y\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"nn_plane\": \"\u6700\u8fd1\u508d\u9762\u306e\u8ddd\u96e2\"\n          }\n        },\n        \"label0\": \"label0\u306e\u8aa4\u5dee\u30e1\u30c8\u30ea\u30af\u30b9\"\n      }\n    }\n  }\n}\n</code></pre> <p>evaluation_task\u304cfp_validation\u306e\u5834\u5408</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"GroundTruthStatus\": {\n        \"UUID\": {\n          \"rate\": {\n            \"TP\": \"\u8868\u793aUUID\u306eTP\u7387\",\n            \"FP\": \"\u8868\u793aUUID\u306eFP\u7387\",\n            \"TN\": \"\u8868\u793aUUID\u306eTN\u7387\",\n            \"FN\": \"\u8868\u793aUUID\u306eFN\u7387\"\n          },\n          \"frame_nums\": {\n            \"total\": \"GT\u304c\u8a55\u4fa1\u3055\u308c\u308b\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\u306e\u30ea\u30b9\u30c8\",\n            \"TP\": \"GT\u304cTP\u3068\u3057\u3066\u8a55\u4fa1\u3055\u308c\u308b\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\u306e\u30ea\u30b9\u30c8\",\n            \"FP\": \"GT\u304cFP\u3068\u3057\u3066\u8a55\u4fa1\u3055\u308c\u308b\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\u306e\u30ea\u30b9\u30c8\",\n            \"TN\": \"GT\u304cTN\u3068\u3057\u3066\u8a55\u4fa1\u3055\u308c\u308b\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\u306e\u30ea\u30b9\u30c8\",\n            \"FN\": \"GT\u304cFN\u3068\u3057\u3066\u8a55\u4fa1\u3055\u308c\u308b\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\u306e\u30ea\u30b9\u30c8\"\n          }\n        }\n      },\n      \"Scene\": {\n        \"TP\": \"\u30b7\u30fc\u30f3\u306eTP\u7387\",\n        \"FP\": \"\u30b7\u30fc\u30f3\u306eFP\u7387\",\n        \"TN\": \"\u30b7\u30fc\u30f3\u306eTN\u7387\",\n        \"FN\": \"\u30b7\u30fc\u30f3\u306eFN\u7387\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"ja/use_case/perception/#pickle","title":"pickle \u30d5\u30a1\u30a4\u30eb","text":"<p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u8907\u6570\u306e bag \u3092\u518d\u751f\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u304c\u3001ROS \u306e\u4ed5\u69d8\u4e0a\u30011 \u56de\u306e launch \u3067\u3001\u8907\u6570\u306e bag \u3092\u5229\u7528\u3059\u308b\u3053\u3068\u306f\u51fa\u6765\u306a\u3044\u3002 1 \u3064\u306e bag\u3001\u3059\u306a\u308f\u3061 1 \u3064\u306e t4_dataset \u306b\u5bfe\u3057\u3066 launch \u3092 1 \u56de\u53e9\u304f\u3053\u3068\u306a\u308b\u306e\u3067\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u542b\u307e\u308c\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u6570\u3060\u3051 launch \u3092\u5b9f\u884c\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002</p> <p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306f 1 \u56de\u306e launch \u3067\u8a55\u4fa1\u3067\u304d\u306a\u3044\u305f\u3081\u3001perception \u3067\u306f\u3001result.jsonl \u306e\u4ed6\u306b scene_result.pkl \u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u3092\u51fa\u529b\u3059\u308b\u3002 pickle \u30d5\u30a1\u30a4\u30eb\u306f python \u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u4fdd\u5b58\u3057\u305f\u3082\u306e\u3067\u3042\u308a\u3001perception_eval \u306e PerceptionEvaluationManager.frame_results \u3092\u4fdd\u5b58\u3057\u3066\u3044\u308b\u3002 pickle \u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3057\u305f object \u3092\u3059\u3079\u3066\u8aad\u307f\u8fbc\u307f\u3001dataset \u306e\u5e73\u5747\u306e\u6307\u6a19\u3092\u51fa\u529b\u3059\u308b\u3053\u3068\u3067\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u8a55\u4fa1\u304c\u884c\u3048\u308b\u3002</p>"},{"location":"ja/use_case/perception/#_15","title":"\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e\u7d50\u679c\u30d5\u30a1\u30a4\u30eb","text":"<p>\u30b7\u30ca\u30ea\u30aa\u306b\u8907\u6570\u306e dataset \u3092\u8a18\u8ff0\u3057\u305f\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e\u5834\u5408\u306b\u306f\u3001\u7d50\u679c\u51fa\u529b\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b database_result.json \u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <p>\u5f62\u5f0f\u306f\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8 \u3068\u540c\u3058</p>"},{"location":"ja/use_case/perception_2d/","title":"\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1(\u30ab\u30e1\u30e9)","text":"<p>Autoware \u306e\u8a8d\u8b58\u6a5f\u80fd(perception)\u306e\u8a8d\u8b58\u7d50\u679c\u304b\u3089 mAP(mean Average Precision)\u306a\u3069\u306e\u6307\u6a19\u3092\u8a08\u7b97\u3057\u3066\u6027\u80fd\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <p>perception \u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8d77\u52d5\u3057\u3066\u51fa\u529b\u3055\u308c\u308b perception \u306e topic \u3092\u8a55\u4fa1\u7528\u30e9\u30a4\u30d6\u30e9\u30ea\u306b\u6e21\u3057\u3066\u8a55\u4fa1\u3092\u884c\u3046\u3002</p>"},{"location":"ja/use_case/perception_2d/#_2","title":"\u4e8b\u524d\u6e96\u5099","text":"<p>perception \u3067\u306f\u3001\u6a5f\u68b0\u5b66\u7fd2\u306e\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3059\u308b\u3002 \u30e2\u30c7\u30eb\u3092\u4e8b\u524d\u306b\u6e96\u5099\u3057\u3066\u3044\u306a\u3044\u3068Autoware\u304b\u3089\u8a8d\u8b58\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u306a\u3044\u3002 \u4f55\u3082\u8a55\u4fa1\u7d50\u679c\u304c\u51fa\u3066\u3053\u306a\u3044\u5834\u5408\u306f\u3001\u3053\u306e\u4f5c\u696d\u304c\u6b63\u3057\u304f\u51fa\u6765\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#_3","title":"\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u30e2\u30c7\u30eb\u306fAutoware\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u6642\u306b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u308b\u3002 \u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u65b9\u6cd5\u306f\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b\u306bAutoware\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u3088\u3063\u3066\u7570\u306a\u308b\u306e\u3067\u3069\u3061\u3089\u306e\u624b\u6cd5\u304c\u4f7f\u308f\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002 \u4ee5\u4e0b\u306e\u30d1\u30bf\u30fc\u30f3\u304c\u5b58\u5728\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#ansible","title":"ansible\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u30b9\u30af\u30ea\u30d7\u30c8\u5b9f\u884c\u6642\u306b<code>Download artifacts? [y/N]</code>\u3068\u51fa\u3066\u304f\u308b\u306e\u3067<code>y</code>\u3092\u5165\u529b\u3057\u3066\u30a8\u30f3\u30bf\u30fc\u3092\u62bc\u3059(Autoware foundation\u306emain\u3060\u3068\u3053\u3061\u3089) https://github.com/autowarefoundation/autoware/blob/main/ansible/roles/artifacts/tasks/main.yaml</p>"},{"location":"ja/use_case/perception_2d/#_4","title":"\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d3\u30eb\u30c9\u6642\u306b\u81ea\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u5c11\u3057\u53e4\u3044Autoware.universe\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u3053\u3061\u3089\u3001<code>13b96ad3c636389b32fea3a47dfb7cfb7813cadc</code>\u306e\u30b3\u30df\u30c3\u30c8\u30cf\u30c3\u30b7\u30e5\u307e\u3067\u306f\u3053\u3061\u3089\u304c\u4f7f\u7528\u3055\u308c\u308b\u3002 tensorrt_yolox/CMakeList.txt</p>"},{"location":"ja/use_case/perception_2d/#_5","title":"\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u5909\u63db","text":"<p>\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f onnx \u30d5\u30a1\u30a4\u30eb\u306f\u305d\u306e\u307e\u307e\u4f7f\u7528\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001TensorRT \u306e engine \u30d5\u30a1\u30a4\u30eb\u306b\u5909\u63db\u3057\u3066\u5229\u7528\u3059\u308b\u3002 \u5909\u63db\u7528\u306e\u30b3\u30de\u30f3\u30c9\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001autoware \u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092 source \u3057\u3066\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3002</p> <p><code>$HOME/autoware</code>\u306bautoware\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u3068\u3057\u3066\u8aac\u660e\u3059\u308b\u3002</p> <pre><code>source $HOME/autoware/install/setup.bash\nros2 launch tensorrt_yolox yolox.launch.xml use_decompress:=false build_only:=true\n</code></pre>"},{"location":"ja/use_case/perception_2d/#ansible_1","title":"ansible\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <pre><code>$HOME/autoware_data/tensorrt_yolox/yolox-sPlus-T4-960x960-pseudo-finetune.EntropyV2-int8-batch1.engine\n</code></pre>"},{"location":"ja/use_case/perception_2d/#_6","title":"\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d3\u30eb\u30c9\u6642\u306b\u81ea\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<pre><code>$HOME/autoware/install/tensorrt_yolox/share/tensorrt_yolox/data/yolox-sPlus-T4-960x960-pseudo-finetune.EntropyV2-int8-batch1.engine\n</code></pre>"},{"location":"ja/use_case/perception_2d/#pc1launch","title":"(PC1\u53f0\u3067\u8a55\u4fa1\u3059\u308b\u5834\u5408)launch\u30d5\u30a1\u30a4\u30eb\u306e\u4fee\u6b63","text":"<p>PC \u4e00\u53f0\u3067\u8a55\u4fa1\u3059\u308b\u306b\u306f\u3001launch \u3092\u3044\u3058\u3063\u3066\u3001\u30ab\u30e1\u30e9\u306e\u8a8d\u8b58\u7d50\u679c\u3092\u51fa\u529b\u3059\u308b\u3088\u3046\u306b\u5909\u66f4\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002 \u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3001launch \u3092\u5909\u66f4\u3059\u308b\u3002</p> <pre><code>\u276f vcs diff src/\n.................................\ndiff --git a/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml b/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml\nindex 9ca8ea3df..a35e8d00f 100644\n--- a/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml\n+++ b/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml\n@@ -30,6 +30,14 @@\n   &lt;arg name=\"remove_unknown\" default=\"true\"/&gt;\n   &lt;arg name=\"trust_distance\" default=\"30.0\"/&gt;\n\n+  &lt;group&gt;\n+    &lt;include file=\"$(find-pkg-share tensorrt_yolox)/launch/yolox.launch.xml\" /&gt;\n+  &lt;/group&gt;\n+\n+  &lt;group&gt;\n+    &lt;include file=\"$(find-pkg-share bytetrack)/launch/bytetrack.launch.xml\" /&gt;\n+  &lt;/group&gt;\n+\n   &lt;!-- Jetson AGX --&gt;\n   &lt;!-- &lt;include file=\"$(find-pkg-share tensorrt_yolo)/launch/yolo.launch.xml\"&gt;\n     &lt;arg name=\"image_raw0\" value=\"$(var image_raw0)\"/&gt;\ndiff --git a/launch/tier4_perception_launch/launch/perception.launch.xml b/launch/tier4_perception_launch/launch/perception.launch.xml\nindex 0a2ef57f6..9a9b06379 100644\n--- a/launch/tier4_perception_launch/launch/perception.launch.xml\n+++ b/launch/tier4_perception_launch/launch/perception.launch.xml\n@@ -33,7 +33,7 @@\n   &lt;arg name=\"camera_info6\" default=\"/sensing/camera/camera6/camera_info\"/&gt;\n   &lt;arg name=\"image_raw7\" default=\"/sensing/camera/camera7/image_rect_color\"/&gt;\n   &lt;arg name=\"camera_info7\" default=\"/sensing/camera/camera7/camera_info\"/&gt;\n-  &lt;arg name=\"image_number\" default=\"6\" description=\"choose image raw number(0-7)\"/&gt;\n+  &lt;arg name=\"image_number\" default=\"1\" description=\"choose image raw number(0-7)\"/&gt;\n   &lt;arg name=\"use_vector_map\" default=\"true\" description=\"use vector map in prediction\"/&gt;\n   &lt;arg name=\"use_pointcloud_map\" default=\"true\" description=\"use pointcloud map in detection\"/&gt;\n   &lt;arg name=\"use_object_filter\" default=\"true\" description=\"use object filter\"/&gt;\ndiff --git a/perception/tensorrt_yolox/launch/yolox.launch.xml b/perception/tensorrt_yolox/launch/yolox.launch.xml\nindex b697b1f50..b9cb53102 100644\n--- a/perception/tensorrt_yolox/launch/yolox.launch.xml\n+++ b/perception/tensorrt_yolox/launch/yolox.launch.xml\n@@ -1,7 +1,7 @@\n &lt;?xml version=\"1.0\"?&gt;\n &lt;launch&gt;\n   &lt;arg name=\"input/image\" default=\"/sensing/camera/camera0/image_rect_color\"/&gt;\n-  &lt;arg name=\"output/objects\" default=\"/perception/object_recognition/detection/rois0\"/&gt;\n+  &lt;arg name=\"output/objects_yolox\" default=\"/perception/object_recognition/detection/rois0\"/&gt;\n   &lt;arg name=\"model_name\" default=\"yolox-tiny\"/&gt;\n   &lt;arg name=\"model_path\" default=\"$(find-pkg-share tensorrt_yolox)/data\"/&gt;\n   &lt;arg name=\"score_threshold\" default=\"0.35\"/&gt;\n@@ -16,7 +16,7 @@\n\n   &lt;node pkg=\"tensorrt_yolox\" exec=\"tensorrt_yolox_node_exe\" name=\"tensorrt_yolox\" output=\"screen\"&gt;\n     &lt;remap from=\"~/in/image\" to=\"$(var input/image)\"/&gt;\n-    &lt;remap from=\"~/out/objects\" to=\"$(var output/objects)\"/&gt;\n+    &lt;remap from=\"~/out/objects\" to=\"$(var output/objects_yolox)\"/&gt;\n     &lt;param name=\"score_threshold\" value=\"$(var score_threshold)\"/&gt;\n     &lt;param name=\"nms_threshold\" value=\"$(var nms_threshold)\"/&gt;\n     &lt;param name=\"model_path\" value=\"$(var model_path)/$(var model_name).onnx\"/&gt;\n</code></pre>"},{"location":"ja/use_case/perception_2d/#_7","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p>launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>perception_2d_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001\u30ab\u30e1\u30e9\u30c7\u30fc\u30bf\u3092\u51fa\u529b\u3057\u3001perception \u30e2\u30b8\u30e5\u30fc\u30eb\u304c\u8a8d\u8b58\u3092\u884c\u3046</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c/perception/object_recognition/detection{/tracked}/rois{camera_no} \u3092 subscribe \u3057\u3066\u3001\u30b3\u30fc\u30eb\u30d0\u30c3\u30af\u3067 perception_eval \u306e\u95a2\u6570\u3092\u7528\u3044\u3066\u8a55\u4fa1\u3057\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/perception_2d/#_8","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#_9","title":"\u6b63\u5e38","text":"<p>perception_eval \u306e\u8a55\u4fa1\u95a2\u6570\u3092\u5b9f\u884c\u3057\u3066\u4ee5\u4e0b\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3059\u3068\u304d</p> <ol> <li>frame_result.pass_fail_result \u306b object \u304c\u6700\u4f4e 1 \u3064\u5165\u3063\u3066\u3044\u308b (<code>tp_object_results != [] and fp_object_results != [] and fn_objects != []</code>)</li> <li>\u8a55\u4fa1\u5931\u6557\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304c 0 \u500b (<code>frame_result.pass_fail_result.get_fail_object_num() == 0</code>)</li> </ol>"},{"location":"ja/use_case/perception_2d/#_10","title":"\u7570\u5e38","text":"<p>\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/perception_2d/#_11","title":"\u8a55\u4fa1\u30b9\u30ad\u30c3\u30d7","text":"<p>\u4ee5\u4e0b\u306e\u5834\u5408\u306b\u3001\u8a55\u4fa1\u3092\u305b\u305a\u306b\u8a55\u4fa1\u304c\u98db\u3070\u3055\u308c\u305f\u56de\u6570\u306e\u30ab\u30a6\u30f3\u30c8(FrameSkip)\u30921\u8db3\u3059\u51e6\u7406\u306e\u307f\u884c\u3046</p> <ul> <li>\u53d7\u4fe1\u3057\u305fobject\u306e\u30d8\u30c3\u30c0\u30fc\u6642\u523b\u306e\u524d\u5f8c75msec\u4ee5\u5185\u306b\u771f\u5024\u304c\u5b58\u5728\u3057\u306a\u3044\u5834\u5408</li> </ul>"},{"location":"ja/use_case/perception_2d/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /perception/object_recognition/detection/rois{camera_no} tier4_perception_msgs/msg/DetectedObjectsWithFeature /perception/object_recognition/detection/tracked/rois{camera_no} tier4_perception_msgs/msg/DetectedObjectsWithFeature <p>Published topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b - -"},{"location":"ja/use_case/perception_2d/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> <li>perception_mode: camera_lidar_fusion</li> </ul> <p>\u6ce8:\u30a2\u30ce\u30fc\u30c6\u30b7\u30e7\u30f3\u6642\u3068\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u6642\u3067\u81ea\u5df1\u4f4d\u7f6e\u3092\u5408\u308f\u305b\u305f\u3044\u306e\u3067 bag \u306b\u5165\u3063\u3066\u3044\u308b tf \u3092\u4f7f\u3044\u56de\u3059\u3002\u305d\u306e\u305f\u3081 localization \u306f\u7121\u52b9\u3067\u3042\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#_12","title":"\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea","text":"<p>\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1\u306fperception_eval\u306b\u4f9d\u5b58\u3057\u3066\u3044\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#driving_log_replayer_v2","title":"\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u306e driving_log_replayer_v2 \u306e\u5f79\u5272\u5206\u62c5","text":"<p>driving_log_replayer_v2 \u304c ROS \u3068\u306e\u63a5\u7d9a\u90e8\u5206\u3092\u62c5\u5f53\u3057\u3001perception_eval \u304c\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f7f\u3063\u3066\u5b9f\u969b\u306b\u8a55\u4fa1\u3059\u308b\u90e8\u5206\u3092\u62c5\u5f53\u3059\u308b\u3068\u3044\u3046\u5206\u62c5\u306b\u306a\u3063\u3066\u3044\u308b\u3002 perception_eval \u306f ROS \u975e\u4f9d\u5b58\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306a\u306e\u3067\u3001ROS \u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u53d7\u3051\u53d6\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u3044\u3002 \u307e\u305f\u3001timestamp \u304c ROS \u3067\u306f\u30ca\u30ce\u79d2\u3001t4_dataset \u306f <code>nuScenes</code> \u3092\u30d9\u30fc\u30b9\u3057\u3066\u3044\u308b\u305f\u3081\u30df\u30ea\u79d2\u304c\u63a1\u7528\u3055\u308c\u3066\u3044\u308b\u3002 \u3053\u306e\u305f\u3081\u3001\u30e9\u30a4\u30d6\u30e9\u30ea\u4f7f\u7528\u524d\u306b\u9069\u5207\u306a\u5909\u63db\u304c\u5fc5\u8981\u3068\u306a\u308b\u3002</p> <p>driving_log_replayer_v2 \u306f\u3001autoware \u306e perception \u30e2\u30b8\u30e5\u30fc\u30eb\u304b\u3089\u51fa\u529b\u3055\u308c\u305f topic \u3092 subscribe \u3057\u3001perception_eval \u3067\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b class \u306b\u5408\u308f\u305b\u305f\u30c7\u30fc\u30bf\u5f62\u5f0f\u306b\u5909\u63db\u3057\u3066\u6e21\u3059\u3002 \u307e\u305f\u3001perception_eval \u304b\u3089\u8fd4\u3063\u3066\u304f\u308b\u8a55\u4fa1\u7d50\u679c\u306e ROS \u306e topic \u3067 publish \u3057\u53ef\u8996\u5316\u3059\u308b\u90e8\u5206\u3082\u62c5\u5f53\u3059\u308b\u3002</p> <p>perception_eval \u306f\u3001driving_log_replayer_v2 \u304b\u3089\u6e21\u3055\u308c\u305f\u691c\u77e5\u7d50\u679c\u3068 GroundTruth \u3092\u6bd4\u8f03\u3057\u3066\u6307\u6a19\u3092\u8a08\u7b97\u3057\u3001\u7d50\u679c\u3092\u51fa\u529b\u3059\u308b\u90e8\u5206\u3092\u62c5\u5f53\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"<p>t4_dataset \u3067\u5fc5\u8981\u306a\u30c8\u30d4\u30c3\u30af\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u3053\u3068</p> <p>\u8eca\u4e21\u306e ECU \u306e CAN \u3068\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b sensor \u306e topic \u304c\u5fc5\u8981 \u4ee5\u4e0b\u306f\u4f8b\u3067\u3042\u308a\u3001\u9055\u3046\u30bb\u30f3\u30b5\u30fc\u3092\u4f7f\u3063\u3066\u3044\u308b\u5834\u5408\u306f\u9069\u5b9c\u8aad\u307f\u66ff\u3048\u308b\u3002</p> <p>LiDAR \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e LiDAR \u306e packets \u3092\u542b\u3081\u308b\u3002 /sensing/lidar/concatenated/pointcloud\u306flaunch\u306eargument\u306bsensing:=false\u3092\u8ffd\u52a0\u3057\u305f\u5834\u5408\u306b\u5229\u7528\u3055\u308c\u308b\u3002</p> <p>CAMERA \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e camera_info \u3068 image_rect_color_compressed \u3092\u542b\u3081\u308b</p> topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>CAN \u306e\u4ee3\u308f\u308a\u306b vehicle \u306e topic \u3092\u542b\u3081\u3066\u3082\u826f\u3044\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/perception_2d/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/perception_2d/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#_13","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u8a55\u4fa1\u3068\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e 2 \u7a2e\u985e\u306e\u8a55\u4fa1\u304c\u3042\u308b\u3002 \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306f 1 \u500b\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u884c\u3046\u8a55\u4fa1\u3067\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306f\u8907\u6570\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7528\u3044\u3066\u3001\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6bce\u306e\u7d50\u679c\u306e\u5e73\u5747\u3092\u53d6\u308b\u8a55\u4fa1\u3067\u3042\u308b\u3002</p> <p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u5024\u306e\u5909\u66f4\u304c\u3042\u308a\u5f97\u308b\u306e\u3067 vehicle_id \u3092\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6bce\u306b\u8a2d\u5b9a\u51fa\u6765\u308b\u3088\u3046\u306b\u3059\u308b\u3002 \u307e\u305f\u3001Sensing \u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8d77\u52d5\u3059\u308b\u304b\u3069\u3046\u304b\u306e\u8a2d\u5b9a\u3082\u884c\u3046\u3002</p> <p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/perception_2d/#_14","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>perception \u3067\u306f\u3001\u30b7\u30ca\u30ea\u30aa\u306b\u6307\u5b9a\u3057\u305f\u6761\u4ef6\u3067 perception_eval \u304c\u8a55\u4fa1\u3057\u305f\u7d50\u679c\u3092\u5404 frame \u6bce\u306b\u51fa\u529b\u3059\u308b\u3002 \u5168\u3066\u306e\u30c7\u30fc\u30bf\u3092\u6d41\u3057\u7d42\u308f\u3063\u305f\u3042\u3068\u306b\u3001\u6700\u7d42\u7684\u306a\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u8a08\u7b97\u3057\u3066\u3044\u308b\u305f\u3081\u3001\u6700\u7d42\u884c\u3060\u3051\u3001\u4ed6\u306e\u884c\u3068\u5f62\u5f0f\u304c\u7570\u306a\u308b\u3002</p> <p>\u4ee5\u4e0b\u306b\u3001\u5404\u30d5\u30ec\u30fc\u30e0\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3068\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u793a\u3059\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>\u5404\u30d5\u30ec\u30fc\u30e0\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <pre><code>{\n  \"Frame\": {\n    \"CameraType\": \"\u8a55\u4fa1\u3057\u305f\u30ab\u30e1\u30e9\",\n    \"FrameName\": \"\u8a55\u4fa1\u306b\u4f7f\u7528\u3057\u305ft4_dataset\u306e\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\",\n    \"FrameSkip\": \"object\u306e\u8a55\u4fa1\u3092\u4f9d\u983c\u3057\u305f\u304cdataset\u306b75msec\u4ee5\u5185\u306e\u771f\u5024\u304c\u306a\u304f\u8a55\u4fa1\u3092\u98db\u3070\u3055\u308c\u305f\u56de\u6570\",\n    \"PassFail\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"TP\": \"TP\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\",\n        \"FP\": \"FP\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\",\n        \"FN\": \"FN\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\"\n      }\n    }\n  }\n}\n</code></pre> <p>\u30e1\u30c8\u30ea\u30af\u30b9\u30c7\u30fc\u30bf\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"Score\": {\n        \"TP\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eTP\u7387\",\n          \"label0\": \"label0\u306eTP\u7387\",\n          \"label1\": \"label1\u306eTP\u7387\"\n        },\n        \"FP\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eFP\u7387\",\n          \"label0\": \"label0\u306eFP\u7387\",\n          \"label1\": \"label1\u306eFP\u7387\"\n        },\n        \"FN\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eFN\u7387\",\n          \"label0\": \"label0\u306eFN\u7387\",\n          \"label1\": \"label1\u306eFN\u7387\"\n        },\n        \"TN\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eTN\u7387\",\n          \"label0\": \"label0\u306eTN\u7387\",\n          \"label1\": \"label1\u306eTN\u7387\"\n        },\n        \"AP(Center Distance)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAP\u7387(Center Distance)\",\n          \"label0\": \"label0\u306eAP\u7387(Center Distance)\",\n          \"label1\": \"label1\u306eAP\u7387(Center Distance)\"\n        },\n        \"APH(Center Distance)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAPH\u7387(Center Distance)\",\n          \"label0\": \"label0\u306eAPH\u7387(Center Distance)\",\n          \"label1\": \"label1\u306eAPH\u7387(Center Distance)\"\n        },\n        \"AP(IoU 2D)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAP\u7387(IoU 2D)\",\n          \"label0\": \"label0\u306eAP\u7387(IoU 2D)\",\n          \"label1\": \"label1\u306eAP\u7387(IoU 2D)\"\n        },\n        \"APH(IoU 2D)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAPH\u7387(IoU 2D)\",\n          \"label0\": \"label0\u306eAPH\u7387(IoU 2D)\",\n          \"label1\": \"label1\u306eAPH\u7387(IoU 2D)\"\n        }\n      },\n      \"ConfusionMatrix\": {\n        \"label0(\u771f\u5024)\": {\n          \"label0(\u4e88\u6e2c\u5024)\": \"\u5024\",\n          \"label1(\u4e88\u6e2c\u5024)\": \"\u5024\"\n        },\n        \"label1(\u771f\u5024)\": {\n          \"label0(\u4e88\u6e2c\u5024)\": \"\u5024\",\n          \"label1(\u4e88\u6e2c\u5024)\": \"\u5024\"\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"ja/use_case/perception_2d/#pickle","title":"pickle \u30d5\u30a1\u30a4\u30eb","text":"<p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u8907\u6570\u306e bag \u3092\u518d\u751f\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u304c\u3001ROS \u306e\u4ed5\u69d8\u4e0a\u30011 \u56de\u306e launch \u3067\u3001\u8907\u6570\u306e bag \u3092\u5229\u7528\u3059\u308b\u3053\u3068\u306f\u51fa\u6765\u306a\u3044\u3002 1 \u3064\u306e bag\u3001\u3059\u306a\u308f\u3061 1 \u3064\u306e t4_dataset \u306b\u5bfe\u3057\u3066 launch \u3092 1 \u56de\u53e9\u304f\u3053\u3068\u306a\u308b\u306e\u3067\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u542b\u307e\u308c\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u6570\u3060\u3051 launch \u3092\u5b9f\u884c\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002</p> <p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306f 1 \u56de\u306e launch \u3067\u8a55\u4fa1\u3067\u304d\u306a\u3044\u305f\u3081\u3001perception \u3067\u306f\u3001result.jsonl \u306e\u4ed6\u306b scene_result.pkl \u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u3092\u51fa\u529b\u3059\u308b\u3002 pickle \u30d5\u30a1\u30a4\u30eb\u306f python \u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u4fdd\u5b58\u3057\u305f\u3082\u306e\u3067\u3042\u308a\u3001perception_eval \u306e PerceptionEvaluationManager.frame_results \u3092\u4fdd\u5b58\u3057\u3066\u3044\u308b\u3002 pickle \u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3057\u305f object \u3092\u3059\u3079\u3066\u8aad\u307f\u8fbc\u307f\u3001dataset \u306e\u5e73\u5747\u306e\u6307\u6a19\u3092\u51fa\u529b\u3059\u308b\u3053\u3068\u3067\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u8a55\u4fa1\u304c\u884c\u3048\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#_15","title":"\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e\u7d50\u679c\u30d5\u30a1\u30a4\u30eb","text":"<p>\u30b7\u30ca\u30ea\u30aa\u306b\u8907\u6570\u306e dataset \u3092\u8a18\u8ff0\u3057\u305f\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e\u5834\u5408\u306b\u306f\u3001\u7d50\u679c\u51fa\u529b\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b database_result.json \u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <p>\u5f62\u5f0f\u306f\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8 \u3068\u540c\u3058</p>"},{"location":"ja/use_case/perception_reproducer/","title":"Perception Reproducer\u306e\u8a55\u4fa1","text":"<p>rosbag\u304b\u3089\u518d\u73fe\u3055\u308c\u305f\u611f\u77e5\u30c7\u30fc\u30bf\u3092\u7528\u3044\u305f\u9589\u30eb\u30fc\u30d7\u6761\u4ef6\u4e0b\u3067\u3001\u6307\u5b9a\u3055\u308c\u305f\u30eb\u30fc\u30c8\u3092\u5b8c\u8d70\u3067\u304d\u308b\u304b\u8a55\u4fa1\u3059\u308b\u3002 perception_reproducer\u30ce\u30fc\u30c9\u306f\u73fe\u5728\u306e\u81ea\u8eca\u4f4d\u7f6e\u306b\u57fa\u3065\u3044\u3066rosbag\u304b\u3089\u611f\u77e5\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u518d\u73fe\u3057\u3001\u9589\u30eb\u30fc\u30d7\u30c6\u30b9\u30c8\u3092\u53ef\u80fd\u306b\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#_1","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p>launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>perception_reproducer_evaluator_node</code>)\u3068 <code>planning_simulator.launch</code>\u3001<code>perception_reproducer</code>\u30ce\u30fc\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li><code>perception_reproducer</code>\u30ce\u30fc\u30c9\u306f\u73fe\u5728\u306e\u81ea\u8eca\u4f4d\u7f6e\u306b\u57fa\u3065\u3044\u3066rosbag\u304b\u3089\u611f\u77e5\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u8aad\u307f\u53d6\u308a\u3001\u30d1\u30d6\u30ea\u30c3\u30b7\u30e5\u3059\u308b</li> <li>Autoware\u304cDRIVING\u72b6\u614b\uff08ENGAGE\uff09\u306b\u5165\u308b\u3068\u8eca\u4e21\u304c\u8d70\u884c\u3092\u958b\u59cb\u3059\u308b</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c topic \u3092 subscribe \u3057\u3066\u3001\u5404\u57fa\u6e96\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3057\u3066\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>\u3059\u3079\u3066\u306epass\u6761\u4ef6\u304c\u6e80\u305f\u3055\u308c\u308b\u304b\u3001\u3044\u305a\u308c\u304b\u306efail\u6761\u4ef6\u304c\u30c8\u30ea\u30ac\u30fc\u3055\u308c\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/perception_reproducer/#_2","title":"\u8a55\u4fa1\u7d50\u679c","text":""},{"location":"ja/use_case/perception_reproducer/#pass","title":"Pass\u6761\u4ef6","text":"<p><code>pass_conditions</code>\u5185\u306e\u3059\u3079\u3066\u306e\u6761\u4ef6\u30b0\u30eb\u30fc\u30d7\u304c\u4e00\u5ea6\u6e80\u305f\u3055\u308c\u308b\u3068\u3001\u30c6\u30b9\u30c8\u304c\u6210\u529f\u3057\u3066\u7d42\u4e86\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#ego_kinematic_trigger","title":"ego_kinematic_trigger","text":"<p>\u81ea\u8eca\u4e21\u304c\u6307\u5b9a\u3055\u308c\u305f\u30a8\u30ea\u30a2\u306b\u5230\u9054\u3057\u305f\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <ul> <li>\u30b7\u30ca\u30ea\u30aa\u306barea\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001\u81ea\u8eca\u4e21\u306ex,y\u4f4d\u7f6e\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305fx,y\u5ea7\u6a19\u304b\u3089range\u306e\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> <li>\u30b7\u30ca\u30ea\u30aa\u306bvelocity\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001\u81ea\u8eca\u4e21\u306e\u901f\u5ea6\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> <li>\u30b7\u30ca\u30ea\u30aa\u306bacceleration\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001\u81ea\u8eca\u4e21\u306e\u52a0\u901f\u5ea6\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> </ul>"},{"location":"ja/use_case/perception_reproducer/#time_wait_trigger","title":"time_wait_trigger","text":"<p>\u6307\u5b9a\u3055\u308c\u305f\u5f85\u6a5f\u6642\u9593\u304c\u7d4c\u904e\u3057\u305f\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <ul> <li>\u30a2\u30af\u30c6\u30a3\u30d9\u30fc\u30b7\u30e7\u30f3\u304b\u3089\u306e\u7d4c\u904e\u6642\u9593\u304c<code>wait_seconds</code>\u306b\u9054\u3059\u308b\u3068\u6761\u4ef6\u304c\u6e80\u305f\u3055\u308c\u308b\u3002</li> </ul>"},{"location":"ja/use_case/perception_reproducer/#condition_group","title":"condition_group","text":"<p>\u30cd\u30b9\u30c8\u3055\u308c\u305f\u6761\u4ef6\u30b0\u30eb\u30fc\u30d7\u304c\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u3066\u3044\u308b\u3002\u30b0\u30eb\u30fc\u30d7\u306f<code>start_at</code>\u3068<code>end_at</code>\u3067\u8a2d\u5b9a\u3067\u304d\u3001\u3044\u3064\u30a2\u30af\u30c6\u30a3\u30d6\u306b\u306a\u308b\u304b\u3092\u5236\u5fa1\u3067\u304d\u308b\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#fail","title":"Fail\u6761\u4ef6","text":"<p><code>fail_conditions</code>\u5185\u306e\u3044\u305a\u308c\u304b\u306e\u6761\u4ef6\u30b0\u30eb\u30fc\u30d7\u304c\u4e00\u5ea6\u6e80\u305f\u3055\u308c\u306a\u3044\u3068\u3001\u30c6\u30b9\u30c8\u304c\u5931\u6557\u3057\u3001<code>terminated_after_fail_s</code>\u79d2\u5f8c\u306b\u7d42\u4e86\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#metric","title":"metric","text":"<p>\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u8a55\u4fa1\u3059\u308b\u3002planning_control\u306e\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3068\u540c\u3058\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#diagnostic","title":"diagnostic","text":"<p>\u8a3a\u65ad\u30b9\u30c6\u30fc\u30bf\u30b9\u3092\u8a55\u4fa1\u3059\u308b\u3002diagnostics\u306e\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3068\u540c\u3058\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#planning_factor","title":"planning_factor","text":"<p>\u8a08\u753b\u56e0\u5b50\u3092\u8a55\u4fa1\u3059\u308b\u3002planning_control\u306e\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3068\u540c\u3058\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#ego_kinematic","title":"ego_kinematic","text":"<p>\u30a2\u30af\u30c6\u30a3\u30d6\u671f\u9593\u4e2d\u3001\u81ea\u8eca\u4e21\u306e\u904b\u52d5\u5b66\u6761\u4ef6\uff08\u4f4d\u7f6e\u3001\u901f\u5ea6\u3001\u52a0\u901f\u5ea6\uff09\u3092\u7d99\u7d9a\u7684\u306b\u8a55\u4fa1\u3059\u308b\u3002</p> <ul> <li>\u30b7\u30ca\u30ea\u30aa\u306barea\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001\u81ea\u8eca\u4e21\u306ex,y\u4f4d\u7f6e\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305fx,y\u5ea7\u6a19\u304b\u3089range\u306e\u7bc4\u56f2\u5185/\u5916\u306b\u3042\u308b\u3002</li> <li>\u30b7\u30ca\u30ea\u30aa\u306bvelocity\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001\u81ea\u8eca\u4e21\u306e\u901f\u5ea6\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> <li>\u30b7\u30ca\u30ea\u30aa\u306bacceleration\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001\u81ea\u8eca\u4e21\u306e\u52a0\u901f\u5ea6\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> </ul>"},{"location":"ja/use_case/perception_reproducer/#condition_group_1","title":"condition_group","text":"<p>\u30cd\u30b9\u30c8\u3055\u308c\u305f\u6761\u4ef6\u30b0\u30eb\u30fc\u30d7\u304c\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u3066\u3044\u308b\u3002\u30b0\u30eb\u30fc\u30d7\u306f<code>start_at</code>\u3068<code>end_at</code>\u3067\u8a2d\u5b9a\u3067\u304d\u3001\u3044\u3064\u30a2\u30af\u30c6\u30a3\u30d6\u306b\u306a\u308b\u304b\u3092\u5236\u5fa1\u3067\u304d\u308b\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#_3","title":"\u8a55\u4fa1\u7d50\u679c\u306e\u51fa\u529b\u5148\u30d5\u30a1\u30a4\u30eb","text":"<p>perception_reproducer\u306b\u304a\u3044\u3066\u306f\u3001\u4ee5\u4e0b\u306e3\u3064\u306e\u30d5\u30a1\u30a4\u30eb\u306b\u305d\u308c\u305e\u308cresult.jsonl\u304c\u4f5c\u6210\u3055\u308c\u308b\u3002 result.jsonl\u306f\u5fc5\u305a\u51fa\u529b\u3055\u308c\u308b\u304c\u3001pass_result.jsonl\u3068fail_result.jsonl\u306f\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u5834\u5408\u306b\u306e\u307f\u51fa\u529b\u3055\u308c\u308b</p>"},{"location":"ja/use_case/perception_reproducer/#resultjsonl","title":"result.jsonl","text":"<p>output_dir/result.jsonl\u306b\u51fa\u529b\u3055\u308c\u308b\u3002 pass\u3068fail\u8a55\u4fa1\u304b\u3089\u307e\u3068\u3081\u3055\u308c\u305f\u8a55\u4fa1\u7d50\u679c\u304c\u8a18\u8ff0\u3055\u308c\u308b\u3002</p> <p>Evaluator\u3067\u5b9f\u884c\u3059\u308b\u5834\u5408\u306f\u3001\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u306e\u6700\u7d42\u884c\u304c\u53c2\u7167\u3055\u308c\u3066\u6210\u5426\u304c\u6c7a\u5b9a\u3055\u308c\u308b\u3002 \u3053\u306e\u305f\u3081\u3001pass_result.jsonl\u3068fail_result.jsonl\u306e\u7d50\u679c\u3092\u30de\u30fc\u30b8\u3057\u305f\u6700\u7d42\u7684\u306a\u6210\u5426\u306e\u60c5\u5831\u304cpost_process\u3067\u66f8\u304d\u8fbc\u307e\u308c\u308b\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#pass_resultjsonl","title":"pass_result.jsonl","text":"<p>output_dir/result_archive/pass_result.jsonl\u306b\u51fa\u529b\u3055\u308c\u308b\u3002 pass\u6761\u4ef6\u306e\u8a55\u4fa1\u7d50\u679c\u304c\u8a18\u8ff0\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#fail_resultjsonl","title":"fail_result.jsonl","text":"<p>output_dir/result_archive/fail_result.jsonl\u306b\u51fa\u529b\u3055\u308c\u308b\u3002 fail\u6761\u4ef6\u306e\u8a55\u4fa1\u7d50\u679c\u304c\u8a18\u8ff0\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> Topic name Data type /localization/kinematic_state nav_msgs/msg/Odometry /localization/acceleration geometry_msgs/msg/AccelWithCovarianceStamped /control/control_evaluator/metrics tier4_metric_msg/msg/MetricArray /planning/planning_evaluator/metrics tier4_metric_msg/msg/MetricArray /system/processing_time/metrics tier4_metric_msg/msg/MetricArray /planning/planning_factors/** autoware_internal_planning_msgs/msg/PlanningFactorArray /diagnostics diagnostic_msgs/msg/DiagnosticArray /autoware/state autoware_system_msgs/msg/AutowareState <p>Published topics:</p> Topic name Data type /driving_log_replayer/perception_reproducer/results std_msgs/msg/String /driving_log_replayer/perception_reproducer/pass_results std_msgs/msg/String /driving_log_replayer/perception_reproducer/fail_results std_msgs/msg/String"},{"location":"ja/use_case/perception_reproducer/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"<p>perception_reproducer\u3092\u53c2\u7167\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#planning-simulator","title":"Planning Simulator","text":"<p>\u3053\u306e\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306f\u3001\u8eca\u4e21\u304c\u5b9f\u969b\u306b\u8d70\u884c\u3067\u304d\u308b\u9589\u30eb\u30fc\u30d7\u30c6\u30b9\u30c8\u3092\u53ef\u80fd\u306b\u3059\u308b\u305f\u3081\u3001<code>logging_simulator.launch</code>\u306e\u4ee3\u308f\u308a\u306b<code>planning_simulator.launch</code>\u3092\u4f7f\u7528\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#perception-reproducer_1","title":"Perception Reproducer\u30ce\u30fc\u30c9","text":"<p><code>planning_debug_tools</code>\u30d1\u30c3\u30b1\u30fc\u30b8\u306e<code>perception_reproducer</code>\u30ce\u30fc\u30c9\u306f\u3001\u73fe\u5728\u306e\u81ea\u8eca\u4f4d\u7f6e\u306b\u57fa\u3065\u3044\u3066rosbag\u304b\u3089\u611f\u77e5\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u518d\u73fe\u3059\u308b\u3002 \u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001perception_reproducer\u3092\u53c2\u7167\u3002</p> <p>\u8a2d\u5b9a\u30aa\u30d7\u30b7\u30e7\u30f3\uff1a</p> <ul> <li><code>noise</code>: \u611f\u77e5\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u30ce\u30a4\u30ba\u3092\u9069\u7528\u3059\u308b</li> <li><code>reproduce_cool_down</code>: \u518d\u30d1\u30d6\u30ea\u30c3\u30b7\u30e5\u306e\u30af\u30fc\u30eb\u30c0\u30a6\u30f3\u6642\u9593\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: 80.0\uff09</li> <li><code>tracked_object</code>: \u8ffd\u8de1\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u30d1\u30d6\u30ea\u30c3\u30b7\u30e5\u3059\u308b</li> <li><code>search_radius</code>: rosbag\u306e\u81ea\u8eca\u30aa\u30c9\u30e1\u30c8\u30ea\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u691c\u7d22\u3059\u308b\u691c\u7d22\u534a\u5f84\uff08\u30c7\u30d5\u30a9\u30eb\u30c8: 1.5\uff09</li> <li><code>pub_route</code>: rosbag\u304b\u3089\u4f5c\u6210\u3055\u308c\u305f\u30eb\u30fc\u30c8\u3092\u30d1\u30d6\u30ea\u30c3\u30b7\u30e5\u3059\u308b\uff08GoalPose\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306b\u4f7f\u7528\uff09</li> </ul>"},{"location":"ja/use_case/perception_reproducer/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/perception_reproducer/#_4","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/perception_reproducer/#_5","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/performance_diag/","title":"LiDAR\u306e\u8a3a\u65ad\u6a5f\u80fd\u306e\u8a55\u4fa1","text":"<p>Autoware \u306e\u8a3a\u65ad\u6a5f\u80fd(diagnostics)\u304c\u610f\u56f3\u901a\u308a\u306b\u6a5f\u80fd\u3057\u3066\u3044\u308b\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <p>\u73fe\u5728\u306f\u3001lidar \u306e visibility \u3068 blockage \u306e\u8a55\u4fa1\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u308b\u3002</p> <ul> <li>visibility: \u9727\u3084\u96e8\u306a\u3069\u3067\u8996\u754c\u304c\u60aa\u304f\u306a\u3063\u3066\u3044\u306a\u3044\u304b\u3092\u5224\u5b9a\u3059\u308b\u6a5f\u80fd</li> <li>blockage: LiDAR \u306b\u8449\u3063\u3071\u306a\u3069\u304c\u4ed8\u7740\u3057\u3066\u8a08\u6e2c\u306e\u59a8\u3052\u3092\u3057\u3066\u3044\u306a\u3044\u304b\u3092\u5224\u5b9a\u3059\u308b\u6a5f\u80fd</li> </ul>"},{"location":"ja/use_case/performance_diag/#_1","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p>launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>performance_diag_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001/diagnostics \u3092\u51fa\u529b\u3059\u308b</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c/diagnostics \u3092 subscribe \u3057\u3066\u3001\u30b3\u30fc\u30eb\u30d0\u30c3\u30af\u3067\u8a55\u4fa1\u3092\u884c\u3044\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b\u3002</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/performance_diag/#visibility","title":"visibility \u8a55\u4fa1","text":"<p>visibility \u306e\u8a55\u4fa1\u3067\u306f\u3001\u96e8\u5929\u6642\u3084\u4eba\u5de5\u7684\u306b\u96e8\u3092\u964d\u3089\u305b\u3089\u308c\u308b\u65bd\u8a2d\u3067\u53d6\u5f97\u3057\u305f\u30c7\u30fc\u30bf\u3092\u7528\u3044\u3066 visibility \u306e ERROR \u304c\u4e00\u5b9a\u30ec\u30fc\u30c8\u4ee5\u4e0a\u51fa\u529b\u3055\u308c\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u3002 \u307e\u305f\u3001\u6674\u5929\u6642\u306e\u30c7\u30fc\u30bf\u3092\u5229\u7528\u3057\u3066\u3001ERROR \u304c\u4e00\u5ea6\u3082\u51fa\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u3002</p> <p><code>/diagnostics</code>\u306e<code>status.name</code>\u304c<code>polar_voxel_outlier_filter: /sensing/lidar/.*: visibility_validation</code>\u306b\u8a72\u5f53\u3059\u308b\u3082\u306e\u3092\u5224\u5b9a\u306b\u5229\u7528\u3059\u308b\u3002</p>"},{"location":"ja/use_case/performance_diag/#blockage","title":"blockage \u8a55\u4fa1","text":"<p>blockage \u306e\u8a55\u4fa1\u3067\u306f\u3001LiDAR \u3092\u610f\u56f3\u7684\u306b\u30ec\u30fc\u30b6\u30fc\u5149\u3092\u901a\u3055\u306a\u3044\u7d20\u6750(\u7bb1\u306a\u3069)\u3067\u8986\u3063\u305f\u72b6\u614b\u3067\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u3057 blockage \u306e ERROR \u304c\u4e00\u5b9a\u30ec\u30fc\u30c8\u4ee5\u4e0a\u51fa\u529b\u3055\u308c\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u3002 \u307e\u305f\u3001\u8986\u3063\u3066\u306a\u3044 LiDAR \u306b\u3064\u3044\u3066\u306f ERROR \u304c\u4e00\u5ea6\u3082\u51fa\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u3002</p> <p><code>/diagnostics</code>\u306e<code>status.name</code>\u304c<code>blockage_return_diag: /sensing/lidar/.*: blockage_validation</code>\u306b\u8a72\u5f53\u3059\u308b\u3082\u306e\u3092\u5224\u5b9a\u306b\u5229\u7528\u3059\u308b\u3002</p>"},{"location":"ja/use_case/performance_diag/#_2","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>LiDAR \u306e\u8a3a\u65ad\u7d50\u679c\u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <p>\u8a55\u4fa1\u3057\u305f\u3044\u5185\u5bb9\u306b\u3088\u3063\u3066 ERROR \u304c\u51fa\u308b\u5834\u5408\u3092\u6210\u529f\u3068\u3059\u308b\u304b\u5931\u6557\u3068\u3059\u308b\u304b\u304c\u5206\u304b\u308c\u308b\u306e\u3067\u3001\u30b7\u30ca\u30ea\u30aa\u306b\u30bf\u30a4\u30d7\u3092\u8a18\u8ff0\u3059\u308b\u3053\u3068\u3067\u5909\u66f4\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u3002</p> <ul> <li>\u30b7\u30ca\u30ea\u30aa\u7a2e\u985e\u304c TP \u306e\u5834\u5408\u306f Diag \u304c ERROR \u306b\u306a\u308c\u3070\u6210\u529f</li> <li>\u30b7\u30ca\u30ea\u30aa\u7a2e\u985e\u304c FP \u306e\u5834\u5408\u306f Diag \u304c ERROR \u306b\u306a\u3089\u306a\u3051\u308c\u3070\u6210\u529f</li> <li>\u30b7\u30ca\u30ea\u30aa\u7a2e\u985e\u304c null \u306e\u5834\u5408\u306f\u30c6\u30b9\u30c8\u3092\u7701\u7565\u3059\u308b</li> </ul>"},{"location":"ja/use_case/performance_diag/#tp","title":"TP \u6b63\u5e38","text":"<p>\u30b7\u30ca\u30ea\u30aa\u7a2e\u985e\u304c TP \u306e\u5834\u5408\u3067\u3001\u8a3a\u65ad\u60c5\u5831\u306e level \u304c ERROR(=2)\u306e\u5834\u5408</p>"},{"location":"ja/use_case/performance_diag/#tp_1","title":"TP \u7570\u5e38","text":"<p>\u30b7\u30ca\u30ea\u30aa\u7a2e\u985e\u304c TP \u306e\u5834\u5408\u3067\u3001\u8a3a\u65ad\u60c5\u5831\u306e level \u304c ERROR \u3067\u306a\u3044(!=2)\u306e\u5834\u5408</p>"},{"location":"ja/use_case/performance_diag/#fp","title":"FP \u6b63\u5e38","text":"<p>\u30b7\u30ca\u30ea\u30aa\u7a2e\u985e\u304c FP \u306e\u5834\u5408\u3067\u3001\u8a3a\u65ad\u60c5\u5831\u306e level \u304c ERROR \u3067\u306a\u3044(!=2)\u306e\u5834\u5408</p>"},{"location":"ja/use_case/performance_diag/#fp_1","title":"FP \u7570\u5e38","text":"<p>\u30b7\u30ca\u30ea\u30aa\u7a2e\u985e\u304c FP \u306e\u5834\u5408\u3067\u3001\u8a3a\u65ad\u60c5\u5831\u306e level \u304c ERROR(=2)\u306e\u5834\u5408</p>"},{"location":"ja/use_case/performance_diag/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /perception/obstacle_segmentation/pointcloud sensor_msgs/msg/PointCloud2 /diagnostics diagnostic_msgs/msg/DiagnosticArray /tf tf2_msgs/msg/TFMessage <p>Published topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /driving_log_replayer_v2/visibility/value example_interfaces/msg/Float64 /driving_log_replayer_v2/visibility/level example_interfaces/msg/Byte /driving_log_replayer_v2/blockage/{lidar_name}/ground/ratio example_interfaces/msg/Float64 /driving_log_replayer_v2/blockage/{lidar_name}/sky/ratio example_interfaces/msg/Float64 /driving_log_replayer_v2/blockage/{lidar_name}/level example_interfaces/msg/Byte <p>{lidar_name}\u306b\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b lidar \u306e\u540d\u524d\u304c\u5165\u308b\u3002</p>"},{"location":"ja/use_case/performance_diag/#service","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Service \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"service \u540d \u30c7\u30fc\u30bf\u578b /localization/initialize autoware_internal_localization_msgs/srv/InitializeLocalization"},{"location":"ja/use_case/performance_diag/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> </ul>"},{"location":"ja/use_case/performance_diag/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/performance_diag/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"<p>\u8eca\u4e21\u306e ECU \u306e CAN \u3068\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b sensor \u306e topic \u304c\u5fc5\u8981 \u4ee5\u4e0b\u306f\u4f8b\u3067\u3042\u308a\u3001\u9055\u3046\u30bb\u30f3\u30b5\u30fc\u3092\u4f7f\u3063\u3066\u3044\u308b\u5834\u5408\u306f\u9069\u5b9c\u8aad\u307f\u66ff\u3048\u308b\u3002</p> <p>LiDAR \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e LiDAR \u306e packets \u3092\u542b\u3081\u308b</p> topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>CAN \u306e\u4ee3\u308f\u308a\u306b vehicle \u306e topic \u3092\u542b\u3081\u3066\u3082\u826f\u3044\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport <p>\u6ce8:localization \u304c false(\u30c7\u30d5\u30a9\u30eb\u30c8\u3067 false)\u306e\u5834\u5408\u306f/tf \u304c\u4f7f\u7528\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/performance_diag/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/performance_diag/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/performance_diag/#_3","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/performance_diag/#_4","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>performance_diag \u3067\u306f\u3001visibility \u3068 blockage \u306e 2 \u3064\u3092\u8a55\u4fa1\u3057\u3066\u3044\u308b\u3002 Result \u306f visibility \u3068 blockage \u306e\u4e21\u65b9\u3092\u30d1\u30b9\u3057\u3066\u3044\u308c\u3070 true \u3067\u305d\u308c\u4ee5\u5916\u306f false \u5931\u6557\u3068\u306a\u308b\u3002</p> <p>\u4ee5\u4e0b\u306b\u3001\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u793a\u3059\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>visibility\u306e\u7d50\u679c(Frame \u306b Visibility \u306e\u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Visibility\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Invalid\" },\n    \"Info\": {\n      \"Level\": \"diag\u306e\u30ec\u30d9\u30eb\",\n      \"Visibility\": \"visibility\u306e\u5024\"\n    }\n  }\n}\n</code></pre> <p>blockage\u306e\u7d50\u679c(Frame \u306b Blockage \u306e\u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Blockage\": {\n    \"LiDAR1\u306e\u540d\u524d\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"Level\": \"diag\u306e\u30ec\u30d9\u30eb\",\n        \"GroundBlockageRatio\": \"\u5730\u4e0a\u5074\u306eblockage\u6bd4\u7387\",\n        \"GroundBlockageCount\": \"\u53c2\u8003\u5024\",\n        \"SkyBlockageRatio\": \"\u7a7a\u4e2d\u5074\u306eblockage\u6bd4\u7387\",\n        \"SkyBlockageCount\": \"\u53c2\u8003\u5024\"\n      }\n    },\n    \"LiDAR2\u306e\u540d\u524d\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"Level\": \"diag\u306e\u30ec\u30d9\u30eb\",\n        \"GroundBlockageRatio\": \"\u5730\u4e0a\u5074\u306eblockage\u6bd4\u7387\",\n        \"GroundBlockageCount\": \"\u53c2\u8003\u5024\",\n        \"SkyBlockageRatio\": \"\u7a7a\u4e2d\u5074\u306eblockage\u6bd4\u7387\",\n        \"SkyBlockageCount\": \"\u53c2\u8003\u5024\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"ja/use_case/planning_control/","title":"Planning Control\u306e\u8a55\u4fa1","text":"<p>Metrics\u3001PlanningFactors\u304c\u6307\u5b9a\u306e\u6761\u4ef6\u3067\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u8a55\u4fa1\u3059\u308b\u3002 include_use_case\u3067diagnostics\u3092\u6307\u5b9a\u3059\u308c\u3070\u3001diagnostics\u306e\u8a55\u4fa1\u3082\u53ef\u80fd\u3002</p>"},{"location":"ja/use_case/planning_control/#_1","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p>launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>planning_control_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001metrics\u578b\u3001PlanningFactor\u578b\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u51fa\u529b\u3059\u308b</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c topic \u3092 subscribe \u3057\u3066\u3001\u5404\u57fa\u6e96\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3057\u3066\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/planning_control/#_2","title":"\u8a55\u4fa1\u7d50\u679c","text":""},{"location":"ja/use_case/planning_control/#metric","title":"Metric","text":"<p>Metric.msg\u304c\u5229\u7528\u3055\u308c\u3066\u3044\u308btopic\u3092\u5229\u7528\u3059\u308b\u3002 \u4e3b\u306b\u3001<code>/control/control_evaluator/metrics</code>, <code>/planning/planning_evaluator/metrics</code>, <code>/system/processing_time/metrics</code>\u3092\u60f3\u5b9a\u3057\u3066\u3044\u308b\u3002 \u8a55\u4fa1\u5bfe\u8c61\u3068\u306a\u308btopic\u5185\u306e<code>name</code>\u306f<code>metric_name</code>\u306b\u3066\u6307\u5b9a\u3059\u308b\u3002 \u4ee5\u4e0b\u6761\u4ef6\u3092\u8a55\u4fa1\u3067\u304d\u308b\u3002</p> <ul> <li>\u6307\u5b9a\u30e1\u30c8\u30ea\u30af\u30b9\u304c\u30b7\u30ca\u30ea\u30aa\u6307\u5b9a\u306e\u7bc4\u56f2\u5185\u304b</li> <li>\u6307\u5b9a\u30e1\u30c8\u30ea\u30af\u30b9\u304c\u30b7\u30ca\u30ea\u30aa\u6307\u5b9a\u306e\u5024\u3068\u306a\u308b\u304b</li> </ul>"},{"location":"ja/use_case/planning_control/#metricjudgement-positive","title":"Metric\u6b63\u5e38(judgement: positive)","text":"<p><code>value_type=number</code>\u306e\u5834\u5408\u306b\u3001\u30e1\u30c8\u30ea\u30af\u30b9Topic\u4e2d\u306e\u6307\u5b9ametric\u304c<code>value_range</code>\u306e\u7bc4\u56f2\u306b\u5165\u3063\u3066\u308b\u3068\u6b63\u5e38\u3068\u306a\u308b\u3002 <code>value_type=string</code>\u306e\u5834\u5408\u306b\u3001\u30e1\u30c8\u30ea\u30af\u30b9Topic\u4e2d\u306e\u6307\u5b9ametric\u304c<code>value_target</code>\u3068\u4e00\u81f4\u3059\u308b\u3068\u6b63\u5e38\u3068\u306a\u308b\u3002</p>"},{"location":"ja/use_case/planning_control/#metricjudgement-negative","title":"Metric\u6b63\u5e38(judgement: negative)","text":"<p><code>value_type=number</code>\u306e\u5834\u5408\u306b\u3001\u30e1\u30c8\u30ea\u30af\u30b9Topic\u4e2d\u306e\u6307\u5b9ametric\u304c<code>value_range</code>\u306e\u7bc4\u56f2\u5916\u3067\u3042\u308b\u3068\u6b63\u5e38\u3068\u306a\u308b\u3002 <code>value_type=string</code>\u306e\u5834\u5408\u306b\u3001\u30e1\u30c8\u30ea\u30af\u30b9Topic\u4e2d\u306e\u6307\u5b9ametric\u304c<code>value_target</code>\u3068\u4e00\u81f4\u3057\u306a\u3044\u3068\u6b63\u5e38\u3068\u306a\u308b\u3002</p>"},{"location":"ja/use_case/planning_control/#metric_1","title":"Metric\u6b63\u5e38\u7570\u5e38","text":"<p>Metric\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u3068\u304d</p>"},{"location":"ja/use_case/planning_control/#planningfactor","title":"PlanningFactor","text":"<p><code>/planning/planning_factors/**</code>\u306etopic\u3092\u5229\u7528\u3059\u308b\u3002\u8a55\u4fa1\u5bfe\u8c61\u306etopic\u306f\u30b7\u30ca\u30ea\u30aa\u30d5\u30a1\u30a4\u30eb\u3067topic\u540d\u3092\u6307\u5b9a\u3059\u308b\u3002 \u4ee5\u4e0b\u306e\u6761\u4ef6\u3092\u8a55\u4fa1\u3067\u304d\u308b\u3002</p> <ul> <li>PlanningFactor\u306econtrol_point\u306e\u4f4d\u7f6e\u304c\u30b7\u30ca\u30ea\u30aa\u306b\u6307\u5b9a\u3055\u308c\u305f\u6761\u4ef6\u3092\u6e80\u305f\u3059\u304b</li> <li>PlanningFactor\u306ebehavior\u304c\u6307\u5b9a\u306ebehavior\u306b\u306a\u3063\u3066\u308b\u304b</li> </ul>"},{"location":"ja/use_case/planning_control/#planningfactorjudgement-positive","title":"PlanningFactor\u6b63\u5e38(judgement: positive)","text":"<p><code>/planning/planning_factors/**</code>\u304c\u4ee5\u4e0b\u306e\u6761\u4ef6\u3092\u5168\u90e8\u6e80\u305f\u3059\u5834\u5408\u306b\u6b63\u5e38\u3068\u306a\u308b\u3002</p> <ul> <li>\u30b7\u30ca\u30ea\u30aa\u306barea\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001control_points[0].pose\u306ex,y\u306e\u4f4d\u7f6e\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305fx,y\u5ea7\u6a19\u304b\u3089range\u306e\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> <li>\u30b7\u30ca\u30ea\u30aa\u306bbehavior\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001planning_factor\u306ebehavior\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305fbehavior\u306b\u3042\u308b\u3002</li> <li>\u30b7\u30ca\u30ea\u30aa\u306bdistance\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001planning_factor\u306edistance(Ego\u304b\u3089control_point\u307e\u3067\u306e\u8ddd\u96e2)\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> <li>\u30b7\u30ca\u30ea\u30aa\u306bvelocity\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001planning_factor\u306evelocity(control_point\u3067\u306e\u901f\u5ea6)\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> <li>\u30b7\u30ca\u30ea\u30aa\u306btime_to_wall\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001planning_factor\u306etime_to_wall(\u73fe\u5728\u306e\u901f\u5ea6\u3067control_point\u306b\u5230\u9054\u3059\u308b\u307e\u3067\u306e\u6642\u9593)\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> <li>\u30b7\u30ca\u30ea\u30aa\u306bacceleration_to_wall\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001planning_factor\u306eacceleration_to_wall(\u73fe\u5728\u306e\u901f\u5ea6\u3067control_point\u306b\u5230\u9054\u3059\u308b\u305f\u3081\u306b\u5fc5\u8981\u306a\u52a0\u901f\u5ea6)\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> </ul>"},{"location":"ja/use_case/planning_control/#planningfactorjudgement-negative","title":"PlanningFactor\u6b63\u5e38(judgement: negative)","text":"<p><code>/planning/planning_factors/**</code>\u304c\u4ee5\u4e0b\u306e\u4efb\u610f\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408\u306b\u6b63\u5e38\u3068\u306a\u308b\u3002</p> <ul> <li>\u30b7\u30ca\u30ea\u30aa\u306barea\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001control_points[0].pose\u306ex,y\u306e\u4f4d\u7f6e\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305fx,y\u5ea7\u6a19\u304b\u3089range\u306e\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> <li>\u30b7\u30ca\u30ea\u30aa\u306bbehavior\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001planning_factor\u306ebehavior\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305fbehavior\u306b\u3042\u308b\u3002</li> <li>\u30b7\u30ca\u30ea\u30aa\u306bdistance\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001planning_factor\u306edistance(Ego\u304b\u3089control_point\u307e\u3067\u306e\u8ddd\u96e2)\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> <li>\u30b7\u30ca\u30ea\u30aa\u306bvelocity\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001planning_factor\u306evelocity(control_point\u3067\u306e\u901f\u5ea6)\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> <li>\u30b7\u30ca\u30ea\u30aa\u306btime_to_wall\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001planning_factor\u306etime_to_wall(\u73fe\u5728\u306e\u901f\u5ea6\u3067control_point\u306b\u5230\u9054\u3059\u308b\u307e\u3067\u306e\u6642\u9593)\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> <li>\u30b7\u30ca\u30ea\u30aa\u306bacceleration_to_wall\u6761\u4ef6\u304c\u3042\u308b\u5834\u5408\u3001planning_factor\u306eacceleration_to_wall(\u73fe\u5728\u306e\u901f\u5ea6\u3067control_point\u306b\u5230\u9054\u3059\u308b\u305f\u3081\u306b\u5fc5\u8981\u306a\u52a0\u901f\u5ea6)\u304c\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u7bc4\u56f2\u306b\u5165\u3063\u3066\u3044\u308b\u3002</li> </ul>"},{"location":"ja/use_case/planning_control/#planningfactor_1","title":"PlanningFactor\u7570\u5e38","text":"<p>PlanningFactor\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u3068\u304d</p>"},{"location":"ja/use_case/planning_control/#_3","title":"\u8a55\u4fa1\u7d50\u679c\u306e\u51fa\u529b\u5148\u30d5\u30a1\u30a4\u30eb","text":"<p>planning_control\u306b\u304a\u3044\u3066\u306f\u3001\u4ee5\u4e0b\u306e3\u3064\u306e\u30d5\u30a1\u30a4\u30eb\u306b\u305d\u308c\u305e\u308cresult.jsonl\u304c\u4f5c\u6210\u3055\u308c\u308b\u3002 result.jsonl\u306f\u5fc5\u305a\u51fa\u529b\u3055\u308c\u308b\u304c\u3001planning_factor_result.jsonl\u3068metric_result.jsonl\u3068diag_result.jsonl\u306f\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u5834\u5408\u306b\u306e\u307f\u51fa\u529b\u3055\u308c\u308b</p>"},{"location":"ja/use_case/planning_control/#resultjsonl","title":"result.jsonl","text":"<p>output_dir/result.jsonl\u306b\u51fa\u529b\u3055\u308c\u308b\u3002 planning_factor\u3068metric\u3068diag\u8a55\u4fa1\u304b\u3089\u307e\u3068\u3081\u3055\u308c\u305f\u8a55\u4fa1\u7d50\u679c\u304c\u8a18\u8ff0\u3055\u308c\u308b\u3002</p> <p>Evaluator\u3067\u5b9f\u884c\u3059\u308b\u5834\u5408\u306f\u3001\u3053\u306e\u30d5\u30a1\u30a4\u30eb\u306e\u6700\u7d42\u884c\u304c\u53c2\u7167\u3055\u308c\u3066\u6210\u5426\u304c\u6c7a\u5b9a\u3055\u308c\u308b\u3002 \u3053\u306e\u305f\u3081\u3001planning_factor_result.jsonl\u3068metric_result.jsonl\u3068diag_result.jsonl\u306e\u7d50\u679c\u3092\u30de\u30fc\u30b8\u3057\u305f\u6700\u7d42\u7684\u306a\u6210\u5426\u306e\u60c5\u5831\u304cpost_process\u3067\u66f8\u304d\u8fbc\u307e\u308c\u308b\u3002</p>"},{"location":"ja/use_case/planning_control/#planning_factor_resultjsonl","title":"planning_factor_result.jsonl","text":"<p>output_dir/result_archive/planning_factor_result.jsonl\u306b\u51fa\u529b\u3055\u308c\u308b\u3002 planning_factor\u306e\u8a55\u4fa1\u7d50\u679c\u304c\u8a18\u8ff0\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/planning_control/#metric_resultjsonl","title":"metric_result.jsonl","text":"<p>output_dir/result_archive/metric_result.jsonl\u306b\u51fa\u529b\u3055\u308c\u308b\u3002 metrics\u306e\u8a55\u4fa1\u7d50\u679c\u304c\u8a18\u8ff0\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/planning_control/#diag_resultjsonl","title":"diag_result.jsonl","text":"<p>output_dir/result_archive/diag_result.jsonl\u306b\u51fa\u529b\u3055\u308c\u308b\u3002 diagnostics\u306e\u8a55\u4fa1\u7d50\u679c\u304c\u8a18\u8ff0\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/planning_control/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> Topic name Data type /control/control_evaluator/metrics tier4_metric_msg/msg/MetricArray /planning/planning_evaluator/metrics tier4_metric_msg/msg/MetricArray /system/processing_time/metrics tier4_metric_msg/msg/MetricArray /planning/planning_factors/** autoware_internal_planning_msgs/msg/PlanningFactorArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"ja/use_case/planning_control/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/planning_control/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/planning_control/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/planning_control/#_4","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167\u3000#TODO</p>"},{"location":"ja/use_case/planning_control/#_5","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":""},{"location":"ja/use_case/planning_control/#metric_2","title":"metric","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167\u3000#TODO</p>"},{"location":"ja/use_case/planning_control/#planning_factor","title":"planning_factor","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167 #TODO</p>"},{"location":"ja/use_case/planning_control/#diagnostics","title":"diagnostics","text":"<p>diagnostics\u306e\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3068\u540c\u3058</p>"},{"location":"ja/use_case/time_step_based_trajectory/","title":"\u30bf\u30a4\u30e0\u30b9\u30c6\u30c3\u30d7\u30d9\u30fc\u30b9\u306e\u8ecc\u8de1\u306e\u8a55\u4fa1","text":"<p>Autoware \u304b\u3089\u51fa\u529b\u3055\u308c\u308b\u81ea\u8eca\u306e\u8ecc\u8de1\u306b\u3064\u3044\u3066\u306e\u8a55\u4fa1\u3092\u884c\u3046\u3002\u73fe\u72b6\u3001\u4f55\u304b\u3057\u3089\u306e\u57fa\u6e96\u306b\u5bfe\u3059\u308b\u8a55\u4fa1\u306f\u884c\u308f\u306a\u3044(TBD)\u3002\u5f8c\u51e6\u7406\u306b\u304a\u3044\u3066 <code>autoware_tools</code> \u306e <code>autoware_planning_data_analyzer</code> \u3092\u901a\u3058\u3066\u5206\u6790\u306e\u307f\u3092\u884c\u3046\u3002</p>"},{"location":"ja/use_case/time_step_based_trajectory/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<ul> <li>perception: false</li> <li>localization: false</li> <li>control: false</li> </ul>"},{"location":"ja/use_case/time_step_based_trajectory/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/time_step_based_trajectory/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/time_step_based_trajectory/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/time_step_based_trajectory/#_2","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/time_step_based_trajectory/#_3","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u306e\u5185\u5bb9\u306f\u5e38\u306b\u540c\u3058\u3002</p> <p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/traffic_light/","title":"\u4fe1\u53f7\u6a5f\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1","text":"<p>Autoware \u306e\u8a8d\u8b58\u6a5f\u80fd(perception)\u306e\u8a8d\u8b58\u7d50\u679c\u304b\u3089 mAP(mean Average Precision)\u306a\u3069\u306e\u6307\u6a19\u3092\u8a08\u7b97\u3057\u3066\u6027\u80fd\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <p>perception \u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8d77\u52d5\u3057\u3066\u51fa\u529b\u3055\u308c\u308b perception \u306e topic \u3092\u8a55\u4fa1\u7528\u30e9\u30a4\u30d6\u30e9\u30ea\u306b\u6e21\u3057\u3066\u8a55\u4fa1\u3092\u884c\u3046\u3002</p> <p>\u73fe\u72b6\u3001<code>classification2d</code> \u306e\u8a55\u4fa1\u306e\u307f\u3002</p>"},{"location":"ja/use_case/traffic_light/#_2","title":"\u4e8b\u524d\u6e96\u5099","text":"<p>perception \u3067\u306f\u3001\u6a5f\u68b0\u5b66\u7fd2\u306e\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3059\u308b\u3002 \u30e2\u30c7\u30eb\u3092\u4e8b\u524d\u306b\u6e96\u5099\u3057\u3066\u3044\u306a\u3044\u3068Autoware\u304b\u3089\u8a8d\u8b58\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u306a\u3044\u3002 \u4f55\u3082\u8a55\u4fa1\u7d50\u679c\u304c\u51fa\u3066\u3053\u306a\u3044\u5834\u5408\u306f\u3001\u3053\u306e\u4f5c\u696d\u304c\u6b63\u3057\u304f\u51fa\u6765\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#_3","title":"\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u30e2\u30c7\u30eb\u306fAutoware\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u6642\u306b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u308b\u3002 \u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u65b9\u6cd5\u306f\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b\u306bAutoware\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u3088\u3063\u3066\u7570\u306a\u308b\u306e\u3067\u3069\u3061\u3089\u306e\u624b\u6cd5\u304c\u4f7f\u308f\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002 \u4ee5\u4e0b\u306e\u30d1\u30bf\u30fc\u30f3\u304c\u5b58\u5728\u3059\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#ansible","title":"ansible\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u30b9\u30af\u30ea\u30d7\u30c8\u5b9f\u884c\u6642\u306b<code>Download artifacts? [y/N]</code>\u3068\u51fa\u3066\u304f\u308b\u306e\u3067<code>y</code>\u3092\u5165\u529b\u3057\u3066\u30a8\u30f3\u30bf\u30fc\u3092\u62bc\u3059(Autoware foundation\u306emain\u3060\u3068\u3053\u3061\u3089) https://github.com/autowarefoundation/autoware/blob/main/ansible/roles/artifacts/tasks/main.yaml</p>"},{"location":"ja/use_case/traffic_light/#_4","title":"\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d3\u30eb\u30c9\u6642\u306b\u81ea\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u5c11\u3057\u53e4\u3044Autoware.universe\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u3053\u3061\u3089\u3001<code>13b96ad3c636389b32fea3a47dfb7cfb7813cadc</code>\u306e\u30b3\u30df\u30c3\u30c8\u30cf\u30c3\u30b7\u30e5\u307e\u3067\u306f\u3053\u3061\u3089\u304c\u4f7f\u7528\u3055\u308c\u308b\u3002 traffic_light_classifier/CMakeList.txt</p>"},{"location":"ja/use_case/traffic_light/#_5","title":"\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u5909\u63db","text":"<p>\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f onnx \u30d5\u30a1\u30a4\u30eb\u306f\u305d\u306e\u307e\u307e\u4f7f\u7528\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001TensorRT \u306e engine \u30d5\u30a1\u30a4\u30eb\u306b\u5909\u63db\u3057\u3066\u5229\u7528\u3059\u308b\u3002 \u5909\u63db\u7528\u306e\u30b3\u30de\u30f3\u30c9\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001autoware \u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092 source \u3057\u3066\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3002</p> <p><code>$HOME/autoware</code>\u306bautoware\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u3068\u3057\u3066\u8aac\u660e\u3059\u308b\u3002</p> <pre><code>source $HOME/autoware/install/setup.bash\nros2 launch traffic_light_classifier traffic_light_classifier.launch.xml use_gpu:=true  build_only:=true\nros2 launch traffic_light_fine_detector traffic_light_fine_detector.launch.xml build_only:=true\n</code></pre> <p>\u5909\u63db\u30b3\u30de\u30f3\u30c9\u304c\u7d42\u4e86\u3059\u308b\u3068\u3001engine \u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u3002 \u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u65b9\u6cd5\u306b\u5408\u308f\u305b\u3066\u51fa\u529b\u5148\u304c\u5909\u308f\u308b\u306e\u3067\u3001\u9069\u5207\u306a\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#ansible_1","title":"ansible\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <pre><code>$HOME/autoware_data/traffic_light_classifier/traffic_light_classifier_mobilenetv2_batch_6.fp16-batch6.engine\n$HOME/autoware_data/traffic_light_fine_detector/tlr_yolox_s_batch_6.fp16-batch6.engine\n</code></pre>"},{"location":"ja/use_case/traffic_light/#_6","title":"\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d3\u30eb\u30c9\u6642\u306b\u81ea\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b</p> <pre><code>$HOME/autoware/install/traffic_light_classifier/share/traffic_light_classifier/data/traffic_light_classifier_mobilenetv2_batch_6.fp16-batch6.engine\n$HOME/autoware/install/traffic_light_fine_detector/share/traffic_light_fine_detector/data/tlr_yolox_s_batch_6.fp16-batch6.engine\n</code></pre>"},{"location":"ja/use_case/traffic_light/#pc1launch","title":"(PC1\u53f0\u3067\u8a55\u4fa1\u3059\u308b\u5834\u5408)launch\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u66f8\u304d\u63db\u3048","text":"<p>autoware.universe/launch/tier4_perception_launch/launch/perception.launch.xml \u306e traffic_light_recognition/fusion_only \u3092 <code>false</code>\u306b\u3059\u308b\u3002 https://github.com/autowarefoundation/autoware.universe/blob/main/launch/tier4_perception_launch/launch/perception.launch.xml#L79</p> <p>Autoware Foundation\u306emain\u3067\u306f\u3001<code>false</code>\u306b\u306a\u3063\u3066\u3044\u308b\u304c\u3001\u5b9f\u8eca\u4e21\u3067\u5229\u7528\u3057\u3066\u3044\u308bAutoware\u306e\u5834\u5408\u306f\u3001<code>true</code>\u306b\u306a\u3063\u3066\u3044\u3053\u3068\u304c\u3042\u308b\u3002 <code>true</code>\u306f\u3001\u5225\u306e\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u304b\u3089\u3001\u8a8d\u8b58\u7d50\u679c\u304c\u9001\u3089\u308c\u3066\u304f\u308b\u3068\u3044\u3046\u8a2d\u5b9a\u3067\u3042\u308b\u305f\u3081\u3001PC1\u53f0\u3067\u8a55\u4fa1\u3059\u308b\u5834\u5408\u306b\u306f<code>false</code>\u306b\u623b\u3057\u3066\u304b\u3089\u5b9f\u884c\u3059\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#_7","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p>launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>traffic_light_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001\u30ab\u30e1\u30e9\u30c7\u30fc\u30bf\u3092\u51fa\u529b\u3057\u3001perception \u30e2\u30b8\u30e5\u30fc\u30eb\u304c\u8a8d\u8b58\u3092\u884c\u3046</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c/perception/traffic_light_recognition/traffic_signals \u3092 subscribe \u3057\u3066\u3001\u30b3\u30fc\u30eb\u30d0\u30c3\u30af\u3067 perception_eval \u306e\u95a2\u6570\u3092\u7528\u3044\u3066\u8a55\u4fa1\u3057\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/traffic_light/#_8","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#_9","title":"\u6b63\u5e38","text":"<p>perception_eval \u306e\u8a55\u4fa1\u95a2\u6570\u3092\u5b9f\u884c\u3057\u3066\u4ee5\u4e0b\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3059\u3068\u304d</p> <ol> <li>frame_result.pass_fail_result \u306b object \u304c\u6700\u4f4e 1 \u3064\u5165\u3063\u3066\u3044\u308b (<code>tp_object_results != [] and fp_object_results != [] and fn_objects != []</code>)</li> <li>\u8a55\u4fa1\u5931\u6557\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304c 0 \u500b (<code>frame_result.pass_fail_result.get_fail_object_num() == 0</code>)</li> </ol>"},{"location":"ja/use_case/traffic_light/#_10","title":"\u7570\u5e38","text":"<p>\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/traffic_light/#_11","title":"\u8a55\u4fa1\u30b9\u30ad\u30c3\u30d7","text":"<p>\u4ee5\u4e0b\u306e\u5834\u5408\u306b\u3001\u8a55\u4fa1\u3092\u305b\u305a\u306b\u8a55\u4fa1\u304c\u98db\u3070\u3055\u308c\u305f\u56de\u6570\u306e\u30ab\u30a6\u30f3\u30c8(FrameSkip)\u30921\u8db3\u3059\u51e6\u7406\u306e\u307f\u884c\u3046</p> <ul> <li>\u53d7\u4fe1\u3057\u305fobject\u306e\u30d8\u30c3\u30c0\u30fc\u6642\u523b\u306e\u524d\u5f8c75msec\u4ee5\u5185\u306b\u771f\u5024\u304c\u5b58\u5728\u3057\u306a\u3044\u5834\u5408</li> </ul>"},{"location":"ja/use_case/traffic_light/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /perception/traffic_light_recognition/traffic_signals tier4_perception_msgs/msg/TrafficSignalArray <p>Published topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b - -"},{"location":"ja/use_case/traffic_light/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> </ul> <p>\u6ce8:\u30a2\u30ce\u30fc\u30c6\u30b7\u30e7\u30f3\u6642\u3068\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u6642\u3067\u81ea\u5df1\u4f4d\u7f6e\u3092\u5408\u308f\u305b\u305f\u3044\u306e\u3067 bag \u306b\u5165\u3063\u3066\u3044\u308b tf \u3092\u4f7f\u3044\u56de\u3059\u3002\u305d\u306e\u305f\u3081 localization \u306f\u7121\u52b9\u3067\u3042\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#_12","title":"\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea","text":"<p>\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1\u306fperception_eval\u306b\u4f9d\u5b58\u3057\u3066\u3044\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#driving_log_replayer_v2","title":"\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u306e driving_log_replayer_v2 \u306e\u5f79\u5272\u5206\u62c5","text":"<p>driving_log_replayer_v2 \u304c ROS \u3068\u306e\u63a5\u7d9a\u90e8\u5206\u3092\u62c5\u5f53\u3057\u3001perception_eval \u304c\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f7f\u3063\u3066\u5b9f\u969b\u306b\u8a55\u4fa1\u3059\u308b\u90e8\u5206\u3092\u62c5\u5f53\u3059\u308b\u3068\u3044\u3046\u5206\u62c5\u306b\u306a\u3063\u3066\u3044\u308b\u3002 perception_eval \u306f ROS \u975e\u4f9d\u5b58\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306a\u306e\u3067\u3001ROS \u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u53d7\u3051\u53d6\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u3044\u3002 \u307e\u305f\u3001timestamp \u304c ROS \u3067\u306f\u30ca\u30ce\u79d2\u3001t4_dataset \u306f <code>nuScenes</code> \u3092\u30d9\u30fc\u30b9\u3057\u3066\u3044\u308b\u305f\u3081\u30df\u30ea\u79d2\u304c\u63a1\u7528\u3055\u308c\u3066\u3044\u308b\u3002 \u3053\u306e\u305f\u3081\u3001\u30e9\u30a4\u30d6\u30e9\u30ea\u4f7f\u7528\u524d\u306b\u9069\u5207\u306a\u5909\u63db\u304c\u5fc5\u8981\u3068\u306a\u308b\u3002</p> <p>driving_log_replayer_v2 \u306f\u3001autoware \u306e perception \u30e2\u30b8\u30e5\u30fc\u30eb\u304b\u3089\u51fa\u529b\u3055\u308c\u305f topic \u3092 subscribe \u3057\u3001perception_eval \u3067\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b class \u306b\u5408\u308f\u305b\u305f\u30c7\u30fc\u30bf\u5f62\u5f0f\u306b\u5909\u63db\u3057\u3066\u6e21\u3059\u3002 \u307e\u305f\u3001perception_eval \u304b\u3089\u8fd4\u3063\u3066\u304f\u308b\u8a55\u4fa1\u7d50\u679c\u306e ROS \u306e topic \u3067 publish \u3057\u53ef\u8996\u5316\u3059\u308b\u90e8\u5206\u3082\u62c5\u5f53\u3059\u308b\u3002</p> <p>perception_eval \u306f\u3001driving_log_replayer_v2 \u304b\u3089\u6e21\u3055\u308c\u305f\u691c\u77e5\u7d50\u679c\u3068 GroundTruth \u3092\u6bd4\u8f03\u3057\u3066\u6307\u6a19\u3092\u8a08\u7b97\u3057\u3001\u7d50\u679c\u3092\u51fa\u529b\u3059\u308b\u90e8\u5206\u3092\u62c5\u5f53\u3059\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"<p>t4_dataset \u3067\u5fc5\u8981\u306a\u30c8\u30d4\u30c3\u30af\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u3053\u3068</p> <p>\u8eca\u4e21\u306e ECU \u306e CAN \u3068\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b sensor \u306e topic \u304c\u5fc5\u8981 \u4ee5\u4e0b\u306f\u4f8b\u3067\u3042\u308a\u3001\u9055\u3046\u30bb\u30f3\u30b5\u30fc\u3092\u4f7f\u3063\u3066\u3044\u308b\u5834\u5408\u306f\u9069\u5b9c\u8aad\u307f\u66ff\u3048\u308b\u3002</p> <p>LiDAR \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e LiDAR \u306e packets \u3092\u542b\u3081\u308b\u3002 /sensing/lidar/concatenated/pointcloud\u306flaunch\u306eargument\u306bsensing:=false\u3092\u8ffd\u52a0\u3057\u305f\u5834\u5408\u306b\u5229\u7528\u3055\u308c\u308b\u3002</p> <p>CAMERA \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e camera_info \u3068 image_rect_color_compressed \u3092\u542b\u3081\u308b</p> topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>CAN \u306e\u4ee3\u308f\u308a\u306b vehicle \u306e topic \u3092\u542b\u3081\u3066\u3082\u826f\u3044\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/traffic_light/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/traffic_light/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#_13","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u8a55\u4fa1\u3068\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e 2 \u7a2e\u985e\u306e\u8a55\u4fa1\u304c\u3042\u308b\u3002 \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306f 1 \u500b\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u884c\u3046\u8a55\u4fa1\u3067\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306f\u8907\u6570\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7528\u3044\u3066\u3001\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6bce\u306e\u7d50\u679c\u306e\u5e73\u5747\u3092\u53d6\u308b\u8a55\u4fa1\u3067\u3042\u308b\u3002</p> <p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u5024\u306e\u5909\u66f4\u304c\u3042\u308a\u5f97\u308b\u306e\u3067 vehicle_id \u3092\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6bce\u306b\u8a2d\u5b9a\u51fa\u6765\u308b\u3088\u3046\u306b\u3059\u308b\u3002 \u307e\u305f\u3001Sensing \u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8d77\u52d5\u3059\u308b\u304b\u3069\u3046\u304b\u306e\u8a2d\u5b9a\u3082\u884c\u3046\u3002</p> <p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/traffic_light/#_14","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>perception \u3067\u306f\u3001\u30b7\u30ca\u30ea\u30aa\u306b\u6307\u5b9a\u3057\u305f\u6761\u4ef6\u3067 perception_eval \u304c\u8a55\u4fa1\u3057\u305f\u7d50\u679c\u3092\u5404 frame \u6bce\u306b\u51fa\u529b\u3059\u308b\u3002 \u5168\u3066\u306e\u30c7\u30fc\u30bf\u3092\u6d41\u3057\u7d42\u308f\u3063\u305f\u3042\u3068\u306b\u3001\u6700\u7d42\u7684\u306a\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u8a08\u7b97\u3057\u3066\u3044\u308b\u305f\u3081\u3001\u6700\u7d42\u884c\u3060\u3051\u3001\u4ed6\u306e\u884c\u3068\u5f62\u5f0f\u304c\u7570\u306a\u308b\u3002</p> <p>\u4ee5\u4e0b\u306b\u3001\u5404\u30d5\u30ec\u30fc\u30e0\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3068\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u793a\u3059\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>\u5404\u30d5\u30ec\u30fc\u30e0\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <pre><code>{\n  \"Frame\": {\n    \"FrameName\": \"\u8a55\u4fa1\u306b\u4f7f\u7528\u3057\u305ft4_dataset\u306e\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\",\n    \"FrameSkip\": \"object\u306e\u8a55\u4fa1\u3092\u4f9d\u983c\u3057\u305f\u304cdataset\u306b75msec\u4ee5\u5185\u306e\u771f\u5024\u304c\u306a\u304f\u8a55\u4fa1\u3092\u98db\u3070\u3055\u308c\u305f\u56de\u6570\",\n    \"PassFail\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"TP\": \"TP\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\",\n        \"FP\": \"FP\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\",\n        \"FN\": \"FN\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\"\n      }\n    }\n  }\n}\n</code></pre> <p>\u30e1\u30c8\u30ea\u30af\u30b9\u30c7\u30fc\u30bf\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"Score\": {\n        \"TP\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eTP\u7387\",\n          \"label0\": \"label0\u306eTP\u7387\",\n          \"label1\": \"label1\u306eTP\u7387\"\n        },\n        \"FP\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eFP\u7387\",\n          \"label0\": \"label0\u306eFP\u7387\",\n          \"label1\": \"label1\u306eFP\u7387\"\n        },\n        \"FN\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eFN\u7387\",\n          \"label0\": \"label0\u306eFN\u7387\",\n          \"label1\": \"label1\u306eFN\u7387\"\n        },\n        \"TN\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eTN\u7387\",\n          \"label0\": \"label0\u306eTN\u7387\",\n          \"label1\": \"label1\u306eTN\u7387\"\n        },\n        \"Accuracy\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAccuracy\",\n          \"label0\": \"label0\u306eAccuracy\",\n          \"label1\": \"label1\u306eAccuracy\"\n        },\n        \"Precision\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306ePrecision\",\n          \"label0\": \"label0\u306ePrecision\",\n          \"label1\": \"label1\u306ePrecision\"\n        },\n        \"Recall\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eRecall\",\n          \"label0\": \"label0\u306eRecall\",\n          \"label1\": \"label1\u306eRecall\"\n        },\n        \"F1score\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eF1score\",\n          \"label0\": \"label0\u306eF1score\",\n          \"label1\": \"label1\u306eF1score\"\n        }\n      },\n      \"ConfusionMatrix\": {\n        \"label0(\u771f\u5024)\": {\n          \"label0(\u4e88\u6e2c\u5024)\": \"\u5024\",\n          \"label1(\u4e88\u6e2c\u5024)\": \"\u5024\"\n        },\n        \"label1(\u771f\u5024)\": {\n          \"label0(\u4e88\u6e2c\u5024)\": \"\u5024\",\n          \"label1(\u4e88\u6e2c\u5024)\": \"\u5024\"\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"ja/use_case/traffic_light/#pickle","title":"pickle \u30d5\u30a1\u30a4\u30eb","text":"<p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u8907\u6570\u306e bag \u3092\u518d\u751f\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u304c\u3001ROS \u306e\u4ed5\u69d8\u4e0a\u30011 \u56de\u306e launch \u3067\u3001\u8907\u6570\u306e bag \u3092\u5229\u7528\u3059\u308b\u3053\u3068\u306f\u51fa\u6765\u306a\u3044\u3002 1 \u3064\u306e bag\u3001\u3059\u306a\u308f\u3061 1 \u3064\u306e t4_dataset \u306b\u5bfe\u3057\u3066 launch \u3092 1 \u56de\u53e9\u304f\u3053\u3068\u306a\u308b\u306e\u3067\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u542b\u307e\u308c\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u6570\u3060\u3051 launch \u3092\u5b9f\u884c\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002</p> <p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306f 1 \u56de\u306e launch \u3067\u8a55\u4fa1\u3067\u304d\u306a\u3044\u305f\u3081\u3001perception \u3067\u306f\u3001result.jsonl \u306e\u4ed6\u306b scene_result.pkl \u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u3092\u51fa\u529b\u3059\u308b\u3002 pickle \u30d5\u30a1\u30a4\u30eb\u306f python \u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u4fdd\u5b58\u3057\u305f\u3082\u306e\u3067\u3042\u308a\u3001perception_eval \u306e PerceptionEvaluationManager.frame_results \u3092\u4fdd\u5b58\u3057\u3066\u3044\u308b\u3002 pickle \u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3057\u305f object \u3092\u3059\u3079\u3066\u8aad\u307f\u8fbc\u307f\u3001dataset \u306e\u5e73\u5747\u306e\u6307\u6a19\u3092\u51fa\u529b\u3059\u308b\u3053\u3068\u3067\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u8a55\u4fa1\u304c\u884c\u3048\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#_15","title":"\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e\u7d50\u679c\u30d5\u30a1\u30a4\u30eb","text":"<p>\u30b7\u30ca\u30ea\u30aa\u306b\u8907\u6570\u306e dataset \u3092\u8a18\u8ff0\u3057\u305f\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e\u5834\u5408\u306b\u306f\u3001\u7d50\u679c\u51fa\u529b\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b database_result.json \u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <p>\u5f62\u5f0f\u306f\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8 \u3068\u540c\u3058</p>"},{"location":"ja/use_case/yabloc/","title":"YabLoc\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u306e\u8a55\u4fa1","text":"<p>Autoware \u306eYabLoc\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u304c\u5b89\u5b9a\u3057\u3066\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p>"},{"location":"ja/use_case/yabloc/#_1","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p>launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>yabloc_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u3092\u884c\u3046</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c topic \u3092 subscribe \u3057\u3066\u3001\u5404\u57fa\u6e96\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3057\u3066\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/yabloc/#yabloc_1","title":"YabLoc \u306e\u53ef\u7528\u6027","text":"<p>\u672c\u9805\u76ee\u3067\u306f\u3001YabLoc\u306e\u53ef\u7528\u6027\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u3002\u3053\u308c\u306f\u3001\u5177\u4f53\u7684\u306b\u306f\u3001\u4e0b\u8a18\u306e\u3088\u3046\u306a\u30b1\u30fc\u30b9\u3092\u691c\u77e5\u3059\u308b\u3053\u3068\u3092\u76ee\u7684\u3068\u3059\u308b\u3002</p> <ul> <li>Runtime error\u7b49\u306b\u3088\u308a <code>image_processing</code> \u304c\u843d\u3061\u3066\u3044\u308b</li> <li>Runtime error\u7b49\u306b\u3088\u308a <code>particle_filter</code> \u304c\u843d\u3061\u3066\u3044\u308b</li> </ul> <p>\u305d\u306e\u305f\u3081\u306b\u3001\u672c\u9805\u76ee\u3067\u306f\u4e0b\u8a18\u306e\u51fa\u529b\u304c\u5b9a\u671f\u7684\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <ul> <li>/localization/pose_estimator/yabloc/pf/pose</li> </ul> <p>\u3053\u308c\u306f\u3001YabLoc Monitor\u3068\u3044\u3046Autoware\u5185\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u9593\u63a5\u7684\u306b\u5229\u7528\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u5b9f\u73fe\u3055\u308c\u308b\u3002\u672c\u30c4\u30fc\u30eb\u306f\u3001\u4e0b\u8a18\u306e\u30c8\u30d4\u30c3\u30af\u3092\u76e3\u8996\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u305d\u306e\u60c5\u5831\u3092\u53d6\u5f97\u3059\u308b\u3002</p> <ul> <li>/diagnostics</li> </ul>"},{"location":"ja/use_case/yabloc/#_2","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/yabloc/#_3","title":"\u53ef\u7528\u6027\u6b63\u5e38","text":"<p>YabLoc Monitor\u304c\u51fa\u529b\u3059\u308b <code>/diagnostics</code> \u306e\u4e2d\u304b\u3089\u3001\u76e3\u8996\u30c8\u30d4\u30c3\u30af\u306b\u95a2\u3059\u308b\u60c5\u5831\u3092\u62bd\u51fa\u3059\u308b\u3002 \u6700\u65b0\u306e\u60c5\u5831\u306b\u304a\u3051\u308bAvailability\u304c <code>OK</code> \u3067\u3042\u308b\u5834\u5408\u3001\u6b63\u5e38\u3067\u3042\u308b\u3068\u5224\u65ad\u3059\u308b\u3002</p>"},{"location":"ja/use_case/yabloc/#_4","title":"\u53ef\u7528\u6027\u7570\u5e38","text":"<p>\u53ef\u7528\u6027\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/yabloc/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs/msg/DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"ja/use_case/yabloc/#service","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Service \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"service \u540d \u30c7\u30fc\u30bf\u578b /localization/initialize autoware_internal_localization_msgs/srv/InitializeLocalization"},{"location":"ja/use_case/yabloc/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> <li>pose_source: yabloc</li> <li>twist_source: gyro_odom</li> </ul>"},{"location":"ja/use_case/yabloc/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/yabloc/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/yabloc/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/yabloc/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/yabloc/#_5","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/yabloc/#_6","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>\u4ee5\u4e0b\u306b\u3001\u305d\u308c\u305e\u308c\u306e\u8a55\u4fa1\u306e\u4f8b\u3092\u8a18\u8ff0\u3059\u308b\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>Availability\u306e\u7d50\u679c(Frame \u306e\u4e2d\u306b Availability \u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre>"}]}